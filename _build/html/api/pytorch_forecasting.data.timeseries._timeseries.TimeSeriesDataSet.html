
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>TimeSeriesDataSet &#8212; pytorch-forecasting  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=9542a950" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script async="async" src="https://buttons.github.io/buttons.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'api/pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet';</script>
    <link rel="icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DistributionLoss" href="pytorch_forecasting.metrics.base_metrics._base_metrics.DistributionLoss.html" />
    <link rel="prev" title="NaNLabelEncoder" href="pytorch_forecasting.data.encoders.NaNLabelEncoder.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.svg" class="logo__image only-light" alt="pytorch-forecasting  documentation - Home"/>
    <img src="../_static/logo.svg" class="logo__image only-dark pst-js-only" alt="pytorch-forecasting  documentation - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../getting-started.html">
    Getting started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../tutorials.html">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../data.html">
    Data
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../models.html">
    Models
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../metrics.html">
    Metrics
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../faq.html">
    FAQ
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../installation.html">
    Installation
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../api.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../CHANGELOG.html">
    Release Notes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://github.com/sktime/pytorch-forecasting">
    GitHub
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/sktime/pytorch-forecasting" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
        <div class="navbar-item">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../getting-started.html">
    Getting started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../tutorials.html">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../data.html">
    Data
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../models.html">
    Models
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../metrics.html">
    Metrics
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../faq.html">
    FAQ
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../installation.html">
    Installation
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../api.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../CHANGELOG.html">
    Release Notes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://github.com/sktime/pytorch-forecasting">
    GitHub
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/sktime/pytorch-forecasting" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
          <div class="navbar-item">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="pytorch_forecasting.data.html">data</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.data._tslib_data_module.html">_tslib_data_module</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.data._tslib_data_module.TslibDataModule.html">TslibDataModule</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.data._tslib_data_module._TslibDataset.html">_TslibDataset</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.data.data_module.html">data_module</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.data.data_module.EncoderDecoderTimeSeriesDataModule.html">EncoderDecoderTimeSeriesDataModule</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.data.encoders.html">encoders</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.data.encoders._clipped_log.html">_clipped_log</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.data.encoders._clipped_logit.html">_clipped_logit</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.data.encoders._identity.html">_identity</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.data.encoders._minus_one.html">_minus_one</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.data.encoders._plus_one.html">_plus_one</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.data.encoders._square.html">_square</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.data.encoders.softplus_inv.html">softplus_inv</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.data.encoders.EncoderNormalizer.html">EncoderNormalizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.data.encoders.Expm1Transform.html">Expm1Transform</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.data.encoders.GroupNormalizer.html">GroupNormalizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.data.encoders.MinusOneTransform.html">MinusOneTransform</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.data.encoders.MultiNormalizer.html">MultiNormalizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.data.encoders.NaNLabelEncoder.html">NaNLabelEncoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.data.encoders.ReLuTransform.html">ReLuTransform</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.data.encoders.SoftplusTransform.html">SoftplusTransform</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.data.encoders.TorchNormalizer.html">TorchNormalizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.data.encoders.TransformMixIn.html">TransformMixIn</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.data.examples.html">examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.data.examples._get_data_by_filename.html">_get_data_by_filename</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.data.examples.generate_ar_data.html">generate_ar_data</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.data.examples.get_stallion_data.html">get_stallion_data</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.data.examples.load_toydata.html">load_toydata</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.data.samplers.html">samplers</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.data.samplers.GroupedSampler.html">GroupedSampler</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.data.samplers.TimeSynchronizedBatchSampler.html">TimeSynchronizedBatchSampler</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="pytorch_forecasting.data.tests.html">tests</a></li>
<li class="toctree-l2 current active has-children"><a class="reference internal" href="pytorch_forecasting.data.timeseries.html">timeseries</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l3 current active has-children"><a class="reference internal" href="pytorch_forecasting.data.timeseries._timeseries.html">_timeseries</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.data.timeseries._timeseries._find_end_indices.html">_find_end_indices</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.data.timeseries._timeseries.check_for_nonfinite.html">check_for_nonfinite</a></li>
<li class="toctree-l4 current active"><a class="current reference internal" href="#">TimeSeriesDataSet</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.data.timeseries._timeseries_v2.html">_timeseries_v2</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.data.timeseries._timeseries_v2.TimeSeries.html">TimeSeries</a></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="pytorch_forecasting.models.html">models</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.models.base.html">base</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.base._base_model.html">_base_model</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.base._base_model._concatenate_output.html">_concatenate_output</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.base._base_model._torch_cat_na.html">_torch_cat_na</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.base._base_model.AutoRegressiveBaseModel.html">AutoRegressiveBaseModel</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.base._base_model.AutoRegressiveBaseModelWithCovariates.html">AutoRegressiveBaseModelWithCovariates</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.base._base_model.BaseModel.html">BaseModel</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.base._base_model.BaseModelWithCovariates.html">BaseModelWithCovariates</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.base._base_model.PredictCallback.html">PredictCallback</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.base._base_model.PredictTuple.html">PredictTuple</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.base._base_model.Prediction.html">Prediction</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.base._base_model_v2.html">_base_model_v2</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.base._base_model_v2.BaseModel.html">BaseModel</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.base._base_object.html">_base_object</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.base._base_object._BasePtForecaster.html">_BasePtForecaster</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.base._base_object._BasePtForecasterV2.html">_BasePtForecasterV2</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.base._base_object._BasePtForecaster_Common.html">_BasePtForecaster_Common</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.base._tslib_base_model_v2.html">_tslib_base_model_v2</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.base._tslib_base_model_v2.TslibBaseModel.html">TslibBaseModel</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="pytorch_forecasting.models.base_model.html">base_model</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.models.baseline.html">baseline</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.models.baseline.Baseline.html">Baseline</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.models.deepar.html">deepar</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.deepar._deepar.html">_deepar</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.deepar._deepar.DeepAR.html">DeepAR</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.deepar._deepar_pkg.html">_deepar_pkg</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.deepar._deepar_pkg.DeepAR_pkg.html">DeepAR_pkg</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.models.dlinear.html">dlinear</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.dlinear._dlinear_pkg_v2.html">_dlinear_pkg_v2</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.dlinear._dlinear_pkg_v2.DLinear_pkg_v2.html">DLinear_pkg_v2</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.dlinear._dlinear_v2.html">_dlinear_v2</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.dlinear._dlinear_v2.DLinear.html">DLinear</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.models.mlp.html">mlp</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.mlp._decodermlp.html">_decodermlp</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.mlp._decodermlp.DecoderMLP.html">DecoderMLP</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.mlp._decodermlp_pkg.html">_decodermlp_pkg</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.mlp._decodermlp_pkg.DecoderMLP_pkg.html">DecoderMLP_pkg</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.mlp.submodules.html">submodules</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.mlp.submodules.FullyConnectedModule.html">FullyConnectedModule</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.models.nbeats.html">nbeats</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.nbeats._nbeats.html">_nbeats</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.nbeats._nbeats.NBeats.html">NBeats</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.nbeats._nbeats_pkg.html">_nbeats_pkg</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.nbeats._nbeats_pkg.NBeats_pkg.html">NBeats_pkg</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.nbeats.sub_modules.html">sub_modules</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.nbeats.sub_modules.linear.html">linear</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.nbeats.sub_modules.linspace.html">linspace</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.nbeats.sub_modules.NBEATSBlock.html">NBEATSBlock</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.nbeats.sub_modules.NBEATSGenericBlock.html">NBEATSGenericBlock</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.nbeats.sub_modules.NBEATSSeasonalBlock.html">NBEATSSeasonalBlock</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.nbeats.sub_modules.NBEATSTrendBlock.html">NBEATSTrendBlock</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.models.nhits.html">nhits</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.nhits._nhits.html">_nhits</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.nhits._nhits.NHiTS.html">NHiTS</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.nhits._nhits_pkg.html">_nhits_pkg</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.nhits._nhits_pkg.NHiTS_pkg.html">NHiTS_pkg</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.nhits.sub_modules.html">sub_modules</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.nhits.sub_modules.init_weights.html">init_weights</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.nhits.sub_modules.IdentityBasis.html">IdentityBasis</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.nhits.sub_modules.MLP.html">MLP</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.nhits.sub_modules.NHiTS.html">NHiTS</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.nhits.sub_modules.NHiTSBlock.html">NHiTSBlock</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.nhits.sub_modules.StaticFeaturesEncoder.html">StaticFeaturesEncoder</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.models.nn.html">nn</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.nn.embeddings.html">embeddings</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.nn.embeddings.MultiEmbedding.html">MultiEmbedding</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.nn.embeddings.TimeDistributedEmbeddingBag.html">TimeDistributedEmbeddingBag</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.nn.rnn.html">rnn</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.nn.rnn.get_rnn.html">get_rnn</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.nn.rnn.GRU.html">GRU</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.nn.rnn.LSTM.html">LSTM</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.nn.rnn.RNN.html">RNN</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.models.rnn.html">rnn</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.rnn._rnn.html">_rnn</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.rnn._rnn.RecurrentNetwork.html">RecurrentNetwork</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.rnn._rnn_pkg.html">_rnn_pkg</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.rnn._rnn_pkg.RecurrentNetwork_pkg.html">RecurrentNetwork_pkg</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.models.temporal_fusion_transformer.html">temporal_fusion_transformer</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.temporal_fusion_transformer._tft.html">_tft</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.temporal_fusion_transformer._tft.TemporalFusionTransformer.html">TemporalFusionTransformer</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.temporal_fusion_transformer._tft_pkg.html">_tft_pkg</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.temporal_fusion_transformer._tft_pkg.TemporalFusionTransformer_pkg.html">TemporalFusionTransformer_pkg</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.temporal_fusion_transformer._tft_pkg_v2.html">_tft_pkg_v2</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.temporal_fusion_transformer._tft_pkg_v2.TFT_pkg_v2.html">TFT_pkg_v2</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.temporal_fusion_transformer._tft_v2.html">_tft_v2</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.temporal_fusion_transformer._tft_v2.TFT.html">TFT</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.temporal_fusion_transformer.sub_modules.html">sub_modules</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.temporal_fusion_transformer.sub_modules.AddNorm.html">AddNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.temporal_fusion_transformer.sub_modules.GateAddNorm.html">GateAddNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.temporal_fusion_transformer.sub_modules.GatedLinearUnit.html">GatedLinearUnit</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.temporal_fusion_transformer.sub_modules.GatedResidualNetwork.html">GatedResidualNetwork</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.temporal_fusion_transformer.sub_modules.InterpretableMultiHeadAttention.html">InterpretableMultiHeadAttention</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.temporal_fusion_transformer.sub_modules.PositionalEncoder.html">PositionalEncoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.temporal_fusion_transformer.sub_modules.ResampleNorm.html">ResampleNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.temporal_fusion_transformer.sub_modules.ScaledDotProductAttention.html">ScaledDotProductAttention</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.temporal_fusion_transformer.sub_modules.TimeDistributed.html">TimeDistributed</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.temporal_fusion_transformer.sub_modules.TimeDistributedInterpolation.html">TimeDistributedInterpolation</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.temporal_fusion_transformer.sub_modules.VariableSelectionNetwork.html">VariableSelectionNetwork</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.temporal_fusion_transformer.tuning.html">tuning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.temporal_fusion_transformer.tuning._lazywhere.html">_lazywhere</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.temporal_fusion_transformer.tuning.optimize_hyperparameters.html">optimize_hyperparameters</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.models.tide.html">tide</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.tide._tide.html">_tide</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.tide._tide.TiDEModel.html">TiDEModel</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.tide._tide_dsipts.html">_tide_dsipts</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.tide._tide_dsipts._tide_v2.html">_tide_v2</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.tide._tide_dsipts._tide_v2_pkg.html">_tide_v2_pkg</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.tide._tide_pkg.html">_tide_pkg</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.tide._tide_pkg.TiDEModel_pkg.html">TiDEModel_pkg</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.tide.sub_modules.html">sub_modules</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.tide.sub_modules._ResidualBlock.html">_ResidualBlock</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.tide.sub_modules._TideModule.html">_TideModule</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.models.timexer.html">timexer</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.timexer._timexer.html">_timexer</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.timexer._timexer.TimeXer.html">TimeXer</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.timexer._timexer_pkg.html">_timexer_pkg</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.timexer._timexer_pkg.TimeXer_pkg.html">TimeXer_pkg</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.timexer._timexer_pkg_v2.html">_timexer_pkg_v2</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.timexer._timexer_pkg_v2.TimeXer_pkg_v2.html">TimeXer_pkg_v2</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.timexer._timexer_v2.html">_timexer_v2</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.timexer._timexer_v2.TimeXer.html">TimeXer</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.timexer.sub_modules.html">sub_modules</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.timexer.sub_modules.AttentionLayer.html">AttentionLayer</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.timexer.sub_modules.DataEmbedding_inverted.html">DataEmbedding_inverted</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.timexer.sub_modules.EnEmbedding.html">EnEmbedding</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.timexer.sub_modules.Encoder.html">Encoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.timexer.sub_modules.EncoderLayer.html">EncoderLayer</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.timexer.sub_modules.FlattenHead.html">FlattenHead</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.timexer.sub_modules.FullAttention.html">FullAttention</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.timexer.sub_modules.PositionalEmbedding.html">PositionalEmbedding</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.timexer.sub_modules.TriangularCausalMask.html">TriangularCausalMask</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.models.xlstm.html">xlstm</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.xlstm._xlstm.html">_xlstm</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.xlstm._xlstm.xLSTMTime.html">xLSTMTime</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.models.xlstm._xlstm_pkg.html">_xlstm_pkg</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.models.xlstm._xlstm_pkg.xLSTMTime_pkg.html">xLSTMTime_pkg</a></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="pytorch_forecasting.metrics.html">metrics</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="pytorch_forecasting.metrics._distributions_pkg.html">_distributions_pkg</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.metrics._mqf2_utils.html">_mqf2_utils</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.metrics._mqf2_utils.DeepConvexNet.html">DeepConvexNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.metrics._mqf2_utils.MQF2Distribution.html">MQF2Distribution</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.metrics._mqf2_utils.SequentialNet.html">SequentialNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.metrics._mqf2_utils.TransformedMQF2Distribution.html">TransformedMQF2Distribution</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="pytorch_forecasting.metrics._point_pkg.html">_point_pkg</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.metrics._quantile_pkg.html">_quantile_pkg</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.metrics._quantile_pkg._quantile_loss_pkg.html">_quantile_loss_pkg</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.metrics._quantile_pkg._quantile_loss_pkg.QuantileLoss_pkg.html">QuantileLoss_pkg</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.metrics.base_metrics.html">base_metrics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.metrics.base_metrics._base_metrics.html">_base_metrics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.metrics.base_metrics._base_metrics.convert_torchmetric_to_pytorch_forecasting_metric.html">convert_torchmetric_to_pytorch_forecasting_metric</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.metrics.base_metrics._base_metrics.AggregationMetric.html">AggregationMetric</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.metrics.base_metrics._base_metrics.CompositeMetric.html">CompositeMetric</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.metrics.base_metrics._base_metrics.DistributionLoss.html">DistributionLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.metrics.base_metrics._base_metrics.Metric.html">Metric</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.metrics.base_metrics._base_metrics.MultiHorizonMetric.html">MultiHorizonMetric</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.metrics.base_metrics._base_metrics.MultiLoss.html">MultiLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.metrics.base_metrics._base_metrics.MultivariateDistributionLoss.html">MultivariateDistributionLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.metrics.base_metrics._base_metrics.TorchMetricWrapper.html">TorchMetricWrapper</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.metrics.base_metrics._base_object.html">_base_object</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.metrics.base_metrics._base_object._BasePtMetric.html">_BasePtMetric</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.metrics.distributions.html">distributions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.metrics.distributions.BetaDistributionLoss.html">BetaDistributionLoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.metrics.distributions.ImplicitQuantileNetwork.html">ImplicitQuantileNetwork</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.metrics.distributions.ImplicitQuantileNetworkDistributionLoss.html">ImplicitQuantileNetworkDistributionLoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.metrics.distributions.LogNormalDistributionLoss.html">LogNormalDistributionLoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.metrics.distributions.MQF2DistributionLoss.html">MQF2DistributionLoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.metrics.distributions.MultivariateNormalDistributionLoss.html">MultivariateNormalDistributionLoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.metrics.distributions.NegativeBinomialDistributionLoss.html">NegativeBinomialDistributionLoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.metrics.distributions.NormalDistributionLoss.html">NormalDistributionLoss</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.metrics.point.html">point</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.metrics.point.CrossEntropy.html">CrossEntropy</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.metrics.point.MAE.html">MAE</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.metrics.point.MAPE.html">MAPE</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.metrics.point.MASE.html">MASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.metrics.point.PoissonLoss.html">PoissonLoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.metrics.point.RMSE.html">RMSE</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.metrics.point.SMAPE.html">SMAPE</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.metrics.point.TweedieLoss.html">TweedieLoss</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.metrics.quantile.html">quantile</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.metrics.quantile.QuantileLoss.html">QuantileLoss</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="pytorch_forecasting.utils.html">utils</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.utils._classproperty.html">_classproperty</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.utils._classproperty.classproperty.html">classproperty</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.utils._coerce.html">_coerce</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.utils._coerce._coerce_to_dict.html">_coerce_to_dict</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.utils._coerce._coerce_to_list.html">_coerce_to_list</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.utils._dependencies.html">_dependencies</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.utils._dependencies._dependencies.html">_dependencies</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.utils._dependencies._dependencies._check_matplotlib.html">_check_matplotlib</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.utils._dependencies._dependencies._get_installed_packages.html">_get_installed_packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.utils._dependencies._dependencies._get_installed_packages_private.html">_get_installed_packages_private</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.utils._dependencies._safe_import.html">_safe_import</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.utils._dependencies.tests.html">tests</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.utils._dependencies.tests.test_safe_import.html">test_safe_import</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.utils._maint.html">_maint</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="pytorch_forecasting.utils._maint._show_versions.html">_show_versions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.utils._maint._show_versions._get_deps_info.html">_get_deps_info</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.utils._maint._show_versions._get_sys_info.html">_get_sys_info</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch_forecasting.utils._maint._show_versions.show_versions.html">show_versions</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pytorch_forecasting.utils._utils.html">_utils</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.utils._utils.apply_to_list.html">apply_to_list</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.utils._utils.autocorrelation.html">autocorrelation</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.utils._utils.concat_sequences.html">concat_sequences</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.utils._utils.create_mask.html">create_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.utils._utils.detach.html">detach</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.utils._utils.get_embedding_size.html">get_embedding_size</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.utils._utils.groupby_apply.html">groupby_apply</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.utils._utils.integer_histogram.html">integer_histogram</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.utils._utils.masked_op.html">masked_op</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.utils._utils.move_to_device.html">move_to_device</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.utils._utils.next_fast_len.html">next_fast_len</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.utils._utils.padded_stack.html">padded_stack</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.utils._utils.profile.html">profile</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.utils._utils.repr_class.html">repr_class</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.utils._utils.to_list.html">to_list</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.utils._utils.unpack_sequence.html">unpack_sequence</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.utils._utils.unsqueeze_like.html">unsqueeze_like</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.utils._utils.InitialParameterRepresenterMixIn.html">InitialParameterRepresenterMixIn</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.utils._utils.OutputMixIn.html">OutputMixIn</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_forecasting.utils._utils.TupleOutputMixIn.html">TupleOutputMixIn</a></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../getting-started.html" class="nav-link">Getting started</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">TimeSeriesDataSet</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="timeseriesdataset">
<h1>TimeSeriesDataSet<a class="headerlink" href="#timeseriesdataset" title="Link to this heading">#</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pytorch_forecasting.data.timeseries._timeseries.</span></span><span class="sig-name descname"><span class="pre">TimeSeriesDataSet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">time_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group_ids</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_encoder_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">30</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_encoder_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_prediction_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_prediction_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_prediction_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_categoricals</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_reals</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">time_varying_known_categoricals</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">time_varying_known_reals</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">time_varying_unknown_categoricals</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">time_varying_unknown_reals</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">variable_groups</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constant_fill_strategy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allow_missing_timesteps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lags</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_relative_time_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_target_scales</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_encoder_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_normalizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="pytorch_forecasting.data.encoders.TorchNormalizer.html#pytorch_forecasting.data.encoders.TorchNormalizer" title="pytorch_forecasting.data.encoders.TorchNormalizer"><span class="pre">TorchNormalizer</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="pytorch_forecasting.data.encoders.NaNLabelEncoder.html#pytorch_forecasting.data.encoders.NaNLabelEncoder" title="pytorch_forecasting.data.encoders.NaNLabelEncoder"><span class="pre">NaNLabelEncoder</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="pytorch_forecasting.data.encoders.EncoderNormalizer.html#pytorch_forecasting.data.encoders.EncoderNormalizer" title="pytorch_forecasting.data.encoders.EncoderNormalizer"><span class="pre">EncoderNormalizer</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="pytorch_forecasting.data.encoders.TorchNormalizer.html#pytorch_forecasting.data.encoders.TorchNormalizer" title="pytorch_forecasting.data.encoders.TorchNormalizer"><span class="pre">TorchNormalizer</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="pytorch_forecasting.data.encoders.NaNLabelEncoder.html#pytorch_forecasting.data.encoders.NaNLabelEncoder" title="pytorch_forecasting.data.encoders.NaNLabelEncoder"><span class="pre">NaNLabelEncoder</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="pytorch_forecasting.data.encoders.EncoderNormalizer.html#pytorch_forecasting.data.encoders.EncoderNormalizer" title="pytorch_forecasting.data.encoders.EncoderNormalizer"><span class="pre">EncoderNormalizer</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="pytorch_forecasting.data.encoders.TorchNormalizer.html#pytorch_forecasting.data.encoders.TorchNormalizer" title="pytorch_forecasting.data.encoders.TorchNormalizer"><span class="pre">TorchNormalizer</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="pytorch_forecasting.data.encoders.NaNLabelEncoder.html#pytorch_forecasting.data.encoders.NaNLabelEncoder" title="pytorch_forecasting.data.encoders.NaNLabelEncoder"><span class="pre">NaNLabelEncoder</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="pytorch_forecasting.data.encoders.EncoderNormalizer.html#pytorch_forecasting.data.encoders.EncoderNormalizer" title="pytorch_forecasting.data.encoders.EncoderNormalizer"><span class="pre">EncoderNormalizer</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">categorical_encoders</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="pytorch_forecasting.data.encoders.NaNLabelEncoder.html#pytorch_forecasting.data.encoders.NaNLabelEncoder" title="pytorch_forecasting.data.encoders.NaNLabelEncoder"><span class="pre">NaNLabelEncoder</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scalers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="(in scikit-learn v1.7)"><span class="pre">StandardScaler</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler" title="(in scikit-learn v1.7)"><span class="pre">RobustScaler</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="pytorch_forecasting.data.encoders.TorchNormalizer.html#pytorch_forecasting.data.encoders.TorchNormalizer" title="pytorch_forecasting.data.encoders.TorchNormalizer"><span class="pre">TorchNormalizer</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="pytorch_forecasting.data.encoders.EncoderNormalizer.html#pytorch_forecasting.data.encoders.EncoderNormalizer" title="pytorch_forecasting.data.encoders.EncoderNormalizer"><span class="pre">EncoderNormalizer</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">randomize_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pytorch_forecasting/data/timeseries/_timeseries.html#TimeSeriesDataSet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Dataset</span></code></p>
<p>PyTorch Dataset for fitting timeseries models.</p>
<p>The dataset automates common tasks such as</p>
<ul class="simple">
<li><p>scaling and encoding of variables</p></li>
<li><p>normalizing the target variable</p></li>
<li><p>efficiently converting timeseries in pandas dataframes to torch tensors</p></li>
<li><p>holding information about static and time-varying variables known and unknown in
the future</p></li>
<li><p>holding information about related categories (such as holidays)</p></li>
<li><p>downsampling for data augmentation</p></li>
<li><p>generating inference, validation and test datasets</p></li>
</ul>
<p>The <span class="xref std std-ref">tutorial on passing data to models</span> is helpful to
understand the output of the dataset
and how it is coupled to models.</p>
<p>Each sample is a subsequence of a full time series. The subsequence consists of
encoder and decoder/prediction
timepoints for a given time series. This class constructs an index which defined
which subsequences exists and
can be samples from (<code class="docutils literal notranslate"><span class="pre">index</span></code> attribute). The samples in the index are defined
by the various parameters.
to the class (encoder and prediction lengths, minimum prediction length, randomize
length and predict keywords).
How samples are
sampled into batches for training, is determined by the DataLoader.
The class provides the
<a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.to_dataloader" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.to_dataloader"><code class="xref py py-meth docutils literal notranslate"><span class="pre">to_dataloader()</span></code></a> method
to convert the dataset into a dataloader.</p>
<p>Large datasets:</p>
<p>Currently the class is limited to in-memory operations (that can be sped up by an
existing installation of <a class="reference external" href="https://pypi.org/project/numba/">numba</a>).
If you have extremely large data,
however, you can pass prefitted encoders and and scalers to it and a subset of
sequences to the class to
construct a valid dataset (plus, likely the EncoderNormalizer should be used to
normalize targets).
when fitting a network, you would then to create a custom DataLoader that rotates
through the datasets.
There are currently no in-built methods to do this.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>pd.DataFrame</em>) – dataframe with sequence data - each row can be identified with
<code class="docutils literal notranslate"><span class="pre">time_idx</span></code> and the <code class="docutils literal notranslate"><span class="pre">group_ids</span></code></p></li>
<li><p><strong>time_idx</strong> (<em>str</em>) – integer typed column denoting the time index within <code class="docutils literal notranslate"><span class="pre">data</span></code>.
This columns is used to determine the sequence of samples.
If there are no missings observations,
the time index should increase by <code class="docutils literal notranslate"><span class="pre">+1</span></code> for each subsequent sample.
The first time_idx for each series does not necessarily
have to be <code class="docutils literal notranslate"><span class="pre">0</span></code> but any value is allowed.</p></li>
<li><p><strong>target</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>list</em><em>[</em><em>str</em><em>]</em><em>]</em>) – column(s) in <code class="docutils literal notranslate"><span class="pre">data</span></code> denoting the forecasting target.
Can be categorical or continous dtype.</p></li>
<li><p><strong>group_ids</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – list of column names identifying a time series instance within <code class="docutils literal notranslate"><span class="pre">data</span></code>
This means that the <code class="docutils literal notranslate"><span class="pre">group_ids</span></code>
identify a sample together with the <code class="docutils literal notranslate"><span class="pre">time_idx</span></code>.
If you have only one timeseries, set this to the
name of column that is constant.</p></li>
<li><p><strong>weight</strong> (<em>str</em><em>, </em><em>optional</em><em>, </em><em>default=None</em>) – column name for weights. Defaults to None.</p></li>
<li><p><strong>max_encoder_length</strong> (<em>int</em><em>, </em><em>optional</em><em>, </em><em>default=30</em>) – maximum length to encode.
This is the maximum history length used by the time series dataset.</p></li>
<li><p><strong>min_encoder_length</strong> (<em>int</em><em>, </em><em>optional</em><em>, </em><em>default=max_encoder_length</em>) – minimum allowed length to encode. Defaults to max_encoder_length.</p></li>
<li><p><strong>min_prediction_idx</strong> (<em>int</em><em>, </em><em>optional</em><em>, </em><em>default = first time_idx in data</em>) – minimum <code class="docutils literal notranslate"><span class="pre">time_idx</span></code> from where to start predictions.
This parameter can be useful to create a validation or test set.</p></li>
<li><p><strong>max_prediction_length</strong> (<em>int</em><em>, </em><em>optional</em><em>, </em><em>default=1</em>) – maximum prediction/decoder length
(choose this not too short as it can help convergence)</p></li>
<li><p><strong>min_prediction_length</strong> (<em>int</em><em>, </em><em>optional</em><em>, </em><em>default=max_prediction_length</em>) – minimum prediction/decoder length</p></li>
<li><p><strong>static_categoricals</strong> (<em>list</em><em> of </em><em>str</em><em>, </em><em>optional</em><em>, </em><em>default=None</em>) – list of categorical variables that do not change over time, in <code class="docutils literal notranslate"><span class="pre">data</span></code>,
entries can be also lists which are then encoded together
(e.g. useful for product categories)</p></li>
<li><p><strong>static_reals</strong> (<em>list</em><em> of </em><em>str</em><em>, </em><em>optional</em><em>, </em><em>default=None</em>) – list of continuous variables that do not change over time</p></li>
<li><p><strong>time_varying_known_categoricals</strong> (<em>list</em><em> of </em><em>str</em><em>, </em><em>optional</em><em>, </em><em>default=None</em>) – list of categorical variables that change over time and are known in the future,
entries can be also lists which are then encoded together
(e.g. useful for special days or promotion categories)</p></li>
<li><p><strong>time_varying_known_reals</strong> (<em>list</em><em> of </em><em>str</em><em>, </em><em>optional</em><em>, </em><em>default=None</em>) – list of continuous variables that change over time and are known in the future
(e.g. price of a product, but not demand of a product)</p></li>
<li><p><strong>time_varying_unknown_categoricals</strong> (<em>list</em><em> of </em><em>str</em><em>, </em><em>optional</em><em>, </em><em>default=None</em>) – list of categorical variables that are not known in the future
and change over time.
entries can be also lists which are then encoded together
(e.g. useful for weather categories).
Target variables should be included here, if categorical.</p></li>
<li><p><strong>time_varying_unknown_reals</strong> (<em>list</em><em> of </em><em>str</em><em>, </em><em>optional</em><em>, </em><em>default=None</em>) – list of continuous variables that are not known in the future
and change over time.
Target variables should be included here, if real.</p></li>
<li><p><strong>variable_groups</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>list</em><em>[</em><em>str</em><em>]</em><em>]</em><em>, </em><em>optional</em><em>, </em><em>default=None</em>) – dictionary mapping a name to a list of columns in the data.
The name should be present
in a categorical or real class argument, to be able to encode or scale the
columns by group.
This will effectively combine categorical variables is particularly useful
if a categorical variable can have multiple values at the same time.
An example are holidays which can be overlapping.</p></li>
<li><p><strong>constant_fill_strategy</strong> (<em>dict</em><em>, </em><em>optional</em><em>, </em><em>default=None</em>) – Keys must be str, values can be str, float, int or bool.
Dictionary of column names with constants to fill in missing values if there
are gaps in the sequence (by default forward fill strategy is used).
The values will be only used if <code class="docutils literal notranslate"><span class="pre">allow_missing_timesteps=True</span></code>.
A common use case is to denote that demand was 0 if the sample is not in the
dataset.</p></li>
<li><p><strong>allow_missing_timesteps</strong> (<em>bool</em><em>, </em><em>optional</em><em>, </em><em>default=False</em>) – whether to allow missing timesteps that are automatically filled up.
Missing values refer to gaps in the <code class="docutils literal notranslate"><span class="pre">time_idx</span></code>, e.g. if a specific
timeseries has only samples for 1, 2, 4, 5, the sample for 3 will be
generated on-the-fly.
Allow missings does not deal with <code class="docutils literal notranslate"><span class="pre">NA</span></code> values. You should fill NA values
before passing the dataframe to the TimeSeriesDataSet.</p></li>
<li><p><strong>lags</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>list</em><em>[</em><em>int</em><em>]</em><em>]</em><em>, </em><em>optional</em><em>, </em><em>default=None</em>) – dictionary of variable names mapped to list of time steps by which the
variable should be lagged.
Lags can be useful to indicate seasonality to the models.
Useful to add if seasonalit(ies) of the data are known.,
In this case, it is recommended to add the target variables
with the corresponding lags to improve performance.
Lags must be at not larger than the shortest time series as all time series
will be cut by the largest lag value to prevent NA values.
A lagged variable has to appear in the time-varying variables.
If you only want the lagged but not the current value, lag it manually in
your input data using
<code class="docutils literal notranslate"><span class="pre">data[lagged_varname]</span> <span class="pre">=</span> <span class="pre">``</span>
<span class="pre">``data.sort_values(time_idx).groupby(group_ids,</span> <span class="pre">observed=True).shift(lag)</span></code>.</p></li>
<li><p><strong>add_relative_time_idx</strong> (<em>bool</em><em>, </em><em>optional</em><em>, </em><em>default=False</em>) – whether to add a relative time index as feature, i.e.,
for each sampled sequence, the index will range from -encoder_length to
prediction_length.</p></li>
<li><p><strong>add_target_scales</strong> (<em>bool</em><em>, </em><em>optional</em><em>, </em><em>default=False</em>) – whether to add scales for target to static real features, i.e., add the
center and scale of the unnormalized timeseries as features.</p></li>
<li><p><strong>add_encoder_length</strong> (<em>Union</em><em>[</em><em>bool</em><em>, </em><em>str</em><em>]</em><em>, </em><em>optional</em><em>, </em><em>default=&quot;auto&quot;</em>) – whether to add encoder length to list of static real variables.
Defaults to “auto”, iwhich is same as
<code class="docutils literal notranslate"><span class="pre">True</span></code> iff <code class="docutils literal notranslate"><span class="pre">min_encoder_length</span> <span class="pre">!=</span> <span class="pre">max_encoder_length</span></code>.</p></li>
<li><p><strong>target_normalizer</strong> (<em>torch transformer</em><em>, </em><em>str</em><em>, </em><em>list</em><em>, </em><em>tuple</em><em>, </em><em>optional</em><em>, </em><em>default=&quot;auto&quot;</em>) – Transformer that takes group_ids, target and time_idx to normalize targets.
You can choose from
<a class="reference internal" href="pytorch_forecasting.data.encoders.TorchNormalizer.html#pytorch_forecasting.data.encoders.TorchNormalizer" title="pytorch_forecasting.data.encoders.TorchNormalizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">TorchNormalizer</span></code></a>,
<a class="reference internal" href="pytorch_forecasting.data.encoders.GroupNormalizer.html#pytorch_forecasting.data.encoders.GroupNormalizer" title="pytorch_forecasting.data.encoders.GroupNormalizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">GroupNormalizer</span></code></a>,
<a class="reference internal" href="pytorch_forecasting.data.encoders.NaNLabelEncoder.html#pytorch_forecasting.data.encoders.NaNLabelEncoder" title="pytorch_forecasting.data.encoders.NaNLabelEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">NaNLabelEncoder</span></code></a>,
<a class="reference internal" href="pytorch_forecasting.data.encoders.EncoderNormalizer.html#pytorch_forecasting.data.encoders.EncoderNormalizer" title="pytorch_forecasting.data.encoders.EncoderNormalizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">EncoderNormalizer</span></code></a>
(on which overfitting tests will fail)
or <code class="docutils literal notranslate"><span class="pre">None</span></code> for using no normalizer. For multiple targets, use a
:py:class`~pytorch_forecasting.data.encoders.MultiNormalizer`.
By default an appropriate normalizer is chosen automatically.</p></li>
<li><p><strong>categorical_encoders</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>BaseEstimator</em><em>]</em>) – dictionary of scikit learn label transformers.
If you have unobserved categories in
the future  / a cold-start problem, you can use the
<a class="reference internal" href="pytorch_forecasting.data.encoders.NaNLabelEncoder.html#pytorch_forecasting.data.encoders.NaNLabelEncoder" title="pytorch_forecasting.data.encoders.NaNLabelEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">NaNLabelEncoder</span></code></a> with
<code class="docutils literal notranslate"><span class="pre">add_nan=True</span></code>.
Defaults effectively to sklearn’s <code class="docutils literal notranslate"><span class="pre">LabelEncoder()</span></code>.
Prefitted encoders will not be fit again.</p></li>
<li><p><strong>scalers</strong> (<em>optional</em><em>, </em><em>dict with str keys and torch</em><em> or </em><em>sklearn scalers as values</em>) – dictionary of scikit-learn or torch scalers.
Defaults to sklearn’s <code class="docutils literal notranslate"><span class="pre">StandardScaler()</span></code>.
Other options
are <a class="reference internal" href="pytorch_forecasting.data.encoders.EncoderNormalizer.html#pytorch_forecasting.data.encoders.EncoderNormalizer" title="pytorch_forecasting.data.encoders.EncoderNormalizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">EncoderNormalizer</span></code></a>,
<a class="reference internal" href="pytorch_forecasting.data.encoders.GroupNormalizer.html#pytorch_forecasting.data.encoders.GroupNormalizer" title="pytorch_forecasting.data.encoders.GroupNormalizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">GroupNormalizer</span></code></a>
or scikit-learn’s <code class="docutils literal notranslate"><span class="pre">StandarScaler()</span></code>,
<code class="docutils literal notranslate"><span class="pre">RobustScaler()</span></code> or <code class="docutils literal notranslate"><span class="pre">None</span></code> for using no normalizer / normalizer
with <code class="docutils literal notranslate"><span class="pre">center=0</span></code> and <code class="docutils literal notranslate"><span class="pre">scale=1</span></code>
(<code class="docutils literal notranslate"><span class="pre">method=&quot;identity&quot;</span></code>).
Prefittet encoders will not be fit again (with the exception of the
<a class="reference internal" href="pytorch_forecasting.data.encoders.EncoderNormalizer.html#pytorch_forecasting.data.encoders.EncoderNormalizer" title="pytorch_forecasting.data.encoders.EncoderNormalizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">EncoderNormalizer</span></code></a> that is
fit on every encoder sequence).</p></li>
<li><p><strong>randomize_length</strong> (<em>optional</em><em>, </em><em>None</em><em>, </em><em>bool</em><em>, or </em><em>tuple</em><em> of </em><em>float.</em>) – None or False if not to randomize lengths.
Tuple of beta distribution concentrations from which
probabilities are sampled that are used to sample new sequence lengths
with a binomial distribution.
If True, defaults to (0.2, 0.05), i.e. ~1/4 of samples
around minimum encoder length.
Defaults to False otherwise.</p></li>
<li><p><strong>predict_mode</strong> (<em>bool</em>) – If True, the TimeSeriesDataSet will only create one sequence
per time series (i.e. only from the latest provided samples).
Effectively, this will select each time series identified by <code class="docutils literal notranslate"><span class="pre">group_ids</span></code>
the last <code class="docutils literal notranslate"><span class="pre">max_prediction_length</span></code> samples of each time series as
prediction samples and everthing previous up to <code class="docutils literal notranslate"><span class="pre">max_encoder_length</span></code>
samples as encoder samples.
If False, the TimeSeriesDataSet will create subsequences by sliding a
window over the data samples.
For training use cases, it’s preferable to set predict_mode=False
to get all subseries.
On the other hand, predict_mode = True is ideal for validation cases.</p></li>
</ul>
</dd>
</dl>
<p>Timeseries dataset holding data for models.</p>
<dl class="field-list simple">
<dt class="field-odd">Inherited-members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
<p class="rubric">Methods</p>
<div class="pst-scrollable-table-container"><table class="autosummary longtable table autosummary">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.calculate_decoder_length" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.calculate_decoder_length"><code class="xref py py-obj docutils literal notranslate"><span class="pre">calculate_decoder_length</span></code></a>(time_last, ...)</p></td>
<td><p>Calculate length of decoder.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.filter" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.filter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">filter</span></code></a>(filter_func[, copy])</p></td>
<td><p>Filter subsequences in dataset.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.from_dataset" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.from_dataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">from_dataset</span></code></a>(dataset, data[, ...])</p></td>
<td><p>Construct dataset with different data, same variable encoders, scalers, etc.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.from_parameters" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.from_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">from_parameters</span></code></a>(parameters, data[, ...])</p></td>
<td><p>Construct dataset with different data, same variable encoders, scalers, etc.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.get_parameters" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.get_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_parameters</span></code></a>()</p></td>
<td><p>Get parameters of self as dict.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.get_transformer" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.get_transformer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_transformer</span></code></a>(name[, group_id])</p></td>
<td><p>Get transformer for variable.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.load" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(fname)</p></td>
<td><p>Load dataset from disk</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.plot_randomization" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.plot_randomization"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_randomization</span></code></a>([betas, length, min_length])</p></td>
<td><p>Plot expected randomized length distribution.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.reset_overwrite_values" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.reset_overwrite_values"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_overwrite_values</span></code></a>()</p></td>
<td><p>Reset values used to override sample features.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.save" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(fname)</p></td>
<td><p>Save dataset to disk</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.set_overwrite_values" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.set_overwrite_values"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_overwrite_values</span></code></a>(values, variable[, target])</p></td>
<td><p>Overwrite values in decoder or encoder (or both) for a specific variable.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.to_dataloader" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.to_dataloader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_dataloader</span></code></a>([train, batch_size, batch_sampler])</p></td>
<td><p>Construct dataloader from dataset, for use in models.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.transform_values" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.transform_values"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transform_values</span></code></a>(name, values[, data, ...])</p></td>
<td><p>Scale and encode values.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.x_to_index" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.x_to_index"><code class="xref py py-obj docutils literal notranslate"><span class="pre">x_to_index</span></code></a>(x)</p></td>
<td><p>Decode dataframe index from x.</p></td>
</tr>
</tbody>
</table>
</div>
<p class="rubric">Attributes</p>
<div class="pst-scrollable-table-container"><table class="autosummary longtable table autosummary">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.categoricals" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.categoricals"><code class="xref py py-obj docutils literal notranslate"><span class="pre">categoricals</span></code></a></p></td>
<td><p>Categorical variables as used for modelling.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.decoded_index" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.decoded_index"><code class="xref py py-obj docutils literal notranslate"><span class="pre">decoded_index</span></code></a></p></td>
<td><p>Get interpretable version of index.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.dropout_categoricals" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.dropout_categoricals"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dropout_categoricals</span></code></a></p></td>
<td><p>list of categorical variables that are unknown when making a forecast without observed history</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.flat_categoricals" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.flat_categoricals"><code class="xref py py-obj docutils literal notranslate"><span class="pre">flat_categoricals</span></code></a></p></td>
<td><p>Categorical variables as defined in input data.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.lagged_targets" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.lagged_targets"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lagged_targets</span></code></a></p></td>
<td><p>Subset of lagged_variables to variables that are lagged targets.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.lagged_variables" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.lagged_variables"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lagged_variables</span></code></a></p></td>
<td><p>Lagged variables.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.max_lag" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.max_lag"><code class="xref py py-obj docutils literal notranslate"><span class="pre">max_lag</span></code></a></p></td>
<td><p>Maximum number of time steps variables are lagged.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.min_lag" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.min_lag"><code class="xref py py-obj docutils literal notranslate"><span class="pre">min_lag</span></code></a></p></td>
<td><p>Minimum number of time steps variables are lagged.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.multi_target" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.multi_target"><code class="xref py py-obj docutils literal notranslate"><span class="pre">multi_target</span></code></a></p></td>
<td><p>If dataset encodes one or multiple targets.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.reals" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.reals"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reals</span></code></a></p></td>
<td><p>Continous variables as used for modelling.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.target_names" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.target_names"><code class="xref py py-obj docutils literal notranslate"><span class="pre">target_names</span></code></a></p></td>
<td><p>List of targets.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.target_normalizers" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.target_normalizers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">target_normalizers</span></code></a></p></td>
<td><p>List of target normalizers aligned with <code class="docutils literal notranslate"><span class="pre">target_names</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.variable_to_group_mapping" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.variable_to_group_mapping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">variable_to_group_mapping</span></code></a></p></td>
<td><p>Mapping from categorical variables to variables in input data.</p></td>
</tr>
</tbody>
</table>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.calculate_decoder_length">
<span class="sig-name descname"><span class="pre">calculate_decoder_length</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">time_last</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Series</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sequence_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Series</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ndarray</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Series</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ndarray</span></span></span><a class="reference internal" href="../_modules/pytorch_forecasting/data/timeseries/_timeseries.html#TimeSeriesDataSet.calculate_decoder_length"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.calculate_decoder_length" title="Link to this definition">#</a></dt>
<dd><p>Calculate length of decoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>time_last</strong> (<em>Union</em><em>[</em><em>int</em><em>, </em><em>pd.Series</em><em>, </em><em>np.ndarray</em><em>]</em>) – last time index of the sequence</p></li>
<li><p><strong>sequence_length</strong> (<em>Union</em><em>[</em><em>int</em><em>, </em><em>pd.Series</em><em>, </em><em>np.ndarray</em><em>]</em>) – total length of the sequence</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>decoder length(s)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[int, pd.Series, np.ndarray]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.filter">
<span class="sig-name descname"><span class="pre">filter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filter_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TimeSeriesType</span></span></span><a class="reference internal" href="../_modules/pytorch_forecasting/data/timeseries/_timeseries.html#TimeSeriesDataSet.filter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.filter" title="Link to this definition">#</a></dt>
<dd><p>Filter subsequences in dataset.</p>
<p>Uses interpretable version of index <a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.decoded_index" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.decoded_index"><code class="xref py py-meth docutils literal notranslate"><span class="pre">decoded_index()</span></code></a>
to filter subsequences in dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filter_func</strong> (<em>Callable</em>) – function to filter. Should take <a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.decoded_index" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.decoded_index"><code class="xref py py-meth docutils literal notranslate"><span class="pre">decoded_index()</span></code></a>
dataframe as only argument which contains group ids and time index columns.</p></li>
<li><p><strong>copy</strong> (<em>bool</em><em>, </em><em>optional</em><em>, </em><em>default=True</em>) – whether to return copy of dataset (True) or filter inplace (False).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>filtered dataset</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet">TimeSeriesDataSet</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.from_dataset">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TimeSeriesType</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_randomization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">update_kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TimeSeriesType</span></span></span><a class="reference internal" href="../_modules/pytorch_forecasting/data/timeseries/_timeseries.html#TimeSeriesDataSet.from_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.from_dataset" title="Link to this definition">#</a></dt>
<dd><p>Construct dataset with different data, same variable encoders, scalers, etc.</p>
<p>Calls <a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.from_parameters" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.from_parameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">from_parameters()</span></code></a> under the hood.</p>
<p>May override parameters with update_kwargs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset</strong> (<a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet"><em>TimeSeriesDataSet</em></a>) – dataset from which to copy parameters</p></li>
<li><p><strong>data</strong> (<em>pd.DataFrame</em>) – data from which new dataset will be generated</p></li>
<li><p><strong>stop_randomization</strong> (<em>bool</em><em>, </em><em>optional</em><em>, </em><em>default=None</em>) – Whether to stop randomizing encoder and decoder lengths,
useful for validation set.</p></li>
<li><p><strong>predict</strong> (<em>bool</em><em>, </em><em>optional</em><em>, </em><em>default=False</em>) – Whether to predict the decoder length on the last entries in the
time index (i.e. one prediction per group only).</p></li>
<li><p><strong>**update_kwargs</strong> – keyword arguments overrides, passed to constructor of the new dataset</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>new dataset</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet">TimeSeriesDataSet</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.from_parameters">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parameters</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_randomization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">update_kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TimeSeriesType</span></span></span><a class="reference internal" href="../_modules/pytorch_forecasting/data/timeseries/_timeseries.html#TimeSeriesDataSet.from_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.from_parameters" title="Link to this definition">#</a></dt>
<dd><p>Construct dataset with different data, same variable encoders, scalers, etc.</p>
<p>Returns TimeSeriesDataSet with same parameters as self, but different data.
May override parameters with update_kwargs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parameters</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – dataset parameters which to use for the new dataset</p></li>
<li><p><strong>data</strong> (<em>pd.DataFrame</em>) – data from which new dataset will be generated</p></li>
<li><p><strong>stop_randomization</strong> (<em>bool</em><em>, </em><em>optional</em><em>, </em><em>default=None</em>) – Whether to stop randomizing encoder and decoder lengths,
useful for validation set.</p></li>
<li><p><strong>predict</strong> (<em>bool</em><em>, </em><em>optional</em><em>, </em><em>default=False</em>) – Whether to predict the decoder length on the last entries in the
time index (i.e. one prediction per group only).</p></li>
<li><p><strong>**update_kwargs</strong> – keyword arguments overrides, passed to constructor of the new dataset</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>new dataset</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>TimeSeriesDataType</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.get_parameters">
<span class="sig-name descname"><span class="pre">get_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pytorch_forecasting/data/timeseries/_timeseries.html#TimeSeriesDataSet.get_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.get_parameters" title="Link to this definition">#</a></dt>
<dd><p>Get parameters of self as dict.</p>
<p>These can be used with <a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.from_parameters" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.from_parameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">from_parameters()</span></code></a>
to create a new dataset with the same scalers.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>dict[str, Any]</strong></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dictionary of parameters</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.get_transformer">
<span class="sig-name descname"><span class="pre">get_transformer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="pytorch_forecasting.data.encoders.TorchNormalizer.html#pytorch_forecasting.data.encoders.TorchNormalizer" title="pytorch_forecasting.data.encoders.TorchNormalizer"><span class="pre">TorchNormalizer</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="pytorch_forecasting.data.encoders.NaNLabelEncoder.html#pytorch_forecasting.data.encoders.NaNLabelEncoder" title="pytorch_forecasting.data.encoders.NaNLabelEncoder"><span class="pre">NaNLabelEncoder</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="pytorch_forecasting.data.encoders.EncoderNormalizer.html#pytorch_forecasting.data.encoders.EncoderNormalizer" title="pytorch_forecasting.data.encoders.EncoderNormalizer"><span class="pre">EncoderNormalizer</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Any</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/pytorch_forecasting/data/timeseries/_timeseries.html#TimeSeriesDataSet.get_transformer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.get_transformer" title="Link to this definition">#</a></dt>
<dd><p>Get transformer for variable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – variable name</p></li>
<li><p><strong>group_id</strong> (<em>bool</em><em>, </em><em>optional</em><em>, </em><em>default=False</em>) – Whether the passed name refers to a group id,
different encoders are used for these.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>transformer</strong> – transformer for variable, None if no transformer is available</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[NORMALIZER, Any, None]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.load">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TimeSeriesType</span></span></span><a class="reference internal" href="../_modules/pytorch_forecasting/data/timeseries/_timeseries.html#TimeSeriesDataSet.load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.load" title="Link to this definition">#</a></dt>
<dd><p>Load dataset from disk</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>fname</strong> (<em>str</em>) – filename to load from</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>TimeSeriesDataSet</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.plot_randomization">
<span class="sig-name descname"><span class="pre">plot_randomization</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">betas</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pytorch_forecasting/data/timeseries/_timeseries.html#TimeSeriesDataSet.plot_randomization"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.plot_randomization" title="Link to this definition">#</a></dt>
<dd><p>Plot expected randomized length distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>betas</strong> (<em>tuple</em><em>[</em><em>float</em><em>, </em><em>float</em><em>]</em><em>, </em><em>optional</em><em>, </em><em>default=randomize_length</em><em> of </em><em>dataset</em>) – Tuple of betas, e.g. <code class="docutils literal notranslate"><span class="pre">(0.2,</span> <span class="pre">0.05)</span></code> to use for randomization.</p></li>
<li><p><strong>length</strong> (<em>int</em><em>, </em><em>optional</em><em>, </em><em>default=max_encoder_length</em><em> of </em><em>dataset</em>) – Length of sequence to plot.</p></li>
<li><p><strong>min_length</strong> (<em>int</em><em>, </em><em>optional</em><em>, </em><em>default=min_encoder_length</em><em> of </em><em>dataset</em>) – Minimum length of sequence to plot.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>tuple of figure and histogram based on 1000 samples</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[plt.Figure, torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.reset_overwrite_values">
<span class="sig-name descname"><span class="pre">reset_overwrite_values</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/pytorch_forecasting/data/timeseries/_timeseries.html#TimeSeriesDataSet.reset_overwrite_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.reset_overwrite_values" title="Link to this definition">#</a></dt>
<dd><p>Reset values used to override sample features.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/pytorch_forecasting/data/timeseries/_timeseries.html#TimeSeriesDataSet.save"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.save" title="Link to this definition">#</a></dt>
<dd><p>Save dataset to disk</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>fname</strong> (<em>str</em>) – filename to save to</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.set_overwrite_values">
<span class="sig-name descname"><span class="pre">set_overwrite_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">variable</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">slice</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'decoder'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/pytorch_forecasting/data/timeseries/_timeseries.html#TimeSeriesDataSet.set_overwrite_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.set_overwrite_values" title="Link to this definition">#</a></dt>
<dd><p>Overwrite values in decoder or encoder (or both) for a specific variable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>values</strong> (<em>Union</em><em>[</em><em>float</em><em>, </em><em>torch.Tensor</em><em>]</em>) – values to use for overwrite.</p></li>
<li><p><strong>variable</strong> (<em>str</em>) – variable whose values should be overwritten.</p></li>
<li><p><strong>target</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>slice</em><em>]</em><em>, </em><em>optional</em><em>)</em>) – positions to overwrite. One of “decoder”, “encoder” or “all” or
a slice object which is directly used to overwrite indices,
e.g., <code class="docutils literal notranslate"><span class="pre">slice(-5,</span> <span class="pre">None)</span></code> will overwrite
the last 5 values. Defaults to “decoder”.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.to_dataloader">
<span class="sig-name descname"><span class="pre">to_dataloader</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_sampler</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sampler</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataLoader</span></span></span><a class="reference internal" href="../_modules/pytorch_forecasting/data/timeseries/_timeseries.html#TimeSeriesDataSet.to_dataloader"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.to_dataloader" title="Link to this definition">#</a></dt>
<dd><p>Construct dataloader from dataset, for use in models.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> (<em>bool</em><em>, </em><em>optional</em><em>, </em><em>default=Trze</em>) – whether dataloader is used for training (True) or prediction (False).
Will shuffle and drop last batch if True. Defaults to True.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em><em>, </em><em>default=64</em>) – batch size for training model. Defaults to 64.</p></li>
<li><p><strong>batch_sampler</strong> (<em>Sampler</em><em>, </em><em>str</em><em>, or </em><em>None</em><em>, </em><em>optional</em><em>, </em><em>default=None</em>) – <p>torch batch sampler or string. One of</p>
<ul>
<li><dl class="simple">
<dt>”synchronized”: ensure that samples in decoder are aligned in time.</dt><dd><p>Does not support missing values in dataset.
This makes only sense if the underlying algorithm makes use of
values aligned in time.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>PyTorch Sampler instance: any PyTorch sampler,</dt><dd><p>e.g., <code class="docutils literal notranslate"><span class="pre">the</span> <span class="pre">WeightedRandomSampler()</span></code></p>
</dd>
</dl>
</li>
<li><p>None: samples are taken randomly from times series.</p></li>
</ul>
</p></li>
<li><p><strong>**kwargs</strong> (additional arguments passed to <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> constructor)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p><strong>DataLoader</strong> – First entry is <code class="docutils literal notranslate"><span class="pre">x</span></code>, a dictionary of tensors with the entries,
and shapes in brackets.</p>
<ul class="simple">
<li><dl class="simple">
<dt>encoder_cat<span class="classifier">long (batch_size x n_encoder_time_steps x n_features)</span></dt><dd><p>long tensor of encoded categoricals for encoder</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>encoder_cont<span class="classifier">float (batch_size x n_encoder_time_steps x n_features)</span></dt><dd><p>float tensor of scaled continuous variables for encoder</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>encoder_target<span class="classifier">float (batch_size x n_encoder_time_steps) or list thereof</span></dt><dd><p>if list, each entry for a different target.
float tensor with unscaled continous target
or encoded categorical target,
list of tensors for multiple targets</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>encoder_lengths<span class="classifier">long (batch_size)</span></dt><dd><p>long tensor with lengths of the encoder time series. No entry will
be greater than n_encoder_time_steps</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>decoder_cat<span class="classifier">long (batch_size x n_decoder_time_steps x n_features)</span></dt><dd><p>long tensor of encoded categoricals for decoder</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>decoder_cont<span class="classifier">float (batch_size x n_decoder_time_steps x n_features)</span></dt><dd><p>float tensor of scaled continuous variables for decoder</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>decoder_target<span class="classifier">float (batch_size x n_decoder_time_steps) or list thereof</span></dt><dd><p>if list, with each entry for a different target.
float tensor with unscaled continous target or encoded categorical
target for decoder
- this corresponds to first entry of <code class="docutils literal notranslate"><span class="pre">y</span></code>,
list of tensors for multiple targets</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>decoder_lengths<span class="classifier">long (batch_size)</span></dt><dd><p>long tensor with lengths of the decoder time series. No entry will
be greater than n_decoder_time_steps</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>group_ids<span class="classifier">float (batch_size x number_of_ids)</span></dt><dd><p>encoded group ids that identify a time series in the dataset</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>target_scale<span class="classifier">float (batch_size x scale_size) or list thereof.</span></dt><dd><p>if list, with each entry for a different target.
parameters used to normalize the target.
Typically these are mean and standard deviation.
Is list of tensors for multiple targets.</p>
</dd>
</dl>
</li>
</ul>
<p>Second entry is <code class="docutils literal notranslate"><span class="pre">y</span></code>, a tuple of the form (<code class="docutils literal notranslate"><span class="pre">target</span></code>, <cite>weight</cite>)</p>
<ul class="simple">
<li><dl class="simple">
<dt>target<span class="classifier">float (batch_size x n_decoder_time_steps) or list thereof</span></dt><dd><p>if list, with each entry for a different target.
unscaled (continuous) or encoded (categories) targets,
list of tensors for multiple targets</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>weight<span class="classifier">None or float (batch_size x n_decoder_time_steps)</span></dt><dd><p>weights for each target, None if no weight is used (= equal weights)</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dataloader that returns Tuple.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<p>Weight by samples for training:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">WeightedRandomSampler</span>

<span class="c1"># length of probabilties for sampler have to be equal to the length of index</span>
<span class="n">probabilities</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">dataset</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="s2">&quot;target&quot;</span><span class="p">])</span>
<span class="n">sampler</span> <span class="o">=</span> <span class="n">WeightedRandomSampler</span><span class="p">(</span><span class="n">probabilities</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">probabilities</span><span class="p">))</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">to_dataloader</span><span class="p">(</span><span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.transform_values">
<span class="sig-name descname"><span class="pre">transform_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">values</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Series</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inverse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="reference internal" href="../_modules/pytorch_forecasting/data/timeseries/_timeseries.html#TimeSeriesDataSet.transform_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.transform_values" title="Link to this definition">#</a></dt>
<dd><p>Scale and encode values.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – name of variable</p></li>
<li><p><strong>values</strong> (<em>Union</em><em>[</em><em>pd.Series</em><em>, </em><em>torch.Tensor</em><em>, </em><em>np.ndarray</em><em>]</em>) – values to encode/scale</p></li>
<li><p><strong>data</strong> (<em>pd.DataFrame</em><em>, </em><em>optional</em><em>, </em><em>default=None</em>) – extra data used for scaling (e.g. dataframe with groups columns)</p></li>
<li><p><strong>inverse</strong> (<em>bool</em><em>, </em><em>optional</em><em>, </em><em>default=False</em>) – whether transform is plain (True), or inverse (False)</p></li>
<li><p><strong>group_id</strong> (<em>bool</em><em>, </em><em>optional</em><em>, </em><em>default=False</em>) – whether the passed name refers to a group id -
different encoders are used for these</p></li>
<li><p><strong>**kwargs</strong> (<em>additional arguments for transform/inverse_transform method</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(de/en)coded/(de)scaled values</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.x_to_index">
<span class="sig-name descname"><span class="pre">x_to_index</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="reference internal" href="../_modules/pytorch_forecasting/data/timeseries/_timeseries.html#TimeSeriesDataSet.x_to_index"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.x_to_index" title="Link to this definition">#</a></dt>
<dd><p>Decode dataframe index from x.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>dataframe with time index column for first prediction and group ids</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.categoricals">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">categoricals</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.categoricals" title="Link to this definition">#</a></dt>
<dd><p>Categorical variables as used for modelling.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of variables</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>list[str]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.decoded_index">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">decoded_index</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">DataFrame</span></em><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.decoded_index" title="Link to this definition">#</a></dt>
<dd><p>Get interpretable version of index.</p>
<p>DataFrame contains
- group_id columns in original encoding
- time_idx_first column: first time index of subsequence
- time_idx_last columns: last time index of subsequence
- time_idx_first_prediction columns: first time index which is in decoder</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>index that can be understood in terms of original data</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>pd.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.dropout_categoricals">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">dropout_categoricals</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.dropout_categoricals" title="Link to this definition">#</a></dt>
<dd><p>list of categorical variables that are unknown when making a
forecast without observed history</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.flat_categoricals">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">flat_categoricals</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.flat_categoricals" title="Link to this definition">#</a></dt>
<dd><p>Categorical variables as defined in input data.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of variables</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>list[str]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.lagged_targets">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">lagged_targets</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.lagged_targets" title="Link to this definition">#</a></dt>
<dd><p>Subset of lagged_variables to variables that are lagged targets.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dict</strong><strong>[</strong><strong>str</strong> – dictionary of variable names corresponding to lagged variables,
mapped to variable that is lagged</p></li>
<li><p><strong>str</strong><strong>]</strong> – dictionary of variable names corresponding to lagged variables,
mapped to variable that is lagged</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.lagged_variables">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">lagged_variables</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.lagged_variables" title="Link to this definition">#</a></dt>
<dd><p>Lagged variables.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dict</strong><strong>[</strong><strong>str</strong> – dictionary of variable names corresponding to lagged variables,
mapped to variable that is lagged</p></li>
<li><p><strong>str</strong><strong>]</strong> – dictionary of variable names corresponding to lagged variables,
mapped to variable that is lagged</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.max_lag">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_lag</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.max_lag" title="Link to this definition">#</a></dt>
<dd><p>Maximum number of time steps variables are lagged.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>int</strong></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>maximum lag</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.min_lag">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">min_lag</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.min_lag" title="Link to this definition">#</a></dt>
<dd><p>Minimum number of time steps variables are lagged.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>int</strong></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>minimum lag</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.multi_target">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">multi_target</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.multi_target" title="Link to this definition">#</a></dt>
<dd><p>If dataset encodes one or multiple targets.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>true if multiple targets</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.reals">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">reals</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.reals" title="Link to this definition">#</a></dt>
<dd><p>Continous variables as used for modelling.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of variables</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>list[str]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.target_names">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">target_names</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.target_names" title="Link to this definition">#</a></dt>
<dd><p>List of targets.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of targets</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>list[str]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.target_normalizers">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">target_normalizers</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="pytorch_forecasting.data.encoders.TorchNormalizer.html#pytorch_forecasting.data.encoders.TorchNormalizer" title="pytorch_forecasting.data.encoders.TorchNormalizer"><span class="pre">TorchNormalizer</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.target_normalizers" title="Link to this definition">#</a></dt>
<dd><p>List of target normalizers aligned with <code class="docutils literal notranslate"><span class="pre">target_names</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of target normalizers</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>list[<a class="reference internal" href="pytorch_forecasting.data.encoders.TorchNormalizer.html#pytorch_forecasting.data.encoders.TorchNormalizer" title="pytorch_forecasting.data.encoders.TorchNormalizer">TorchNormalizer</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.variable_to_group_mapping">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">variable_to_group_mapping</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.variable_to_group_mapping" title="Link to this definition">#</a></dt>
<dd><p>Mapping from categorical variables to variables in input data.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>dictionary, maps <code class="xref py py-meth docutils literal notranslate"><span class="pre">categorical()</span></code> to <a class="reference internal" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.flat_categoricals" title="pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.flat_categoricals"><code class="xref py py-meth docutils literal notranslate"><span class="pre">flat_categoricals()</span></code></a>.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict[str, str]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="pytorch_forecasting.data.encoders.NaNLabelEncoder.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">NaNLabelEncoder</p>
      </div>
    </a>
    <a class="right-next"
       href="pytorch_forecasting.metrics.base_metrics._base_metrics.DistributionLoss.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">DistributionLoss</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.calculate_decoder_length"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet.calculate_decoder_length()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.filter"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet.filter()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.from_dataset"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet.from_dataset()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.from_parameters"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet.from_parameters()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.get_parameters"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet.get_parameters()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.get_transformer"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet.get_transformer()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.load"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet.load()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.plot_randomization"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet.plot_randomization()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.reset_overwrite_values"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet.reset_overwrite_values()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.save"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet.save()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.set_overwrite_values"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet.set_overwrite_values()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.to_dataloader"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet.to_dataloader()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.transform_values"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet.transform_values()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.x_to_index"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet.x_to_index()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.categoricals"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet.categoricals</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.decoded_index"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet.decoded_index</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.dropout_categoricals"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet.dropout_categoricals</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.flat_categoricals"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet.flat_categoricals</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.lagged_targets"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet.lagged_targets</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.lagged_variables"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet.lagged_variables</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.max_lag"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet.max_lag</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.min_lag"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet.min_lag</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.multi_target"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet.multi_target</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.reals"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet.reals</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.target_names"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet.target_names</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.target_normalizers"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet.target_normalizers</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.variable_to_group_mapping"><code class="docutils literal notranslate"><span class="pre">TimeSeriesDataSet.variable_to_group_mapping</span></code></a></li>
</ul>
</li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/api/pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2020, Jan Beitner.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.3.7.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>