
<!DOCTYPE html>


<html lang="en" data-content_root="../../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>pytorch_forecasting.data.timeseries._timeseries &#8212; pytorch-forecasting  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/custom.css?v=9542a950" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script async="async" src="https://buttons.github.io/buttons.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/pytorch_forecasting/data/timeseries/_timeseries';</script>
    <link rel="icon" href="../../../../_static/favicon.png"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../../_static/logo.svg" class="logo__image only-light" alt="pytorch-forecasting  documentation - Home"/>
    <img src="../../../../_static/logo.svg" class="logo__image only-dark pst-js-only" alt="pytorch-forecasting  documentation - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../getting-started.html">
    Getting started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../tutorials.html">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../data.html">
    Data
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../models.html">
    Models
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../metrics.html">
    Metrics
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../faq.html">
    FAQ
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../installation.html">
    Installation
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../api.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../CHANGELOG.html">
    Release Notes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://github.com/sktime/pytorch-forecasting">
    GitHub
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/sktime/pytorch-forecasting" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
        <div class="navbar-item">
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../getting-started.html">
    Getting started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../tutorials.html">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../data.html">
    Data
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../models.html">
    Models
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../metrics.html">
    Metrics
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../faq.html">
    FAQ
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../installation.html">
    Installation
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../api.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../CHANGELOG.html">
    Release Notes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://github.com/sktime/pytorch-forecasting">
    GitHub
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/sktime/pytorch-forecasting" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
          <div class="navbar-item">
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../../index.html" class="nav-link">Module code</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">pytorch_forecasting.data.timeseries._timeseries</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <h1>Source code for pytorch_forecasting.data.timeseries._timeseries</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Timeseries datasets.</span>

<span class="sd">Timeseries data is special and has to be processed and passed in a special way.</span>
<span class="sd">This module defines TimeSeriesDataSet,</span>
<span class="sd">a class that is able to handle a wide variety of timeseries data problems.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">copy</span> <span class="k">as</span> <span class="n">_copy</span><span class="p">,</span> <span class="n">deepcopy</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">cached_property</span>
<span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">TypeVar</span><span class="p">,</span> <span class="n">Union</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.exceptions</span> <span class="kn">import</span> <span class="n">NotFittedError</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">RobustScaler</span><span class="p">,</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.validation</span> <span class="kn">import</span> <span class="n">check_is_fitted</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.distributions</span> <span class="kn">import</span> <span class="n">Beta</span>
<span class="kn">from</span> <span class="nn">torch.nn.utils</span> <span class="kn">import</span> <span class="n">rnn</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Dataset</span>
<span class="kn">from</span> <span class="nn">torch.utils.data.sampler</span> <span class="kn">import</span> <span class="n">Sampler</span><span class="p">,</span> <span class="n">SequentialSampler</span>

<span class="kn">from</span> <span class="nn">pytorch_forecasting.data.encoders</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">EncoderNormalizer</span><span class="p">,</span>
    <span class="n">GroupNormalizer</span><span class="p">,</span>
    <span class="n">MultiNormalizer</span><span class="p">,</span>
    <span class="n">NaNLabelEncoder</span><span class="p">,</span>
    <span class="n">TorchNormalizer</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pytorch_forecasting.data.samplers</span> <span class="kn">import</span> <span class="n">TimeSynchronizedBatchSampler</span>
<span class="kn">from</span> <span class="nn">pytorch_forecasting.utils</span> <span class="kn">import</span> <span class="n">repr_class</span>
<span class="kn">from</span> <span class="nn">pytorch_forecasting.utils._coerce</span> <span class="kn">import</span> <span class="n">_coerce_to_dict</span><span class="p">,</span> <span class="n">_coerce_to_list</span>
<span class="kn">from</span> <span class="nn">pytorch_forecasting.utils._dependencies</span> <span class="kn">import</span> <span class="n">_check_matplotlib</span>


<div class="viewcode-block" id="_find_end_indices">
<a class="viewcode-back" href="../../../../api/pytorch_forecasting.data.timeseries._timeseries._find_end_indices.html#pytorch_forecasting.data.timeseries._timeseries._find_end_indices">[docs]</a>
<span class="k">def</span> <span class="nf">_find_end_indices</span><span class="p">(</span>
    <span class="n">diffs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">max_lengths</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">min_length</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Identify end indices in series even if some values are missing.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    diffs : np.ndarray</span>
<span class="sd">        array of differences to next time step. nans should be filled up with ones</span>
<span class="sd">    max_lengths : np.ndarray</span>
<span class="sd">        maximum length of sequence by position.</span>
<span class="sd">    min_length : int</span>
<span class="sd">        minimum length of sequence.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tuple[np.ndarray, np.ndarray]</span>
<span class="sd">        tuple of arrays where first is end indices and second is list of start</span>
<span class="sd">        and end indices that are currently missing.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">missing_start_ends</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">end_indices</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">length</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">start_idx</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">max_idx</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">diffs</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">max_length</span> <span class="o">=</span> <span class="n">max_lengths</span><span class="p">[</span><span class="n">start_idx</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">diff</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">diffs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">length</span> <span class="o">&gt;=</span> <span class="n">max_length</span><span class="p">:</span>
            <span class="k">while</span> <span class="n">length</span> <span class="o">&gt;=</span> <span class="n">max_length</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">length</span> <span class="o">==</span> <span class="n">max_length</span><span class="p">:</span>
                    <span class="n">end_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">end_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">idx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">length</span> <span class="o">-=</span> <span class="n">diffs</span><span class="p">[</span><span class="n">start_idx</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">start_idx</span> <span class="o">&lt;</span> <span class="n">max_idx</span><span class="p">:</span>
                    <span class="n">start_idx</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">max_length</span> <span class="o">=</span> <span class="n">max_lengths</span><span class="p">[</span><span class="n">start_idx</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">length</span> <span class="o">&gt;=</span> <span class="n">min_length</span><span class="p">:</span>
            <span class="n">missing_start_ends</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">idx</span><span class="p">])</span>
        <span class="n">length</span> <span class="o">+=</span> <span class="n">diff</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">missing_start_ends</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># required for numba compliance</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">end_indices</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">missing_start_ends</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">end_indices</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span></div>



<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">numba</span>

    <span class="n">_find_end_indices</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">nopython</span><span class="o">=</span><span class="kc">True</span><span class="p">)(</span><span class="n">_find_end_indices</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="k">pass</span>


<div class="viewcode-block" id="check_for_nonfinite">
<a class="viewcode-back" href="../../../../api/pytorch_forecasting.data.timeseries._timeseries.check_for_nonfinite.html#pytorch_forecasting.data.timeseries._timeseries.check_for_nonfinite">[docs]</a>
<span class="k">def</span> <span class="nf">check_for_nonfinite</span><span class="p">(</span>
    <span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">names</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Check if tensor contains NAs or infinite values and has correct dimension.</span>

<span class="sd">    Checks:</span>

<span class="sd">    * whether tensor is finite, otherwise raises ValueError</span>
<span class="sd">    * checks whether dimension of tensor is correct. If tensor is a str,</span>
<span class="sd">      tensor.ndim has to be 1, and if tensor is a list, tensor.ndim has to be 2.</span>
<span class="sd">      Otherwise raises AssertionError.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    names : str or list of str</span>
<span class="sd">        name(s) of column(s) to check</span>
<span class="sd">    tensor : torch.Tensor</span>
<span class="sd">        tensor to check</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    torch.Tensor</span>
<span class="sd">        returns tensor unchanged, if checks yield no issues</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        if tensor contains NAs or infinite values</span>
<span class="sd">    AssertionError</span>
<span class="sd">        if tensor has incorrect dimension, see above</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">names</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="n">names</span><span class="p">]</span>
        <span class="k">assert</span> <span class="n">tensor</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="n">names</span>
        <span class="n">nans</span> <span class="o">=</span> <span class="p">(</span><span class="o">~</span><span class="n">torch</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">tensor</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="n">names</span>
        <span class="n">nans</span> <span class="o">=</span> <span class="p">(</span><span class="o">~</span><span class="n">torch</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">tensor</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">na</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">names</span><span class="p">,</span> <span class="n">nans</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">na</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">na</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">na</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">) of </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="s2">&quot;values were found to be NA or infinite (even after encoding). &quot;</span>
                <span class="s2">&quot;NA values are not allowed &quot;</span>
                <span class="s2">&quot;`allow_missing_timesteps` refers to missing rows, not to missing &quot;</span>
                <span class="s2">&quot;values. Possible strategies to &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;fix the issue are (a) dropping the variable </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">, &quot;</span>
                <span class="s2">&quot;(b) using `NaNLabelEncoder(add_nan=True)` for categorical variables, &quot;</span>
                <span class="s2">&quot;(c) filling missing values and/or (d) optionally adding a variable &quot;</span>
                <span class="s2">&quot;indicating filled values&quot;</span>
            <span class="p">)</span>
    <span class="k">return</span> <span class="n">tensor</span></div>



<span class="n">NORMALIZER</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="n">TorchNormalizer</span><span class="p">,</span> <span class="n">NaNLabelEncoder</span><span class="p">,</span> <span class="n">EncoderNormalizer</span><span class="p">]</span>

<span class="n">Columns</span> <span class="o">=</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
<span class="n">TargetType</span> <span class="o">=</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span>
<span class="n">TargetPositive</span> <span class="o">=</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]</span>
<span class="n">TargetSkew</span> <span class="o">=</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>

<span class="n">DataProperties</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">Columns</span><span class="p">,</span> <span class="n">TargetType</span><span class="p">,</span> <span class="n">TargetPositive</span><span class="p">,</span> <span class="n">TargetSkew</span><span class="p">]]</span>
<span class="n">TimeSeriesDataType</span> <span class="o">=</span> <span class="n">TypeVar</span><span class="p">(</span><span class="s2">&quot;TimeSeriesType&quot;</span><span class="p">,</span> <span class="n">bound</span><span class="o">=</span><span class="s2">&quot;TimeSeriesDataSet&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="TimeSeriesDataSet">
<a class="viewcode-back" href="../../../../data.html#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet">[docs]</a>
<span class="k">class</span> <span class="nc">TimeSeriesDataSet</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;PyTorch Dataset for fitting timeseries models.</span>

<span class="sd">    The dataset automates common tasks such as</span>

<span class="sd">    * scaling and encoding of variables</span>
<span class="sd">    * normalizing the target variable</span>
<span class="sd">    * efficiently converting timeseries in pandas dataframes to torch tensors</span>
<span class="sd">    * holding information about static and time-varying variables known and unknown in</span>
<span class="sd">      the future</span>
<span class="sd">    * holding information about related categories (such as holidays)</span>
<span class="sd">    * downsampling for data augmentation</span>
<span class="sd">    * generating inference, validation and test datasets</span>

<span class="sd">    The :ref:`tutorial on passing data to models &lt;passing-data&gt;` is helpful to</span>
<span class="sd">    understand the output of the dataset</span>
<span class="sd">    and how it is coupled to models.</span>

<span class="sd">    Each sample is a subsequence of a full time series. The subsequence consists of</span>
<span class="sd">    encoder and decoder/prediction</span>
<span class="sd">    timepoints for a given time series. This class constructs an index which defined</span>
<span class="sd">    which subsequences exists and</span>
<span class="sd">    can be samples from (``index`` attribute). The samples in the index are defined</span>
<span class="sd">    by the various parameters.</span>
<span class="sd">    to the class (encoder and prediction lengths, minimum prediction length, randomize</span>
<span class="sd">    length and predict keywords).</span>
<span class="sd">    How samples are</span>
<span class="sd">    sampled into batches for training, is determined by the DataLoader.</span>
<span class="sd">    The class provides the</span>
<span class="sd">    :py:meth:`~TimeSeriesDataSet.to_dataloader` method</span>
<span class="sd">    to convert the dataset into a dataloader.</span>

<span class="sd">    Large datasets:</span>

<span class="sd">    Currently the class is limited to in-memory operations (that can be sped up by an</span>
<span class="sd">    existing installation of `numba &lt;https://pypi.org/project/numba/&gt;`_).</span>
<span class="sd">    If you have extremely large data,</span>
<span class="sd">    however, you can pass prefitted encoders and and scalers to it and a subset of</span>
<span class="sd">    sequences to the class to</span>
<span class="sd">    construct a valid dataset (plus, likely the EncoderNormalizer should be used to</span>
<span class="sd">    normalize targets).</span>
<span class="sd">    when fitting a network, you would then to create a custom DataLoader that rotates</span>
<span class="sd">    through the datasets.</span>
<span class="sd">    There are currently no in-built methods to do this.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : pd.DataFrame</span>
<span class="sd">        dataframe with sequence data - each row can be identified with</span>
<span class="sd">        ``time_idx`` and the ``group_ids``</span>

<span class="sd">    time_idx : str</span>
<span class="sd">        integer typed column denoting the time index within ``data``.</span>
<span class="sd">        This columns is used to determine the sequence of samples.</span>
<span class="sd">        If there are no missings observations,</span>
<span class="sd">        the time index should increase by ``+1`` for each subsequent sample.</span>
<span class="sd">        The first time_idx for each series does not necessarily</span>
<span class="sd">        have to be ``0`` but any value is allowed.</span>

<span class="sd">    target : Union[str, list[str]]</span>
<span class="sd">        column(s) in ``data`` denoting the forecasting target.</span>
<span class="sd">        Can be categorical or continous dtype.</span>

<span class="sd">    group_ids : list[str]</span>
<span class="sd">        list of column names identifying a time series instance within ``data``</span>
<span class="sd">        This means that the ``group_ids``</span>
<span class="sd">        identify a sample together with the ``time_idx``.</span>
<span class="sd">        If you have only one timeseries, set this to the</span>
<span class="sd">        name of column that is constant.</span>

<span class="sd">    weight : str, optional, default=None</span>
<span class="sd">        column name for weights. Defaults to None.</span>

<span class="sd">    max_encoder_length : int, optional, default=30</span>
<span class="sd">        maximum length to encode.</span>
<span class="sd">        This is the maximum history length used by the time series dataset.</span>

<span class="sd">    min_encoder_length : int, optional, default=max_encoder_length</span>
<span class="sd">        minimum allowed length to encode. Defaults to max_encoder_length.</span>

<span class="sd">    min_prediction_idx : int, optional, default = first time_idx in data</span>
<span class="sd">        minimum ``time_idx`` from where to start predictions.</span>
<span class="sd">        This parameter can be useful to create a validation or test set.</span>

<span class="sd">    max_prediction_length : int, optional, default=1</span>
<span class="sd">        maximum prediction/decoder length</span>
<span class="sd">        (choose this not too short as it can help convergence)</span>

<span class="sd">    min_prediction_length : int, optional, default=max_prediction_length</span>
<span class="sd">        minimum prediction/decoder length</span>

<span class="sd">    static_categoricals : list of str, optional, default=None</span>
<span class="sd">        list of categorical variables that do not change over time, in ``data``,</span>
<span class="sd">        entries can be also lists which are then encoded together</span>
<span class="sd">        (e.g. useful for product categories)</span>

<span class="sd">    static_reals : list of str, optional, default=None</span>
<span class="sd">        list of continuous variables that do not change over time</span>

<span class="sd">    time_varying_known_categoricals : list of str, optional, default=None</span>
<span class="sd">        list of categorical variables that change over time and are known in the future,</span>
<span class="sd">        entries can be also lists which are then encoded together</span>
<span class="sd">        (e.g. useful for special days or promotion categories)</span>

<span class="sd">    time_varying_known_reals : list of str, optional, default=None</span>
<span class="sd">        list of continuous variables that change over time and are known in the future</span>
<span class="sd">        (e.g. price of a product, but not demand of a product)</span>

<span class="sd">    time_varying_unknown_categoricals : list of str, optional, default=None</span>
<span class="sd">        list of categorical variables that are not known in the future</span>
<span class="sd">        and change over time.</span>
<span class="sd">        entries can be also lists which are then encoded together</span>
<span class="sd">        (e.g. useful for weather categories).</span>
<span class="sd">        Target variables should be included here, if categorical.</span>

<span class="sd">    time_varying_unknown_reals : list of str, optional, default=None</span>
<span class="sd">        list of continuous variables that are not known in the future</span>
<span class="sd">        and change over time.</span>
<span class="sd">        Target variables should be included here, if real.</span>

<span class="sd">    variable_groups : Dict[str, list[str]], optional, default=None</span>
<span class="sd">        dictionary mapping a name to a list of columns in the data.</span>
<span class="sd">        The name should be present</span>
<span class="sd">        in a categorical or real class argument, to be able to encode or scale the</span>
<span class="sd">        columns by group.</span>
<span class="sd">        This will effectively combine categorical variables is particularly useful</span>
<span class="sd">        if a categorical variable can have multiple values at the same time.</span>
<span class="sd">        An example are holidays which can be overlapping.</span>

<span class="sd">    constant_fill_strategy : dict, optional, default=None</span>
<span class="sd">        Keys must be str, values can be str, float, int or bool.</span>
<span class="sd">        Dictionary of column names with constants to fill in missing values if there</span>
<span class="sd">        are gaps in the sequence (by default forward fill strategy is used).</span>
<span class="sd">        The values will be only used if ``allow_missing_timesteps=True``.</span>
<span class="sd">        A common use case is to denote that demand was 0 if the sample is not in the</span>
<span class="sd">        dataset.</span>

<span class="sd">    allow_missing_timesteps : bool, optional, default=False</span>
<span class="sd">        whether to allow missing timesteps that are automatically filled up.</span>
<span class="sd">        Missing values refer to gaps in the ``time_idx``, e.g. if a specific</span>
<span class="sd">        timeseries has only samples for 1, 2, 4, 5, the sample for 3 will be</span>
<span class="sd">        generated on-the-fly.</span>
<span class="sd">        Allow missings does not deal with ``NA`` values. You should fill NA values</span>
<span class="sd">        before passing the dataframe to the TimeSeriesDataSet.</span>

<span class="sd">    lags : dict[str, list[int]], optional, default=None</span>
<span class="sd">        dictionary of variable names mapped to list of time steps by which the</span>
<span class="sd">        variable should be lagged.</span>
<span class="sd">        Lags can be useful to indicate seasonality to the models.</span>
<span class="sd">        Useful to add if seasonalit(ies) of the data are known.,</span>
<span class="sd">        In this case, it is recommended to add the target variables</span>
<span class="sd">        with the corresponding lags to improve performance.</span>
<span class="sd">        Lags must be at not larger than the shortest time series as all time series</span>
<span class="sd">        will be cut by the largest lag value to prevent NA values.</span>
<span class="sd">        A lagged variable has to appear in the time-varying variables.</span>
<span class="sd">        If you only want the lagged but not the current value, lag it manually in</span>
<span class="sd">        your input data using</span>
<span class="sd">        ``data[lagged_varname] = ``</span>
<span class="sd">        ``data.sort_values(time_idx).groupby(group_ids, observed=True).shift(lag)``.</span>

<span class="sd">    add_relative_time_idx : bool, optional, default=False</span>
<span class="sd">        whether to add a relative time index as feature, i.e.,</span>
<span class="sd">        for each sampled sequence, the index will range from -encoder_length to</span>
<span class="sd">        prediction_length.</span>

<span class="sd">    add_target_scales : bool, optional, default=False</span>
<span class="sd">        whether to add scales for target to static real features, i.e., add the</span>
<span class="sd">        center and scale of the unnormalized timeseries as features.</span>

<span class="sd">    add_encoder_length : Union[bool, str], optional, default=&quot;auto&quot;</span>
<span class="sd">        whether to add encoder length to list of static real variables.</span>
<span class="sd">        Defaults to &quot;auto&quot;, iwhich is same as</span>
<span class="sd">        ``True`` iff ``min_encoder_length != max_encoder_length``.</span>

<span class="sd">    target_normalizer : torch transformer, str, list, tuple, optional, default=&quot;auto&quot;</span>
<span class="sd">        Transformer that takes group_ids, target and time_idx to normalize targets.</span>
<span class="sd">        You can choose from</span>
<span class="sd">        :py:class:`~pytorch_forecasting.data.encoders.TorchNormalizer`,</span>
<span class="sd">        :py:class:`~pytorch_forecasting.data.encoders.GroupNormalizer`,</span>
<span class="sd">        :py:class:`~pytorch_forecasting.data.encoders.NaNLabelEncoder`,</span>
<span class="sd">        :py:class:`~pytorch_forecasting.data.encoders.EncoderNormalizer`</span>
<span class="sd">        (on which overfitting tests will fail)</span>
<span class="sd">        or ``None`` for using no normalizer. For multiple targets, use a</span>
<span class="sd">        :py:class`~pytorch_forecasting.data.encoders.MultiNormalizer`.</span>
<span class="sd">        By default an appropriate normalizer is chosen automatically.</span>

<span class="sd">    categorical_encoders : dict[str, BaseEstimator]</span>
<span class="sd">        dictionary of scikit learn label transformers.</span>
<span class="sd">        If you have unobserved categories in</span>
<span class="sd">        the future  / a cold-start problem, you can use the</span>
<span class="sd">        :py:class:`~pytorch_forecasting.data.encoders.NaNLabelEncoder` with</span>
<span class="sd">        ``add_nan=True``.</span>
<span class="sd">        Defaults effectively to sklearn&#39;s ``LabelEncoder()``.</span>
<span class="sd">        Prefitted encoders will not be fit again.</span>

<span class="sd">    scalers : optional, dict with str keys and torch or sklearn scalers as values</span>
<span class="sd">        dictionary of scikit-learn or torch scalers.</span>
<span class="sd">        Defaults to sklearn&#39;s ``StandardScaler()``.</span>
<span class="sd">        Other options</span>
<span class="sd">        are :py:class:`~pytorch_forecasting.data.encoders.EncoderNormalizer`,</span>
<span class="sd">        :py:class:`~pytorch_forecasting.data.encoders.GroupNormalizer`</span>
<span class="sd">        or scikit-learn&#39;s ``StandarScaler()``,</span>
<span class="sd">        ``RobustScaler()`` or ``None`` for using no normalizer / normalizer</span>
<span class="sd">        with ``center=0`` and ``scale=1``</span>
<span class="sd">        (``method=&quot;identity&quot;``).</span>
<span class="sd">        Prefittet encoders will not be fit again (with the exception of the</span>
<span class="sd">        :py:class:`~pytorch_forecasting.data.encoders.EncoderNormalizer` that is</span>
<span class="sd">        fit on every encoder sequence).</span>

<span class="sd">    randomize_length : optional, None, bool, or tuple of float.</span>
<span class="sd">        None or False if not to randomize lengths.</span>
<span class="sd">        Tuple of beta distribution concentrations from which</span>
<span class="sd">        probabilities are sampled that are used to sample new sequence lengths</span>
<span class="sd">        with a binomial distribution.</span>
<span class="sd">        If True, defaults to (0.2, 0.05), i.e. ~1/4 of samples</span>
<span class="sd">        around minimum encoder length.</span>
<span class="sd">        Defaults to False otherwise.</span>

<span class="sd">    predict_mode : bool</span>
<span class="sd">        If True, the TimeSeriesDataSet will only create one sequence</span>
<span class="sd">        per time series (i.e. only from the latest provided samples).</span>
<span class="sd">        Effectively, this will select each time series identified by ``group_ids``</span>
<span class="sd">        the last ``max_prediction_length`` samples of each time series as</span>
<span class="sd">        prediction samples and everthing previous up to ``max_encoder_length``</span>
<span class="sd">        samples as encoder samples.</span>
<span class="sd">        If False, the TimeSeriesDataSet will create subsequences by sliding a</span>
<span class="sd">        window over the data samples.</span>
<span class="sd">        For training use cases, it&#39;s preferable to set predict_mode=False</span>
<span class="sd">        to get all subseries.</span>
<span class="sd">        On the other hand, predict_mode = True is ideal for validation cases.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># todo: refactor:</span>
    <span class="c1"># - creating base class with minimal functionality</span>
    <span class="c1"># - &quot;outsource&quot; transformations -&gt; use pytorch transformations as default</span>

    <span class="c1"># todo: integrate graphs</span>
    <span class="c1"># - add option to pass networkx graph to the dataset -&gt; clearly defined</span>
    <span class="c1"># - create method to create networkx graph for hierachies -&gt; clearly defined</span>
    <span class="c1"># - convert networkx graph to pytorch geometric graph</span>
    <span class="c1"># - create sampler to sample from the graph</span>
    <span class="c1"># - create option in `to_dataloader` method to use a graph sampler</span>
    <span class="c1">#     -&gt; automatically changing collate function which returns graphs</span>
    <span class="c1">#     -&gt; should incorporate entire dataset but be compatible with current approach</span>
    <span class="c1"># - integrate hierachical loss somehow into loss metrics</span>

    <span class="c1"># how to get there:</span>
    <span class="c1"># - add networkx and pytorch_geometric to requirements BUT as extras</span>
    <span class="c1">#     -&gt; do we also need torch_sparse, etc.? -&gt; can we avoid this? probably not</span>
    <span class="c1"># - networkx graph: define what makes sense from user perspective</span>
    <span class="c1"># - define conversion into pytorch geometric graph? is this a two-step process of</span>
    <span class="c1">#     - encoding networkx graph and converting it into &quot;unfilled&quot; pytorch geometric</span>
    <span class="c1">#       graph</span>
    <span class="c1">#     - then creating full graph in collate function on the fly?</span>
    <span class="c1">#     - or is data already stored in pytorch geometric graph, only cut through it?</span>
    <span class="c1">#     - dataformat would change? Is is all timeseries data? + mask when valid?</span>
    <span class="c1">#     - then making cuts through the graph in sampling?</span>
    <span class="c1">#     - would it be best in this case to re-think the timeseries class and design it</span>
    <span class="c1">#       as series of transformations?</span>
    <span class="c1">#     - what is the new master data? very off current state or very similar?</span>
    <span class="c1">#     - current approach is storing data in long format which is memory efficient</span>
    <span class="c1">#       and using the index object to</span>
    <span class="c1">#       make sense of it when accessing. graphs would require wide format?</span>
    <span class="c1"># - do NOT overengineer, i.e. support only usecase of single static graph,</span>
    <span class="c1">#   but only subset might be relevant</span>
    <span class="c1">#     -&gt; however, should think what happens if we want a dynamic graph. would this</span>
    <span class="c1">#        completely change the</span>
    <span class="c1">#        data format?</span>

    <span class="c1"># decisions:</span>
    <span class="c1"># - stay with long format and create graph on the fly even if hampering</span>
    <span class="c1">#   efficiency and performance</span>
    <span class="c1"># - go with pytorch_geometric approach for future proofing</span>
    <span class="c1"># - directly convert networkx into pytorch_geometric graph</span>
    <span class="c1"># - sampling: support only time-synchronized.</span>
    <span class="c1">#     - sample randomly an instance from index as now.</span>
    <span class="c1">#     - then get additional samples as per graph (that has been created) and</span>
    <span class="c1">#       available data</span>
    <span class="c1">#     - then collate into graph object</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">data</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">time_idx</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">target</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">group_ids</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">weight</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_encoder_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span>
        <span class="n">min_encoder_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">min_prediction_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">min_prediction_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_prediction_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">static_categoricals</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">static_reals</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">time_varying_known_categoricals</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">time_varying_known_reals</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">time_varying_unknown_categoricals</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">time_varying_unknown_reals</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">variable_groups</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">constant_fill_strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]]</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">allow_missing_timesteps</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">lags</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">add_relative_time_idx</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">add_target_scales</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">add_encoder_length</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="n">target_normalizer</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
            <span class="n">NORMALIZER</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">NORMALIZER</span><span class="p">],</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">NORMALIZER</span><span class="p">],</span> <span class="kc">None</span>
        <span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="n">categorical_encoders</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">NaNLabelEncoder</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">scalers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="nb">dict</span><span class="p">[</span>
                <span class="nb">str</span><span class="p">,</span>
                <span class="n">Union</span><span class="p">[</span><span class="n">StandardScaler</span><span class="p">,</span> <span class="n">RobustScaler</span><span class="p">,</span> <span class="n">TorchNormalizer</span><span class="p">,</span> <span class="n">EncoderNormalizer</span><span class="p">],</span>
            <span class="p">]</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">randomize_length</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">predict_mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Timeseries dataset holding data for models.&quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># write variables to self and handle defaults</span>
        <span class="c1"># -------------------------------------------</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_encoder_length</span> <span class="o">=</span> <span class="n">max_encoder_length</span>
        <span class="k">if</span> <span class="n">min_encoder_length</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">min_encoder_length</span> <span class="o">=</span> <span class="n">max_encoder_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_encoder_length</span> <span class="o">=</span> <span class="n">min_encoder_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_prediction_length</span> <span class="o">=</span> <span class="n">max_prediction_length</span>
        <span class="k">if</span> <span class="n">min_prediction_length</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">min_prediction_length</span> <span class="o">=</span> <span class="n">max_prediction_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_prediction_length</span> <span class="o">=</span> <span class="n">min_prediction_length</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">target</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">time_idx</span> <span class="o">=</span> <span class="n">time_idx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">group_ids</span> <span class="o">=</span> <span class="n">_coerce_to_list</span><span class="p">(</span><span class="n">group_ids</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">static_categoricals</span> <span class="o">=</span> <span class="n">static_categoricals</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_static_categoricals</span> <span class="o">=</span> <span class="n">_coerce_to_list</span><span class="p">(</span><span class="n">static_categoricals</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">static_reals</span> <span class="o">=</span> <span class="n">static_reals</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_static_reals</span> <span class="o">=</span> <span class="n">_coerce_to_list</span><span class="p">(</span><span class="n">static_reals</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">time_varying_known_categoricals</span> <span class="o">=</span> <span class="n">time_varying_known_categoricals</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_time_varying_known_categoricals</span> <span class="o">=</span> <span class="n">_coerce_to_list</span><span class="p">(</span>
            <span class="n">time_varying_known_categoricals</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">time_varying_known_reals</span> <span class="o">=</span> <span class="n">time_varying_known_reals</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_time_varying_known_reals</span> <span class="o">=</span> <span class="n">_coerce_to_list</span><span class="p">(</span><span class="n">time_varying_known_reals</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">time_varying_unknown_categoricals</span> <span class="o">=</span> <span class="n">time_varying_unknown_categoricals</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_time_varying_unknown_categoricals</span> <span class="o">=</span> <span class="n">_coerce_to_list</span><span class="p">(</span>
            <span class="n">time_varying_unknown_categoricals</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">time_varying_unknown_reals</span> <span class="o">=</span> <span class="n">time_varying_unknown_reals</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_time_varying_unknown_reals</span> <span class="o">=</span> <span class="n">_coerce_to_list</span><span class="p">(</span><span class="n">time_varying_unknown_reals</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">add_relative_time_idx</span> <span class="o">=</span> <span class="n">add_relative_time_idx</span>

        <span class="c1"># set automatic defaults</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">randomize_length</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">randomize_length</span><span class="p">:</span>
                <span class="n">randomize_length</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">randomize_length</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">randomize_length</span> <span class="o">=</span> <span class="n">randomize_length</span>

        <span class="k">if</span> <span class="n">min_prediction_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">min_prediction_idx</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">time_idx</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_prediction_idx</span> <span class="o">=</span> <span class="n">min_prediction_idx</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">constant_fill_strategy</span> <span class="o">=</span> <span class="n">constant_fill_strategy</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_constant_fill_strategy</span> <span class="o">=</span> <span class="n">_coerce_to_dict</span><span class="p">(</span><span class="n">constant_fill_strategy</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">predict_mode</span> <span class="o">=</span> <span class="n">predict_mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">allow_missing_timesteps</span> <span class="o">=</span> <span class="n">allow_missing_timesteps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span> <span class="o">=</span> <span class="n">target_normalizer</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">categorical_encoders</span> <span class="o">=</span> <span class="n">categorical_encoders</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_categorical_encoders</span> <span class="o">=</span> <span class="n">_coerce_to_dict</span><span class="p">(</span><span class="n">categorical_encoders</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">scalers</span> <span class="o">=</span> <span class="n">scalers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_scalers</span> <span class="o">=</span> <span class="n">_coerce_to_dict</span><span class="p">(</span><span class="n">scalers</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">add_target_scales</span> <span class="o">=</span> <span class="n">add_target_scales</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">variable_groups</span> <span class="o">=</span> <span class="n">variable_groups</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_variable_groups</span> <span class="o">=</span> <span class="n">_coerce_to_dict</span><span class="p">(</span><span class="n">variable_groups</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">lags</span> <span class="o">=</span> <span class="n">lags</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_lags</span> <span class="o">=</span> <span class="n">_coerce_to_dict</span><span class="p">(</span><span class="n">lags</span><span class="p">)</span>

        <span class="c1"># add_encoder_length</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">add_encoder_length</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Only &#39;auto&#39; allowed for add_encoder_length &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but found </span><span class="si">{</span><span class="n">add_encoder_length</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="k">assert</span> <span class="n">add_encoder_length</span> <span class="o">==</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">msg</span>
            <span class="n">add_encoder_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_encoder_length</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_encoder_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_encoder_length</span> <span class="o">=</span> <span class="n">add_encoder_length</span>

        <span class="c1"># overwrite values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_overwrite_values</span><span class="p">()</span>

        <span class="c1"># check parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_params</span><span class="p">()</span>

        <span class="c1"># data preprocessing in pandas</span>
        <span class="c1"># ----------------------------</span>

        <span class="c1"># get metadata from data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_data_properties</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_properties</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="c1"># target normalizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_target_normalizer</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_data_properties</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span>
        <span class="p">)</span>

        <span class="c1"># add time index relative to prediction position</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_relative_time_idx</span><span class="p">:</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="s2">&quot;relative_time_idx&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">columns</span>
            <span class="p">),</span> <span class="s2">&quot;relative_time_idx is a protected column and must not be present in data&quot;</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="s2">&quot;relative_time_idx&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_time_varying_known_reals</span>
                <span class="ow">and</span> <span class="s2">&quot;relative_time_idx&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reals</span>
            <span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_time_varying_known_reals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;relative_time_idx&quot;</span><span class="p">)</span>

        <span class="c1"># add decoder length to static real variables</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_encoder_length</span><span class="p">:</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="s2">&quot;encoder_length&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">columns</span>
            <span class="p">),</span> <span class="s2">&quot;encoder_length is a protected column and must not be present in data&quot;</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="s2">&quot;encoder_length&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_time_varying_known_reals</span>
                <span class="ow">and</span> <span class="s2">&quot;encoder_length&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reals</span>
            <span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_static_reals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;encoder_length&quot;</span><span class="p">)</span>

        <span class="c1"># add columns for additional features</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_relative_time_idx</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_encoder_length</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>  <span class="c1"># only copies indices (underlying data is NOT copied)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_relative_time_idx</span><span class="p">:</span>
            <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="s2">&quot;relative_time_idx&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="mf">0.0</span>  <span class="c1"># dummy - real value will be set dynamically in __getitem__()</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_encoder_length</span><span class="p">:</span>
            <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="s2">&quot;encoder_length&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="mi">0</span>  <span class="c1"># dummy - real value will be set dynamically in __getitem__()</span>
            <span class="p">)</span>

        <span class="c1"># validate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="c1"># add lags</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_lags</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_set_lagged_variables</span><span class="p">()</span>

        <span class="c1"># filter data</span>
        <span class="k">if</span> <span class="n">min_prediction_idx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># filtering for min_prediction_idx will be done on subsequence level,</span>
            <span class="c1"># ensuring that minimal decoder index is always &gt;= min_prediction_idx</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span>
                <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">time_idx</span><span class="p">]</span>
                <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_prediction_idx</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_encoder_length</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span>
            <span class="p">]</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">group_ids</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">time_idx</span><span class="p">])</span>

        <span class="c1"># preprocess data</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess_data</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Target normalizer is separate and not in scalers.&quot;</span>
        <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">target</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scalers</span><span class="p">,</span> <span class="n">msg</span>

        <span class="c1"># index for getitem based resampling</span>
        <span class="c1"># ----------------------------------</span>
        <span class="c1"># NOTE: this should be refactored and probably in a DataLoader</span>

        <span class="c1"># create index</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_construct_index</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">predict_mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">predict_mode</span><span class="p">)</span>

        <span class="c1"># data conversion to torch tensors</span>
        <span class="c1"># --------------------------------</span>

        <span class="c1"># convert to torch tensor for high performance data loading later</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_to_tensors</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="c1"># check that all tensors are finite</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_tensors</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_check_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check parameters of self against assumptions.&quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">max_encoder_length</span><span class="p">,</span> <span class="nb">int</span>
        <span class="p">),</span> <span class="s2">&quot;max encoder length must be integer&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">min_encoder_length</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_encoder_length</span>
        <span class="p">),</span> <span class="s2">&quot;max encoder length has to be larger equals min encoder length&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">min_encoder_length</span><span class="p">,</span> <span class="nb">int</span>
        <span class="p">),</span> <span class="s2">&quot;min encoder length must be integer&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">max_prediction_length</span><span class="p">,</span> <span class="nb">int</span>
        <span class="p">),</span> <span class="s2">&quot;max prediction length must be integer&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">min_prediction_length</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_prediction_length</span>
        <span class="p">),</span> <span class="s2">&quot;max prediction length has to be larger equals min prediction length&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">min_prediction_length</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="p">),</span> <span class="s2">&quot;min prediction length must be larger than 0&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">min_prediction_length</span><span class="p">,</span> <span class="nb">int</span>
        <span class="p">),</span> <span class="s2">&quot;min prediction length must be integer&quot;</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;add_encoder_length should be boolean or &#39;auto&#39; &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;but found </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">add_encoder_length</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">add_encoder_length</span><span class="p">,</span> <span class="nb">bool</span><span class="p">),</span> <span class="n">msg</span>

        <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span><span class="p">:</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="n">target</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_time_varying_known_reals</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;target </span><span class="si">{</span><span class="n">target</span><span class="si">}</span><span class="s2"> should be an unknown continuous variable in the future&quot;</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_lag</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;lags should be positive&quot;</span>

    <span class="k">def</span> <span class="nf">_data_properties</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataProperties</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a dict with properties of the data used later.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : pd.DataFrame</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict</span>
<span class="sd">            dictionary with properties of the data.</span>
<span class="sd">            The following fields are returned:</span>

<span class="sd">            * columns : list[str]</span>
<span class="sd">                list of column names in the data</span>
<span class="sd">            * target_type : dict[str, str]</span>
<span class="sd">                type of target variable, categorial or real.</span>
<span class="sd">                Keys are target variable names in self.target_names.</span>
<span class="sd">                Value is either &quot;categorical&quot; or &quot;real&quot;.</span>
<span class="sd">            * target_positive : dict[str, bool]</span>
<span class="sd">                whether target variable is positive.</span>
<span class="sd">                Keys are target variable names in self.target_names that are real.</span>
<span class="sd">                Value is True if all values of the target variable are positive.</span>
<span class="sd">                Computed and returned only if target_normalizer is &quot;auto&quot;.</span>
<span class="sd">            * target_skew : dict[str, float]</span>
<span class="sd">                skew of target variable.</span>
<span class="sd">                Keys are target variable names in self.target_names that are</span>
<span class="sd">                real and positive. Value is the skew of the target variable.</span>
<span class="sd">                Computed and returned only if target_normalizer is &quot;auto&quot;.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">target_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span>
        <span class="n">details_required</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">target_norm</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">target_norm</span> <span class="o">==</span> <span class="s2">&quot;auto&quot;</span>

        <span class="n">props</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;target_type&quot;</span><span class="p">:</span> <span class="p">{},</span> <span class="s2">&quot;target_skew&quot;</span><span class="p">:</span> <span class="p">{},</span> <span class="s2">&quot;target_positive&quot;</span><span class="p">:</span> <span class="p">{}}</span>
        <span class="n">props</span><span class="p">[</span><span class="s2">&quot;columns&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">data</span><span class="p">[</span><span class="n">target</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span> <span class="o">!=</span> <span class="s2">&quot;f&quot;</span><span class="p">:</span>  <span class="c1"># category</span>
                <span class="n">props</span><span class="p">[</span><span class="s2">&quot;target_type&quot;</span><span class="p">][</span><span class="n">target</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;categorical&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">props</span><span class="p">[</span><span class="s2">&quot;target_type&quot;</span><span class="p">][</span><span class="n">target</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;real&quot;</span>

                <span class="k">if</span> <span class="n">details_required</span><span class="p">:</span>
                    <span class="n">props</span><span class="p">[</span><span class="s2">&quot;target_positive&quot;</span><span class="p">][</span><span class="n">target</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">target</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
                    <span class="k">if</span> <span class="n">props</span><span class="p">[</span><span class="s2">&quot;target_positive&quot;</span><span class="p">][</span><span class="n">target</span><span class="p">]:</span>
                        <span class="n">props</span><span class="p">[</span><span class="s2">&quot;target_skew&quot;</span><span class="p">][</span><span class="n">target</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">target</span><span class="p">]</span><span class="o">.</span><span class="n">skew</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">props</span>

    <span class="k">def</span> <span class="nf">_set_lagged_variables</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Add lagged variables to lists of variables.</span>

<span class="sd">        * generates lagged variable names and adds them to the appropriate lists</span>
<span class="sd">          of time-varying variables, typed by known/unknown and categorical/real</span>
<span class="sd">        * checks that all lagged variables passed by user adhere to the</span>
<span class="sd">          naming convention of lags</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">var_name_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="p">(</span><span class="s2">&quot;real&quot;</span><span class="p">,</span> <span class="s2">&quot;known&quot;</span><span class="p">):</span> <span class="s2">&quot;_time_varying_known_reals&quot;</span><span class="p">,</span>
            <span class="p">(</span><span class="s2">&quot;real&quot;</span><span class="p">,</span> <span class="s2">&quot;unknown&quot;</span><span class="p">):</span> <span class="s2">&quot;_time_varying_unknown_reals&quot;</span><span class="p">,</span>
            <span class="p">(</span><span class="s2">&quot;cat&quot;</span><span class="p">,</span> <span class="s2">&quot;known&quot;</span><span class="p">):</span> <span class="s2">&quot;_time_varying_known_categoricals&quot;</span><span class="p">,</span>
            <span class="p">(</span><span class="s2">&quot;cat&quot;</span><span class="p">,</span> <span class="s2">&quot;unknown&quot;</span><span class="p">):</span> <span class="s2">&quot;_time_varying_unknown_categoricals&quot;</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="k">def</span> <span class="nf">_attr</span><span class="p">(</span><span class="n">realcat</span><span class="p">,</span> <span class="n">known</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">var_name_dict</span><span class="p">[(</span><span class="n">realcat</span><span class="p">,</span> <span class="n">known</span><span class="p">)])</span>

        <span class="k">def</span> <span class="nf">_append_if_new</span><span class="p">(</span><span class="n">lst</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">x</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">lst</span><span class="p">:</span>
                <span class="n">lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># check that all names passed in self._lags appear as variables</span>
        <span class="n">all_time_varying_var_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">kw</span> <span class="ow">in</span> <span class="n">var_name_dict</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">_attr</span><span class="p">(</span><span class="o">*</span><span class="n">kw</span><span class="p">)]</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lags</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">all_time_varying_var_names</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;lagged variable </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> is not a known &quot;</span>
                    <span class="s2">&quot;nor unknown time-varying variable&quot;</span>
                <span class="p">)</span>

        <span class="c1"># add lagged variables to type indicators</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lags</span><span class="p">:</span>
            <span class="n">lagged_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lagged_names</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

            <span class="c1"># add lags</span>
            <span class="k">for</span> <span class="n">realcat</span><span class="p">,</span> <span class="n">known</span> <span class="ow">in</span> <span class="n">var_name_dict</span><span class="p">:</span>
                <span class="n">var_names</span> <span class="o">=</span> <span class="n">_attr</span><span class="p">(</span><span class="n">realcat</span><span class="p">,</span> <span class="n">known</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">var_names</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">lagged_name</span><span class="p">,</span> <span class="n">lag</span> <span class="ow">in</span> <span class="n">lagged_names</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                        <span class="c1"># if lag is longer than horizon, lagged var becomes future-known</span>
                        <span class="k">if</span> <span class="n">known</span> <span class="o">==</span> <span class="s2">&quot;known&quot;</span> <span class="ow">or</span> <span class="n">lag</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_prediction_length</span><span class="p">:</span>
                            <span class="n">_append_if_new</span><span class="p">(</span><span class="n">_attr</span><span class="p">(</span><span class="n">realcat</span><span class="p">,</span> <span class="s2">&quot;known&quot;</span><span class="p">),</span> <span class="n">lagged_name</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">_append_if_new</span><span class="p">(</span><span class="n">_attr</span><span class="p">(</span><span class="n">realcat</span><span class="p">,</span> <span class="s2">&quot;unknown&quot;</span><span class="p">),</span> <span class="n">lagged_name</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">dropout_categoricals</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        list of categorical variables that are unknown when making a</span>
<span class="sd">        forecast without observed history</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="n">name</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">encoder</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_categorical_encoders</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">encoder</span><span class="o">.</span><span class="n">add_nan</span>
        <span class="p">]</span>

    <span class="k">def</span> <span class="nf">_get_lagged_names</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate names for lagged variables</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name : str</span>
<span class="sd">            name of variable to lag</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict[str, int]</span>
<span class="sd">            dictionary mapping new variable names to lags</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_lagged_by_</span><span class="si">{</span><span class="n">lag</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">lag</span> <span class="k">for</span> <span class="n">lag</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lags</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[])}</span>

    <span class="nd">@cached_property</span>
    <span class="k">def</span> <span class="nf">lagged_variables</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Lagged variables.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dict[str, str]</span>
<span class="sd">            dictionary of variable names corresponding to lagged variables,</span>
<span class="sd">            mapped to variable that is lagged</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">vars</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lags</span><span class="p">:</span>
            <span class="nb">vars</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="n">lag_name</span><span class="p">:</span> <span class="n">name</span> <span class="k">for</span> <span class="n">lag_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lagged_names</span><span class="p">(</span><span class="n">name</span><span class="p">)})</span>
        <span class="k">return</span> <span class="nb">vars</span>

    <span class="nd">@cached_property</span>
    <span class="k">def</span> <span class="nf">lagged_targets</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Subset of lagged_variables to variables that are lagged targets.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dict[str, str]</span>
<span class="sd">            dictionary of variable names corresponding to lagged variables,</span>
<span class="sd">            mapped to variable that is lagged</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">vars</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lags</span><span class="p">:</span>
            <span class="nb">vars</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="p">{</span>
                    <span class="n">lag_name</span><span class="p">:</span> <span class="n">name</span>
                    <span class="k">for</span> <span class="n">lag_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lagged_names</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span>
                <span class="p">}</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="nb">vars</span>

    <span class="nd">@cached_property</span>
    <span class="k">def</span> <span class="nf">min_lag</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Minimum number of time steps variables are lagged.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int: minimum lag</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_lags</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">1e9</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">min</span><span class="p">([</span><span class="nb">min</span><span class="p">(</span><span class="n">lag</span><span class="p">)</span> <span class="k">for</span> <span class="n">lag</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lags</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>

    <span class="nd">@cached_property</span>
    <span class="k">def</span> <span class="nf">max_lag</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Maximum number of time steps variables are lagged.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int: maximum lag</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_lags</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">max</span><span class="p">([</span><span class="nb">max</span><span class="p">(</span><span class="n">lag</span><span class="p">)</span> <span class="k">for</span> <span class="n">lag</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lags</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>

    <span class="k">def</span> <span class="nf">_set_target_normalizer</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">data_properties</span><span class="p">:</span> <span class="n">DataProperties</span><span class="p">,</span>
        <span class="n">target_normalizer</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">NORMALIZER</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TorchNormalizer</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Determine target normalizer.</span>

<span class="sd">        Determines normalizers for variables based on self.target_normalizer setting.</span>

<span class="sd">        Coerces normalizers to torch normalizer, and deals with the &quot;auto&quot; setting.</span>

<span class="sd">        In the auto case, the normalizer for a variable x is determined as follows:</span>

<span class="sd">        * if x is categorical, a NaNLabelEncoder is used</span>
<span class="sd">        * if x is real and max_encoder_length &gt; 20 and min_encoder_length &gt; 1,</span>
<span class="sd">            an EncoderNormalizer is used, otherwise a GroupNormalizer is used.</span>
<span class="sd">            The transformation used in it is determined as follows:</span>
<span class="sd">        * if x is real and positive, a log transformation is used if the skew of x is</span>
<span class="sd">            larger than 2.5, otherwise a ReLU transformation is used</span>
<span class="sd">        * if x is real and not positive, no transformation is used</span>

<span class="sd">        The &quot;auto&quot; case uses metadata from the data passed in ``data_properties``,</span>
<span class="sd">        otherwise the ``data_properties`` are not used.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data_properties : dict</span>
<span class="sd">            Dictionary of data properties as returned by self._data_properties(data)</span>
<span class="sd">        target_normalizer : Union[NORMALIZER, str, list, tuple, None]</span>
<span class="sd">            Normalizer for target variable. If &quot;auto&quot;, the normalizer is determined</span>
<span class="sd">            as above.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        TorchNormalizer</span>
<span class="sd">            Normalizer for target variable, determined as above.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">target_normalizer</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">target_normalizer</span> <span class="o">==</span> <span class="s2">&quot;auto&quot;</span><span class="p">:</span>
            <span class="n">target_normalizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_auto_normalizer</span><span class="p">(</span><span class="n">data_properties</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">target_normalizer</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="n">target_normalizer</span> <span class="o">=</span> <span class="n">MultiNormalizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">target_normalizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">target_normalizer</span> <span class="o">=</span> <span class="n">TorchNormalizer</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;identity&quot;</span><span class="p">)</span>

        <span class="c1"># validation</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">target_normalizer</span><span class="p">,</span> <span class="n">EncoderNormalizer</span><span class="p">)</span>
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_encoder_length</span> <span class="o">&gt;=</span> <span class="n">target_normalizer</span><span class="o">.</span><span class="n">min_length</span>
        <span class="p">),</span> <span class="s2">&quot;EncoderNormalizer is only allowed if min_encoder_length &gt; 1&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">target_normalizer</span><span class="p">,</span> <span class="p">(</span><span class="n">TorchNormalizer</span><span class="p">,</span> <span class="n">NaNLabelEncoder</span><span class="p">)),</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;target_normalizer has to be either None or of &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;class TorchNormalizer but found </span><span class="si">{</span><span class="n">target_normalizer</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_target</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">target_normalizer</span><span class="p">,</span> <span class="n">MultiNormalizer</span>
        <span class="p">),</span> <span class="p">(</span>
            <span class="s2">&quot;multiple targets / list of targets requires MultiNormalizer as &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;target_normalizer but found </span><span class="si">{</span><span class="n">target_normalizer</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">target_normalizer</span>

    <span class="k">def</span> <span class="nf">_get_auto_normalizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_properties</span><span class="p">:</span> <span class="n">DataProperties</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TorchNormalizer</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get normalizer for auto setting, using data_properties.</span>

<span class="sd">        See docstring of _set_target_normalizer for details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data_properties : dict</span>
<span class="sd">            Dictionary of data properties as returned by self._data_properties(data)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        TorchNormalizer</span>
<span class="sd">            Normalizer for target variable</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">normalizers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">data_properties</span><span class="p">[</span><span class="s2">&quot;target_type&quot;</span><span class="p">][</span><span class="n">target</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;categorical&quot;</span><span class="p">:</span>
                <span class="n">normalizers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">NaNLabelEncoder</span><span class="p">())</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_target_scales</span><span class="p">:</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                        <span class="s2">&quot;Target scales will be only added for continous targets&quot;</span><span class="p">,</span>
                        <span class="ne">UserWarning</span><span class="p">,</span>
                    <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># real</span>
                <span class="k">if</span> <span class="n">data_properties</span><span class="p">[</span><span class="s2">&quot;target_positive&quot;</span><span class="p">][</span><span class="n">target</span><span class="p">]:</span>
                    <span class="k">if</span> <span class="n">data_properties</span><span class="p">[</span><span class="s2">&quot;target_skew&quot;</span><span class="p">][</span><span class="n">target</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">2.5</span><span class="p">:</span>
                        <span class="n">transformer</span> <span class="o">=</span> <span class="s2">&quot;log&quot;</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">transformer</span> <span class="o">=</span> <span class="s2">&quot;relu&quot;</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">transformer</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_encoder_length</span> <span class="o">&gt;</span> <span class="mi">20</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_encoder_length</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">normalizers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">EncoderNormalizer</span><span class="p">(</span><span class="n">transformation</span><span class="o">=</span><span class="n">transformer</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">normalizers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">GroupNormalizer</span><span class="p">(</span><span class="n">transformation</span><span class="o">=</span><span class="n">transformer</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_target</span><span class="p">:</span>
            <span class="n">target_normalizer</span> <span class="o">=</span> <span class="n">MultiNormalizer</span><span class="p">(</span><span class="n">normalizers</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">target_normalizer</span> <span class="o">=</span> <span class="n">normalizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">target_normalizer</span>

    <span class="nd">@cached_property</span>
    <span class="k">def</span> <span class="nf">_group_ids_mapping</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Mapping of group id names to group ids used to identify series in dataset -</span>
<span class="sd">        group ids can also be used for target normalizer.</span>

<span class="sd">        The former can change from training to validation and test dataset</span>
<span class="sd">        while the later must not.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;__group_id__</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">group_ids</span><span class="p">}</span>

    <span class="nd">@cached_property</span>
    <span class="k">def</span> <span class="nf">_group_ids</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Group ids used to identify series in dataset.</span>

<span class="sd">        See :py:meth:`~TimeSeriesDataSet._group_ids_mapping` for details.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_group_ids_mapping</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">_validate_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Validate assumptions on data..&quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">time_idx</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span> <span class="o">==</span> <span class="s2">&quot;i&quot;</span>
        <span class="p">),</span> <span class="s2">&quot;Timeseries index should be of type integer&quot;</span>
        <span class="c1"># numeric categoricals which can cause issues in tensorborad logging</span>
        <span class="n">category_columns</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="s2">&quot;category&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">columns</span>
        <span class="n">object_columns</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="nb">object</span><span class="p">)</span><span class="o">.</span><span class="n">columns</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flat_categoricals</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;variable </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> specified but not found in data&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span>
                <span class="n">name</span> <span class="ow">in</span> <span class="n">object_columns</span>
                <span class="ow">or</span> <span class="p">(</span>
                    <span class="n">name</span> <span class="ow">in</span> <span class="n">category_columns</span>
                    <span class="ow">and</span> <span class="n">data</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">categories</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span> <span class="ow">not</span> <span class="ow">in</span> <span class="s2">&quot;bifc&quot;</span>
                <span class="p">)</span>
            <span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Data type of category </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> was found to be numeric&quot;</span>
                    <span class="s2">&quot; - use a string type / categorified string&quot;</span>
                <span class="p">)</span>
        <span class="c1"># check for &quot;.&quot; in column names</span>
        <span class="n">columns_with_dot</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\.&quot;</span><span class="p">)]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">columns_with_dot</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;column names must not contain &#39;.&#39; characters. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Names </span><span class="si">{</span><span class="n">columns_with_dot</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span><span class="si">}</span><span class="s2"> are invalid&quot;</span>
            <span class="p">)</span>

        <span class="k">assert</span> <span class="n">data</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">is_unique</span><span class="p">,</span> <span class="s2">&quot;data index has to be unique&quot;</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_lags</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lags</span><span class="p">:</span>
                <span class="n">lagged_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lagged_names</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">lagged_name</span> <span class="ow">in</span> <span class="n">lagged_names</span><span class="p">:</span>
                    <span class="k">assert</span> <span class="n">lagged_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">lagged_name</span><span class="si">}</span><span class="s2"> is a protected column and must not be &quot;</span>
                        <span class="s2">&quot;present in data&quot;</span>
                    <span class="p">)</span>

<div class="viewcode-block" id="TimeSeriesDataSet.save">
<a class="viewcode-back" href="../../../../api/pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.html#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.save">[docs]</a>
    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fname</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save dataset to disk</span>

<span class="sd">        Args:</span>
<span class="sd">            fname (str): filename to save to</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fname</span><span class="p">)</span></div>


<div class="viewcode-block" id="TimeSeriesDataSet.load">
<a class="viewcode-back" href="../../../../api/pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.html#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.load">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">cls</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">TimeSeriesDataType</span><span class="p">],</span> <span class="n">fname</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TimeSeriesDataType</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load dataset from disk</span>

<span class="sd">        Args:</span>
<span class="sd">            fname (str): filename to load from</span>

<span class="sd">        Returns:</span>
<span class="sd">            TimeSeriesDataSet</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">obj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="bp">cls</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Loaded file is not of class </span><span class="si">{</span><span class="bp">cls</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">return</span> <span class="n">obj</span></div>


    <span class="k">def</span> <span class="nf">_preprocess_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Scale continuous variables, encode categories and set aside target and weight.</span>

<span class="sd">        Args:</span>
<span class="sd">            data (pd.DataFrame): original data</span>

<span class="sd">        Returns:</span>
<span class="sd">            pd.DataFrame: pre-processed dataframe</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># add lags to data</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lags</span><span class="p">:</span>
            <span class="c1"># todo: add support for variable groups</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;lagged variables that are in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_variable_groups</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="s2">&quot;are not supported yet&quot;</span>
            <span class="p">)</span>
            <span class="k">assert</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_variable_groups</span><span class="p">,</span> <span class="n">msg</span>

            <span class="k">for</span> <span class="n">lagged_name</span><span class="p">,</span> <span class="n">lag</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lagged_names</span><span class="p">(</span><span class="n">name</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">data</span><span class="p">[</span><span class="n">lagged_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">group_ids</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span>
                    <span class="n">name</span>
                <span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="n">lag</span><span class="p">)</span>

        <span class="c1"># encode group ids - this encoding</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">group_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_group_ids_mapping</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># use existing encoder - but a copy of it not too loose current encodings</span>
            <span class="n">encoder</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_categorical_encoders</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">group_name</span><span class="p">,</span> <span class="n">NaNLabelEncoder</span><span class="p">())</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_categorical_encoders</span><span class="p">[</span><span class="n">group_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
                <span class="n">data</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
            <span class="n">data</span><span class="p">[</span><span class="n">group_name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_values</span><span class="p">(</span>
                <span class="n">name</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="n">name</span><span class="p">],</span> <span class="n">inverse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">group_id</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>

        <span class="c1"># encode categoricals first to ensure</span>
        <span class="c1"># that group normalizer relies on encoded categories</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span><span class="p">,</span> <span class="p">(</span><span class="n">GroupNormalizer</span><span class="p">,</span> <span class="n">MultiNormalizer</span><span class="p">)</span>
        <span class="p">):</span>  <span class="c1"># if we use a group normalizer, group_ids must be encoded as well</span>
            <span class="n">group_ids_to_encode</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">group_ids</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">group_ids_to_encode</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">dict</span><span class="o">.</span><span class="n">fromkeys</span><span class="p">(</span><span class="n">group_ids_to_encode</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">categoricals</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">lagged_variables</span><span class="p">:</span>
                <span class="k">continue</span>  <span class="c1"># do not encode here but only in transform</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_variable_groups</span><span class="p">:</span>  <span class="c1"># fit groups</span>
                <span class="n">columns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_variable_groups</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_categorical_encoders</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_categorical_encoders</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">NaNLabelEncoder</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
                        <span class="n">data</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                    <span class="p">)</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_categorical_encoders</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_categorical_encoders</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
                    <span class="k">except</span> <span class="n">NotFittedError</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_categorical_encoders</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_categorical_encoders</span><span class="p">[</span>
                            <span class="n">name</span>
                        <span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_categorical_encoders</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_categorical_encoders</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">NaNLabelEncoder</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
                <span class="k">elif</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_categorical_encoders</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="ow">and</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span>
                <span class="p">):</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_categorical_encoders</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
                    <span class="k">except</span> <span class="n">NotFittedError</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_categorical_encoders</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_categorical_encoders</span><span class="p">[</span>
                            <span class="n">name</span>
                        <span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>

        <span class="c1"># encode them</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">dict</span><span class="o">.</span><span class="n">fromkeys</span><span class="p">(</span><span class="n">group_ids_to_encode</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">flat_categoricals</span><span class="p">):</span>
            <span class="c1"># targets and its lagged versions are handled separetely</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span> <span class="ow">and</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">lagged_targets</span><span class="p">:</span>
                <span class="n">data</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_values</span><span class="p">(</span>
                    <span class="n">name</span><span class="p">,</span>
                    <span class="n">data</span><span class="p">[</span><span class="n">name</span><span class="p">],</span>
                    <span class="n">inverse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">ignore_na</span><span class="o">=</span><span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">lagged_variables</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="c1"># save special variables</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="s2">&quot;__time_idx__&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">columns</span>
        <span class="p">),</span> <span class="s2">&quot;__time_idx__ is a protected column and must not be present in data&quot;</span>
        <span class="n">data</span><span class="p">[</span><span class="s2">&quot;__time_idx__&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">time_idx</span><span class="p">]</span>  <span class="c1"># save unscaled</span>
        <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;__target__</span><span class="si">{</span><span class="n">target</span><span class="si">}</span><span class="s2"> is a protected column &quot;</span>
                <span class="s2">&quot;and must not be present in data&quot;</span>
            <span class="p">)</span>
            <span class="k">assert</span> <span class="sa">f</span><span class="s2">&quot;__target__</span><span class="si">{</span><span class="n">target</span><span class="si">}</span><span class="s2">&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">msg</span>
            <span class="n">data</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;__target__</span><span class="si">{</span><span class="n">target</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">target</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">data</span><span class="p">[</span><span class="s2">&quot;__weight__&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">]</span>

        <span class="c1"># train target normalizer</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># fit target normalizer</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span><span class="p">)</span>
            <span class="k">except</span> <span class="n">NotFittedError</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span><span class="p">,</span> <span class="n">EncoderNormalizer</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">])</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span><span class="p">,</span> <span class="p">(</span><span class="n">GroupNormalizer</span><span class="p">,</span> <span class="n">MultiNormalizer</span><span class="p">)</span>
                <span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">],</span> <span class="n">data</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">])</span>

            <span class="c1"># transform target</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span><span class="p">,</span> <span class="n">EncoderNormalizer</span><span class="p">):</span>
                <span class="c1"># we approximate the scales and target transformation by assuming one</span>
                <span class="c1"># transformation over the entire time range but by each group</span>
                <span class="n">common_init_args</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">name</span>
                    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span>
                        <span class="n">GroupNormalizer</span><span class="o">.</span><span class="fm">__init__</span>
                    <span class="p">)</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
                    <span class="k">if</span> <span class="n">name</span>
                    <span class="ow">in</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">EncoderNormalizer</span><span class="o">.</span><span class="fm">__init__</span><span class="p">)</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
                    <span class="ow">and</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="s2">&quot;self&quot;</span><span class="p">]</span>
                <span class="p">]</span>
                <span class="n">copy_kwargs</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="n">name</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">common_init_args</span>
                <span class="p">}</span>
                <span class="n">normalizer</span> <span class="o">=</span> <span class="n">GroupNormalizer</span><span class="p">(</span><span class="n">groups</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">group_ids</span><span class="p">,</span> <span class="o">**</span><span class="n">copy_kwargs</span><span class="p">)</span>
                <span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">],</span> <span class="n">scales</span> <span class="o">=</span> <span class="n">normalizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span>
                    <span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">],</span> <span class="n">data</span><span class="p">,</span> <span class="n">return_norm</span><span class="o">=</span><span class="kc">True</span>
                <span class="p">)</span>

            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span><span class="p">,</span> <span class="n">GroupNormalizer</span><span class="p">):</span>
                <span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">],</span> <span class="n">scales</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span>
                    <span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">],</span> <span class="n">data</span><span class="p">,</span> <span class="n">return_norm</span><span class="o">=</span><span class="kc">True</span>
                <span class="p">)</span>

            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span><span class="p">,</span> <span class="n">MultiNormalizer</span><span class="p">):</span>
                <span class="n">transformed</span><span class="p">,</span> <span class="n">scales</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span>
                    <span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">],</span> <span class="n">data</span><span class="p">,</span> <span class="n">return_norm</span><span class="o">=</span><span class="kc">True</span>
                <span class="p">)</span>

                <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_names</span><span class="p">):</span>
                    <span class="n">data</span><span class="p">[</span><span class="n">target</span><span class="p">]</span> <span class="o">=</span> <span class="n">transformed</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">NaNLabelEncoder</span><span class="p">):</span>
                        <span class="c1"># overwrite target because it requires encoding</span>
                        <span class="c1"># (continuous targets should not be normalized)</span>
                        <span class="n">data</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;__target__</span><span class="si">{</span><span class="n">target</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">target</span><span class="p">]</span>

            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span><span class="p">,</span> <span class="n">NaNLabelEncoder</span><span class="p">):</span>
                <span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">])</span>
                <span class="c1"># overwrite target because it requires encoding</span>
                <span class="c1"># (continuous targets should not be normalized)</span>
                <span class="n">data</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;__target__</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">]</span>
                <span class="n">scales</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">],</span> <span class="n">scales</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span>
                    <span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">],</span> <span class="n">return_norm</span><span class="o">=</span><span class="kc">True</span>
                <span class="p">)</span>

            <span class="c1"># add target scales</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_target_scales</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span><span class="p">,</span> <span class="n">MultiNormalizer</span><span class="p">):</span>
                    <span class="n">scales</span> <span class="o">=</span> <span class="p">[</span><span class="n">scales</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">target_idx</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_names</span><span class="p">):</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">target_normalizers</span><span class="p">[</span><span class="n">target_idx</span><span class="p">],</span> <span class="n">NaNLabelEncoder</span>
                    <span class="p">):</span>
                        <span class="k">for</span> <span class="n">scale_idx</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="s2">&quot;center&quot;</span><span class="p">,</span> <span class="s2">&quot;scale&quot;</span><span class="p">]):</span>
                            <span class="n">feature_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">target</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span>
                            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature_name</span><span class="si">}</span><span class="s2"> is a protected column &quot;</span>
                                <span class="s2">&quot;and must not be present in data&quot;</span>
                            <span class="p">)</span>
                            <span class="k">assert</span> <span class="n">feature_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">msg</span>

                            <span class="n">data</span><span class="p">[</span><span class="n">feature_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">scales</span><span class="p">[</span><span class="n">target_idx</span><span class="p">][</span>
                                <span class="p">:,</span> <span class="n">scale_idx</span>
                            <span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
                            <span class="k">if</span> <span class="n">feature_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reals</span><span class="p">:</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">_static_reals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">feature_name</span><span class="p">)</span>

        <span class="c1"># rescale continuous variables apart from target</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reals</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span> <span class="ow">or</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">lagged_variables</span><span class="p">:</span>
                <span class="c1"># lagged variables are only transformed - not fitted</span>
                <span class="k">continue</span>
            <span class="k">elif</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scalers</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_scalers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">[[</span><span class="n">name</span><span class="p">]])</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scalers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_scalers</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
                <span class="k">except</span> <span class="n">NotFittedError</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_scalers</span><span class="p">[</span><span class="n">name</span><span class="p">],</span> <span class="n">GroupNormalizer</span><span class="p">):</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_scalers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scalers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">name</span><span class="p">],</span> <span class="n">data</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_scalers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scalers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">[[</span><span class="n">name</span><span class="p">]])</span>

        <span class="c1"># encode after fitting</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reals</span><span class="p">:</span>
            <span class="c1"># targets are handled separately</span>
            <span class="n">transformer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_transformer</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span>
                <span class="ow">and</span> <span class="n">transformer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">transformer</span><span class="p">,</span> <span class="n">EncoderNormalizer</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="n">data</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_values</span><span class="p">(</span>
                    <span class="n">name</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="n">name</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">inverse</span><span class="o">=</span><span class="kc">False</span>
                <span class="p">)</span>

        <span class="c1"># encode lagged categorical targets</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">lagged_targets</span><span class="p">:</span>
            <span class="c1"># normalizer only now available</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flat_categoricals</span><span class="p">:</span>
                <span class="n">data</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_values</span><span class="p">(</span>
                    <span class="n">name</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="n">name</span><span class="p">],</span> <span class="n">inverse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ignore_na</span><span class="o">=</span><span class="kc">True</span>
                <span class="p">)</span>

        <span class="c1"># encode constant values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoded_constant_fill_strategy</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constant_fill_strategy</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">encoded_constant_fill_strategy</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;__target__</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">encoded_constant_fill_strategy</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_values</span><span class="p">(</span>
                <span class="n">name</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">value</span><span class="p">]),</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">inverse</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># shorten data by maximum of lagged sequences to avoid NA values -</span>
        <span class="c1"># shorten only after encoding</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># negative tail implementation as .groupby().tail(-self.max_lag)</span>
            <span class="c1"># is not implemented in pandas</span>
            <span class="n">g</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_group_ids</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">_selected_obj</span><span class="p">[</span><span class="n">g</span><span class="o">.</span><span class="n">cumcount</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">data</span>

<div class="viewcode-block" id="TimeSeriesDataSet.get_transformer">
<a class="viewcode-back" href="../../../../api/pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.html#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.get_transformer">[docs]</a>
    <span class="k">def</span> <span class="nf">get_transformer</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">group_id</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">NORMALIZER</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get transformer for variable.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name : str</span>
<span class="sd">            variable name</span>
<span class="sd">        group_id : bool, optional, default=False</span>
<span class="sd">            Whether the passed name refers to a group id,</span>
<span class="sd">            different encoders are used for these.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        transformer: Union[NORMALIZER, Any, None]</span>
<span class="sd">            transformer for variable, None if no transformer is available</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">group_id</span><span class="p">:</span>
            <span class="n">name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_group_ids_mapping</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
        <span class="k">elif</span> <span class="p">(</span>
            <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">lagged_variables</span>
        <span class="p">):</span>  <span class="c1"># recover transformer fitted on non-lagged variable</span>
            <span class="n">name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lagged_variables</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flat_categoricals</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">group_ids</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_group_ids</span><span class="p">:</span>
            <span class="n">name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">variable_to_group_mapping</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>  <span class="c1"># map name to encoder</span>

            <span class="c1"># take target normalizer if required</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span><span class="p">:</span>
                <span class="n">transformer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_normalizers</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target_names</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">name</span><span class="p">)]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">transformer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_categorical_encoders</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">transformer</span>

        <span class="k">elif</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reals</span><span class="p">:</span>
            <span class="c1"># take target normalizer if required</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span><span class="p">:</span>
                <span class="n">transformer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_normalizers</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target_names</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">name</span><span class="p">)]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">transformer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scalers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">transformer</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span></div>


<div class="viewcode-block" id="TimeSeriesDataSet.transform_values">
<a class="viewcode-back" href="../../../../api/pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.html#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.transform_values">[docs]</a>
    <span class="k">def</span> <span class="nf">transform_values</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">values</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
        <span class="n">data</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">inverse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">group_id</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Scale and encode values.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name : str</span>
<span class="sd">            name of variable</span>
<span class="sd">        values : Union[pd.Series, torch.Tensor, np.ndarray]</span>
<span class="sd">            values to encode/scale</span>
<span class="sd">        data : pd.DataFrame, optional, default=None</span>
<span class="sd">            extra data used for scaling (e.g. dataframe with groups columns)</span>
<span class="sd">        inverse : bool, optional, default=False</span>
<span class="sd">            whether transform is plain (True), or inverse (False)</span>
<span class="sd">        group_id : bool, optional, default=False</span>
<span class="sd">            whether the passed name refers to a group id -</span>
<span class="sd">            different encoders are used for these</span>
<span class="sd">        **kwargs: additional arguments for transform/inverse_transform method</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        np.ndarray</span>
<span class="sd">            (de/en)coded/(de)scaled values</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">transformer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_transformer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">group_id</span><span class="o">=</span><span class="n">group_id</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">transformer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">values</span>
        <span class="k">if</span> <span class="n">inverse</span><span class="p">:</span>
            <span class="n">transform</span> <span class="o">=</span> <span class="n">transformer</span><span class="o">.</span><span class="n">inverse_transform</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">transform</span> <span class="o">=</span> <span class="n">transformer</span><span class="o">.</span><span class="n">transform</span>

        <span class="k">if</span> <span class="n">group_id</span><span class="p">:</span>
            <span class="n">name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_group_ids_mapping</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
        <span class="c1"># remaining categories</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flat_categoricals</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">group_ids</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_group_ids</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">transform</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># reals</span>
        <span class="k">elif</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reals</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">transformer</span><span class="p">,</span> <span class="n">GroupNormalizer</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">transform</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">transformer</span><span class="p">,</span> <span class="n">EncoderNormalizer</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">transform</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">):</span>
                    <span class="n">values</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
                    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">transform</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">values</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                    <span class="k">return</span> <span class="n">transform</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">values</span></div>


    <span class="k">def</span> <span class="nf">_data_to_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert data to tensors for faster access with :py:meth:`~__getitem__`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : pd.DataFrame</span>
<span class="sd">            preprocessed data</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict[str, torch.Tensor]</span>
<span class="sd">            dictionary of tensors for continous, categorical data, groups, target and</span>
<span class="sd">            time index</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">_to_tensor</span><span class="p">(</span><span class="n">cols</span><span class="p">,</span> <span class="n">long</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">real</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Convert data[cols] to torch tensor.</span>

<span class="sd">            Converts sub-frames to numpy and then to torch tensor.</span>
<span class="sd">            Makes the following choices for types:</span>

<span class="sd">            - real is True:</span>
<span class="sd">                * the sub-frame is converted to a torch.float32 tensor</span>
<span class="sd">            - long is True (and real is False):</span>
<span class="sd">                * the sub-frame is converted to a torch.long tensor</span>
<span class="sd">            - real is False and long is False:</span>
<span class="sd">                * if all columns are integer or boolean, the sub-frame is</span>
<span class="sd">                  converted to a torch.int64 tensor</span>
<span class="sd">                * if one column is a float, the sub-frame is converted to</span>
<span class="sd">                  a torch.float32 tensor</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cols</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="n">cols</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cols</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">cols</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">dtypekind</span> <span class="o">=</span> <span class="s2">&quot;f&quot;</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cols</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>  <span class="c1"># and len(cols) &gt; 0</span>
                <span class="c1"># dtypekind = data.dtypes[cols[0]].kind</span>
                <span class="n">dtypekind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">result_type</span><span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="p">[</span><span class="n">cols</span><span class="p">]</span><span class="o">.</span><span class="n">dtypes</span><span class="o">.</span><span class="n">to_list</span><span class="p">())</span><span class="o">.</span><span class="n">kind</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">dtypekind</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">dtypes</span><span class="p">[</span><span class="n">cols</span><span class="p">]</span><span class="o">.</span><span class="n">kind</span>
            <span class="k">if</span> <span class="n">real</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">cols</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="n">long</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">cols</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">dtypekind</span> <span class="ow">in</span> <span class="s2">&quot;bi&quot;</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">cols</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">cols</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>

        <span class="n">index</span> <span class="o">=</span> <span class="n">_to_tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_group_ids</span><span class="p">,</span> <span class="n">long</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">time</span> <span class="o">=</span> <span class="n">_to_tensor</span><span class="p">(</span><span class="s2">&quot;__time_idx__&quot;</span><span class="p">,</span> <span class="n">long</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">categorical</span> <span class="o">=</span> <span class="n">_to_tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flat_categoricals</span><span class="p">,</span> <span class="n">long</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">weight</span> <span class="o">=</span> <span class="n">_to_tensor</span><span class="p">(</span><span class="s2">&quot;__weight__&quot;</span><span class="p">)</span>

        <span class="c1"># get target</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span><span class="p">,</span> <span class="n">NaNLabelEncoder</span><span class="p">):</span>
            <span class="n">target</span> <span class="o">=</span> <span class="p">[</span><span class="n">_to_tensor</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;__target__</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>  <span class="c1"># multi-target</span>
                <span class="n">target</span> <span class="o">=</span> <span class="p">[</span><span class="n">_to_tensor</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;__target__</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">target</span> <span class="o">=</span> <span class="p">[</span><span class="n">_to_tensor</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;__target__</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)]</span>

        <span class="c1"># continuous covariates</span>
        <span class="n">continuous</span> <span class="o">=</span> <span class="n">_to_tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reals</span><span class="p">)</span>

        <span class="n">tensors</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
            <span class="n">reals</span><span class="o">=</span><span class="n">continuous</span><span class="p">,</span>
            <span class="n">categoricals</span><span class="o">=</span><span class="n">categorical</span><span class="p">,</span>
            <span class="n">groups</span><span class="o">=</span><span class="n">index</span><span class="p">,</span>
            <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span>
            <span class="n">weight</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span>
            <span class="n">time</span><span class="o">=</span><span class="n">time</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">tensors</span>

    <span class="k">def</span> <span class="nf">_check_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensors</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check for non-finite values in tensors.&quot;&quot;&quot;</span>
        <span class="n">var_names_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;reals&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">reals</span><span class="p">,</span>
            <span class="s2">&quot;categoricals&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">flat_categoricals</span><span class="p">,</span>
            <span class="s2">&quot;groups&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">group_ids</span><span class="p">,</span>
            <span class="s2">&quot;target&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span><span class="p">,</span>
            <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span>
            <span class="s2">&quot;time&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_idx</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">tensors</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">var_names</span> <span class="o">=</span> <span class="n">var_names_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">tensor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">target_tensor</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
                        <span class="n">check_for_nonfinite</span><span class="p">(</span><span class="n">target_tensor</span><span class="p">,</span> <span class="n">var_names</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">check_for_nonfinite</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">var_names</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">categoricals</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Categorical variables as used for modelling.</span>

<span class="sd">        Returns:</span>
<span class="sd">            list[str]: list of variables</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_static_categoricals</span>
            <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_time_varying_known_categoricals</span>
            <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_time_varying_unknown_categoricals</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">flat_categoricals</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Categorical variables as defined in input data.</span>

<span class="sd">        Returns:</span>
<span class="sd">            list[str]: list of variables</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">categories</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">categoricals</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_variable_groups</span><span class="p">:</span>
                <span class="n">categories</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_variable_groups</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">categories</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">categories</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">variable_to_group_mapping</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Mapping from categorical variables to variables in input data.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict[str, str]</span>
<span class="sd">            dictionary, maps :py:meth:`~categorical` to :py:meth:`~flat_categoricals`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">groups</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">group_name</span><span class="p">,</span> <span class="n">sublist</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_variable_groups</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">groups</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="n">name</span><span class="p">:</span> <span class="n">group_name</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">sublist</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">groups</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">reals</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Continous variables as used for modelling.</span>

<span class="sd">        Returns:</span>
<span class="sd">            list[str]: list of variables</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_static_reals</span>
            <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_time_varying_known_reals</span>
            <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_time_varying_unknown_reals</span>
        <span class="p">)</span>

    <span class="nd">@cached_property</span>
    <span class="k">def</span> <span class="nf">target_names</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        List of targets.</span>

<span class="sd">        Returns:</span>
<span class="sd">            list[str]: list of targets</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_target</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">multi_target</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        If dataset encodes one or multiple targets.</span>

<span class="sd">        Returns:</span>
<span class="sd">            bool: true if multiple targets</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">target_normalizers</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">TorchNormalizer</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        List of target normalizers aligned with ``target_names``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            list[TorchNormalizer]: list of target normalizers</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span><span class="p">,</span> <span class="n">MultiNormalizer</span><span class="p">):</span>
            <span class="n">target_normalizers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span><span class="o">.</span><span class="n">normalizers</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">target_normalizers</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">target_normalizers</span>

<div class="viewcode-block" id="TimeSeriesDataSet.get_parameters">
<a class="viewcode-back" href="../../../../api/pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.html#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.get_parameters">[docs]</a>
    <span class="k">def</span> <span class="nf">get_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get parameters of self as dict.</span>

<span class="sd">        These can be used with :py:meth:`~from_parameters`</span>
<span class="sd">        to create a new dataset with the same scalers.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict[str, Any]: dictionary of parameters</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">name</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="fm">__init__</span><span class="p">)</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="s2">&quot;self&quot;</span><span class="p">]</span>
        <span class="p">}</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;categorical_encoders&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_categorical_encoders</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;scalers&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scalers</span>
        <span class="k">return</span> <span class="n">kwargs</span></div>


<div class="viewcode-block" id="TimeSeriesDataSet.from_dataset">
<a class="viewcode-back" href="../../../../api/pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.html#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.from_dataset">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_dataset</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">TimeSeriesDataType</span><span class="p">],</span>
        <span class="n">dataset</span><span class="p">:</span> <span class="n">TimeSeriesDataType</span><span class="p">,</span>
        <span class="n">data</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">stop_randomization</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">predict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">update_kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TimeSeriesDataType</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Construct dataset with different data, same variable encoders, scalers, etc.</span>

<span class="sd">        Calls :py:meth:`~from_parameters` under the hood.</span>

<span class="sd">        May override parameters with update_kwargs.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dataset : TimeSeriesDataSet</span>
<span class="sd">            dataset from which to copy parameters</span>
<span class="sd">        data : pd.DataFrame</span>
<span class="sd">            data from which new dataset will be generated</span>
<span class="sd">        stop_randomization : bool, optional, default=None</span>
<span class="sd">            Whether to stop randomizing encoder and decoder lengths,</span>
<span class="sd">            useful for validation set.</span>
<span class="sd">        predict : bool, optional, default=False</span>
<span class="sd">            Whether to predict the decoder length on the last entries in the</span>
<span class="sd">            time index (i.e. one prediction per group only).</span>
<span class="sd">        **update_kwargs</span>
<span class="sd">            keyword arguments overrides, passed to constructor of the new dataset</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        TimeSeriesDataSet</span>
<span class="sd">            new dataset</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">from_parameters</span><span class="p">(</span>
            <span class="n">dataset</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">(),</span>
            <span class="n">data</span><span class="p">,</span>
            <span class="n">stop_randomization</span><span class="o">=</span><span class="n">stop_randomization</span><span class="p">,</span>
            <span class="n">predict</span><span class="o">=</span><span class="n">predict</span><span class="p">,</span>
            <span class="o">**</span><span class="n">update_kwargs</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="TimeSeriesDataSet.from_parameters">
<a class="viewcode-back" href="../../../../api/pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.html#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.from_parameters">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_parameters</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">TimeSeriesDataType</span><span class="p">],</span>
        <span class="n">parameters</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
        <span class="n">data</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">stop_randomization</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">predict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">update_kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TimeSeriesDataType</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Construct dataset with different data, same variable encoders, scalers, etc.</span>

<span class="sd">        Returns TimeSeriesDataSet with same parameters as self, but different data.</span>
<span class="sd">        May override parameters with update_kwargs.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        parameters : dict[str, Any]</span>
<span class="sd">            dataset parameters which to use for the new dataset</span>
<span class="sd">        data : pd.DataFrame</span>
<span class="sd">            data from which new dataset will be generated</span>
<span class="sd">        stop_randomization : bool, optional, default=None</span>
<span class="sd">            Whether to stop randomizing encoder and decoder lengths,</span>
<span class="sd">            useful for validation set.</span>
<span class="sd">        predict : bool, optional, default=False</span>
<span class="sd">            Whether to predict the decoder length on the last entries in the</span>
<span class="sd">            time index (i.e. one prediction per group only).</span>
<span class="sd">        **update_kwargs</span>
<span class="sd">            keyword arguments overrides, passed to constructor of the new dataset</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        TimeSeriesDataType</span>
<span class="sd">            new dataset</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">parameters</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">predict</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">stop_randomization</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">stop_randomization</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;If predicting, no randomization should be possible - &quot;</span>
                    <span class="s2">&quot;setting stop_randomization=True&quot;</span><span class="p">,</span>
                    <span class="ne">UserWarning</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;min_prediction_length&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;max_prediction_length&quot;</span><span class="p">]</span>
            <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;predict_mode&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># this treats cases for randomize_length randomization:</span>
        <span class="c1"># if predict mode, always turned off, i.e., always stop_ransomization=True</span>
        <span class="c1"># otherwise, None defaults to False</span>
        <span class="n">stop_randomization</span> <span class="o">=</span> <span class="n">predict</span> <span class="ow">or</span> <span class="n">stop_randomization</span>
        <span class="k">if</span> <span class="n">stop_randomization</span><span class="p">:</span>
            <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;randomize_length&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">parameters</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">update_kwargs</span><span class="p">)</span>

        <span class="n">new</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">parameters</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new</span></div>


    <span class="k">def</span> <span class="nf">_construct_index</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">predict_mode</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create index of samples returned by getitem dunder.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : pd.DataFrame</span>
<span class="sd">            preprocessed data</span>
<span class="sd">        predict_mode : bool</span>
<span class="sd">            whether to create one sample per group</span>
<span class="sd">            with prediction length equals ``max_decoder_length``</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        pd.DataFrame</span>
<span class="sd">            index dataframe for timesteps and index dataframe for groups.</span>
<span class="sd">            It contains a list of all possible subsequences.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_group_ids</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">df_index_first</span> <span class="o">=</span> <span class="n">g</span><span class="p">[</span><span class="s2">&quot;__time_idx__&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="s2">&quot;first&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to_frame</span><span class="p">(</span><span class="s2">&quot;time_first&quot;</span><span class="p">)</span>
        <span class="n">df_index_last</span> <span class="o">=</span> <span class="n">g</span><span class="p">[</span><span class="s2">&quot;__time_idx__&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="s2">&quot;last&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to_frame</span><span class="p">(</span><span class="s2">&quot;time_last&quot;</span><span class="p">)</span>
        <span class="n">df_index_diff_to_next</span> <span class="o">=</span> <span class="p">(</span>
            <span class="o">-</span><span class="n">g</span><span class="p">[</span><span class="s2">&quot;__time_idx__&quot;</span><span class="p">]</span>
            <span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
            <span class="o">.</span><span class="n">to_frame</span><span class="p">(</span><span class="s2">&quot;time_diff_to_next&quot;</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">df_index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
            <span class="p">[</span><span class="n">df_index_first</span><span class="p">,</span> <span class="n">df_index_last</span><span class="p">,</span> <span class="n">df_index_diff_to_next</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">)</span>
        <span class="n">df_index</span><span class="p">[</span><span class="s2">&quot;index_start&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df_index</span><span class="p">))</span>
        <span class="n">df_index</span><span class="p">[</span><span class="s2">&quot;time&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;__time_idx__&quot;</span><span class="p">]</span>
        <span class="n">df_index</span><span class="p">[</span><span class="s2">&quot;count&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_index</span><span class="p">[</span><span class="s2">&quot;time_last&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">df_index</span><span class="p">[</span><span class="s2">&quot;time_first&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span>
            <span class="nb">int</span>
        <span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">sequence_ids</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">ngroup</span><span class="p">()</span>
        <span class="n">df_index</span><span class="p">[</span><span class="s2">&quot;sequence_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sequence_ids</span>

        <span class="n">min_sequence_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_prediction_length</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_encoder_length</span>
        <span class="n">max_sequence_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_prediction_length</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_encoder_length</span>

        <span class="c1"># calculate maximum index to include from current index_start</span>
        <span class="n">max_time</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_index</span><span class="p">[</span><span class="s2">&quot;time&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">max_sequence_length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span>
            <span class="n">upper</span><span class="o">=</span><span class="n">df_index</span><span class="p">[</span><span class="s2">&quot;count&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">df_index</span><span class="o">.</span><span class="n">time_first</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="p">)</span>

        <span class="c1"># if there are missing timesteps, we cannot say directly what</span>
        <span class="c1"># is the last timestep to include</span>
        <span class="c1"># therefore we iterate until it is found</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">df_index</span><span class="p">[</span><span class="s2">&quot;time_diff_to_next&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="s2">&quot;Time difference between steps has been idenfied as larger than 1 - &quot;</span>
                <span class="s2">&quot;set allow_missing_timesteps=True&quot;</span>
            <span class="p">)</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">allow_missing_timesteps</span><span class="p">,</span> <span class="n">msg</span>

        <span class="n">df_index</span><span class="p">[</span><span class="s2">&quot;index_end&quot;</span><span class="p">],</span> <span class="n">missing_sequences</span> <span class="o">=</span> <span class="n">_find_end_indices</span><span class="p">(</span>
            <span class="n">diffs</span><span class="o">=</span><span class="n">df_index</span><span class="o">.</span><span class="n">time_diff_to_next</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span>
            <span class="n">max_lengths</span><span class="o">=</span><span class="p">(</span><span class="n">max_time</span> <span class="o">-</span> <span class="n">df_index</span><span class="o">.</span><span class="n">time</span><span class="p">)</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">min_length</span><span class="o">=</span><span class="n">min_sequence_length</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># add duplicates but mostly with shorter sequence length for start of timeseries</span>
        <span class="c1"># while the previous steps have ensured that we start a sequence on every time</span>
        <span class="c1"># step, the missing_sequences</span>
        <span class="c1"># ensure that there is a sequence that finishes on every timestep</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">missing_sequences</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">shortened_sequences</span> <span class="o">=</span> <span class="n">df_index</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">missing_sequences</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
                <span class="n">index_end</span><span class="o">=</span><span class="n">missing_sequences</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="p">)</span>

            <span class="c1"># concatenate shortened sequences</span>
            <span class="n">df_index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
                <span class="p">[</span><span class="n">df_index</span><span class="p">,</span> <span class="n">shortened_sequences</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>

        <span class="c1"># filter out where encode and decode length are not satisfied</span>
        <span class="n">df_index</span><span class="p">[</span><span class="s2">&quot;sequence_length&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">df_index</span><span class="p">[</span><span class="s2">&quot;time&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">df_index</span><span class="p">[</span><span class="s2">&quot;index_end&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
            <span class="o">-</span> <span class="n">df_index</span><span class="p">[</span><span class="s2">&quot;time&quot;</span><span class="p">]</span>
            <span class="o">+</span> <span class="mi">1</span>
        <span class="p">)</span>

        <span class="c1"># filter too short sequences</span>
        <span class="n">df_index</span> <span class="o">=</span> <span class="n">df_index</span><span class="p">[</span>
            <span class="c1"># sequence must be at least of minimal prediction length</span>
            <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">sequence_length</span> <span class="o">&gt;=</span> <span class="n">min_sequence_length</span><span class="p">)</span>
            <span class="o">&amp;</span>
            <span class="c1"># prediction must be for minimal prediction index + length of prediction</span>
            <span class="p">(</span>
                <span class="n">x</span><span class="p">[</span><span class="s2">&quot;sequence_length&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;time&quot;</span><span class="p">]</span>
                <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_prediction_idx</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_prediction_length</span>
            <span class="p">)</span>
        <span class="p">]</span>

        <span class="k">if</span> <span class="n">predict_mode</span><span class="p">:</span>
            <span class="c1"># keep longest element per series</span>
            <span class="c1"># (i.e., the first element that spans to the end of the series)</span>
            <span class="c1"># filter all elements that are longer</span>
            <span class="c1"># than the allowed maximum sequence length</span>
            <span class="n">df_index</span> <span class="o">=</span> <span class="n">df_index</span><span class="p">[</span>
                <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;time_last&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;time&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">&lt;=</span> <span class="n">max_sequence_length</span><span class="p">)</span>
                <span class="o">&amp;</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;sequence_length&quot;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">min_sequence_length</span><span class="p">)</span>
            <span class="p">]</span>
            <span class="c1"># choose longest sequence</span>
            <span class="n">df_index</span> <span class="o">=</span> <span class="n">df_index</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span>
                <span class="n">df_index</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;sequence_id&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sequence_length</span><span class="o">.</span><span class="n">idxmax</span><span class="p">()</span>
            <span class="p">]</span>

        <span class="c1"># check that all groups/series have at least one entry in the index</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">sequence_ids</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">df_index</span><span class="o">.</span><span class="n">sequence_id</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
            <span class="n">missing_groups</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span>
                <span class="o">~</span><span class="n">sequence_ids</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">df_index</span><span class="o">.</span><span class="n">sequence_id</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_group_ids</span>
            <span class="p">]</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">()</span>
            <span class="c1"># decode values</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="nb">id</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_group_ids_mapping</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">missing_groups</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_values</span><span class="p">(</span>
                    <span class="n">name</span><span class="p">,</span> <span class="n">missing_groups</span><span class="p">[</span><span class="nb">id</span><span class="p">],</span> <span class="n">inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">group_id</span><span class="o">=</span><span class="kc">True</span>
                <span class="p">)</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Min encoder length and/or min_prediction_idx and/or min &quot;</span>
                <span class="s2">&quot;prediction length and/or lags are too large for &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">missing_groups</span><span class="p">)</span><span class="si">}</span><span class="s2"> series/groups which therefore are not present&quot;</span>
                <span class="s2">&quot; in the dataset index. &quot;</span>
                <span class="s2">&quot;This means no predictions can be made for those series. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;First 10 removed groups: &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">missing_groups</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(</span><span class="n">orient</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="ne">UserWarning</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="s2">&quot;filters should not remove entries all entries - &quot;</span>
            <span class="s2">&quot;check encoder/decoder lengths and lags&quot;</span>
        <span class="p">)</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">df_index</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">msg</span>

        <span class="n">minimal_columns</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;index_start&quot;</span><span class="p">,</span>
            <span class="s2">&quot;index_end&quot;</span><span class="p">,</span>
            <span class="s2">&quot;sequence_length&quot;</span><span class="p">,</span>
            <span class="s2">&quot;time&quot;</span><span class="p">,</span>
            <span class="s2">&quot;sequence_id&quot;</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="n">predict_mode</span> <span class="ow">and</span> <span class="s2">&quot;sequence_id&quot;</span> <span class="ow">in</span> <span class="n">df_index</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
            <span class="n">minimal_columns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;sequence_id&quot;</span><span class="p">)</span>

        <span class="n">df_index</span> <span class="o">=</span> <span class="n">df_index</span><span class="p">[</span><span class="n">minimal_columns</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;int32&quot;</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">df_index</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<div class="viewcode-block" id="TimeSeriesDataSet.filter">
<a class="viewcode-back" href="../../../../api/pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.html#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.filter">[docs]</a>
    <span class="k">def</span> <span class="nf">filter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filter_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">copy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TimeSeriesDataType</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Filter subsequences in dataset.</span>

<span class="sd">        Uses interpretable version of index :py:meth:`~decoded_index`</span>
<span class="sd">        to filter subsequences in dataset.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        filter_func : Callable</span>
<span class="sd">            function to filter. Should take :py:meth:`~decoded_index`</span>
<span class="sd">            dataframe as only argument which contains group ids and time index columns.</span>
<span class="sd">        copy : bool, optional, default=True</span>
<span class="sd">            whether to return copy of dataset (True) or filter inplace (False).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        TimeSeriesDataSet</span>
<span class="sd">            filtered dataset</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># calculate filter</span>
        <span class="n">filtered_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">filter_func</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoded_index</span><span class="p">))]</span>
        <span class="c1"># raise error if filter removes all entries</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">filtered_index</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;After applying filter no sub-sequences left in dataset&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">copy</span><span class="p">:</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">_copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="n">dataset</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">filtered_index</span>
            <span class="k">return</span> <span class="n">dataset</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">filtered_index</span>
            <span class="k">return</span> <span class="bp">self</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">decoded_index</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get interpretable version of index.</span>

<span class="sd">        DataFrame contains</span>
<span class="sd">        - group_id columns in original encoding</span>
<span class="sd">        - time_idx_first column: first time index of subsequence</span>
<span class="sd">        - time_idx_last columns: last time index of subsequence</span>
<span class="sd">        - time_idx_first_prediction columns: first time index which is in decoder</span>

<span class="sd">        Returns:</span>
<span class="sd">            pd.DataFrame: index that can be understood in terms of original data</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># get dataframe to filter</span>
        <span class="n">index_start</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="s2">&quot;index_start&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
        <span class="n">index_last</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="s2">&quot;index_end&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
        <span class="n">index</span> <span class="o">=</span> <span class="p">(</span>
            <span class="c1"># get group ids in order of index</span>
            <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;groups&quot;</span><span class="p">][</span><span class="n">index_start</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">group_ids</span>
            <span class="p">)</span>
            <span class="c1"># to original values</span>
            <span class="o">.</span><span class="n">apply</span><span class="p">(</span>
                <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_values</span><span class="p">(</span>
                    <span class="n">name</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">group_id</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inverse</span><span class="o">=</span><span class="kc">True</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="c1"># add time index</span>
            <span class="o">.</span><span class="n">assign</span><span class="p">(</span>
                <span class="n">time_idx_first</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;time&quot;</span><span class="p">][</span><span class="n">index_start</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
                <span class="n">time_idx_last</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;time&quot;</span><span class="p">][</span><span class="n">index_last</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
                <span class="c1"># prediction index is last time index - decoder length + 1</span>
                <span class="n">time_idx_first_prediction</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">time_idx_last</span>
                <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">calculate_decoder_length</span><span class="p">(</span>
                    <span class="n">time_last</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">time_idx_last</span><span class="p">,</span>
                    <span class="n">sequence_length</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">time_idx_last</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">time_idx_first</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">index</span>

<div class="viewcode-block" id="TimeSeriesDataSet.plot_randomization">
<a class="viewcode-back" href="../../../../api/pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.html#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.plot_randomization">[docs]</a>
    <span class="k">def</span> <span class="nf">plot_randomization</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">betas</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">min_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Plot expected randomized length distribution.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        betas : tuple[float, float], optional, default=randomize_length of dataset</span>
<span class="sd">            Tuple of betas, e.g. ``(0.2, 0.05)`` to use for randomization.</span>
<span class="sd">        length : int, optional, default=max_encoder_length of dataset</span>
<span class="sd">            Length of sequence to plot.</span>
<span class="sd">        min_length : int, optional, default=min_encoder_length of dataset</span>
<span class="sd">            Minimum length of sequence to plot.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tuple[plt.Figure, torch.Tensor]</span>
<span class="sd">            tuple of figure and histogram based on 1000 samples</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_check_matplotlib</span><span class="p">(</span><span class="s2">&quot;plot_randomization&quot;</span><span class="p">)</span>

        <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

        <span class="k">if</span> <span class="n">betas</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">betas</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">randomize_length</span>
        <span class="k">if</span> <span class="n">length</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_encoder_length</span>
        <span class="k">if</span> <span class="n">min_length</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">min_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_encoder_length</span>
        <span class="n">probabilities</span> <span class="o">=</span> <span class="n">Beta</span><span class="p">(</span><span class="n">betas</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">betas</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">1000</span><span class="p">,))</span>

        <span class="n">lengths</span> <span class="o">=</span> <span class="p">((</span><span class="n">length</span> <span class="o">-</span> <span class="n">min_length</span><span class="p">)</span> <span class="o">*</span> <span class="n">probabilities</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">()</span> <span class="o">+</span> <span class="n">min_length</span>

        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">lengths</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">lengths</span></div>


    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Length of dataset.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int: length</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<div class="viewcode-block" id="TimeSeriesDataSet.set_overwrite_values">
<a class="viewcode-back" href="../../../../api/pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.html#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.set_overwrite_values">[docs]</a>
    <span class="k">def</span> <span class="nf">set_overwrite_values</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">values</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">variable</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">target</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">slice</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;decoder&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Overwrite values in decoder or encoder (or both) for a specific variable.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        values : Union[float, torch.Tensor]</span>
<span class="sd">            values to use for overwrite.</span>
<span class="sd">        variable : str</span>
<span class="sd">            variable whose values should be overwritten.</span>
<span class="sd">        target : Union[str, slice], optional)</span>
<span class="sd">            positions to overwrite. One of &quot;decoder&quot;, &quot;encoder&quot; or &quot;all&quot; or</span>
<span class="sd">            a slice object which is directly used to overwrite indices,</span>
<span class="sd">            e.g., ``slice(-5, None)`` will overwrite</span>
<span class="sd">            the last 5 values. Defaults to &quot;decoder&quot;.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transform_values</span><span class="p">(</span>
                <span class="n">variable</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">values</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">inverse</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
        <span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;target has be one of &#39;all&#39;, &#39;decoder&#39; or &#39;encoder&#39; &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;but got target=</span><span class="si">{</span><span class="n">target</span><span class="si">}</span><span class="s2"> instead&quot;</span>
        <span class="p">)</span>
        <span class="k">assert</span> <span class="n">target</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;all&quot;</span><span class="p">,</span> <span class="s2">&quot;decoder&quot;</span><span class="p">,</span> <span class="s2">&quot;encoder&quot;</span><span class="p">],</span> <span class="n">msg</span>

        <span class="k">if</span> <span class="n">variable</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_static_categoricals</span> <span class="ow">or</span> <span class="n">variable</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_static_reals</span><span class="p">:</span>
            <span class="n">target</span> <span class="o">=</span> <span class="s2">&quot;all&quot;</span>

        <span class="k">if</span> <span class="n">variable</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Target variable is not supported&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">==</span> <span class="n">variable</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Weight variable is not supported&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_scalers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">variable</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_categorical_encoders</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">variable</span><span class="p">)),</span>
            <span class="n">TorchNormalizer</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;TorchNormalizer (e.g. GroupNormalizer) is not supported&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_overwrite_values</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_overwrite_values</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_overwrite_values</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="nb">dict</span><span class="p">(</span><span class="n">values</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">variable</span><span class="o">=</span><span class="n">variable</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">)</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="TimeSeriesDataSet.reset_overwrite_values">
<a class="viewcode-back" href="../../../../api/pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.html#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.reset_overwrite_values">[docs]</a>
    <span class="k">def</span> <span class="nf">reset_overwrite_values</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Reset values used to override sample features.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_overwrite_values</span> <span class="o">=</span> <span class="kc">None</span></div>


<div class="viewcode-block" id="TimeSeriesDataSet.calculate_decoder_length">
<a class="viewcode-back" href="../../../../api/pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.html#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.calculate_decoder_length">[docs]</a>
    <span class="k">def</span> <span class="nf">calculate_decoder_length</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">time_last</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
        <span class="n">sequence_length</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calculate length of decoder.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        time_last : Union[int, pd.Series, np.ndarray]</span>
<span class="sd">            last time index of the sequence</span>
<span class="sd">        sequence_length : Union[int, pd.Series, np.ndarray]</span>
<span class="sd">            total length of the sequence</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Union[int, pd.Series, np.ndarray]</span>
<span class="sd">            decoder length(s)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">time_last</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">decoder_length</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span>
                <span class="n">time_last</span>
                <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">min_prediction_idx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>  <span class="c1"># not going beyond min prediction idx</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">max_prediction_length</span><span class="p">,</span>  <span class="c1"># maximum prediction length</span>
                <span class="n">sequence_length</span>
                <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_encoder_length</span><span class="p">,</span>  <span class="c1"># sequence length - min decoder length</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">decoder_length</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">time_last</span> <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">min_prediction_idx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>
                    <span class="n">sequence_length</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_encoder_length</span><span class="p">,</span>
                <span class="p">],</span>
                <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="p">)</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="nb">max</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_prediction_length</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">decoder_length</span></div>


    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get sample for model</span>

<span class="sd">        Args:</span>
<span class="sd">            idx (int): index of prediction (between ``0`` and ``len(dataset) - 1``)</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple[dict[str, torch.Tensor], torch.Tensor]: x and y for model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

        <span class="c1"># slice data based on index</span>
        <span class="n">idx_slice</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="n">index</span><span class="o">.</span><span class="n">index_start</span><span class="p">,</span> <span class="n">index</span><span class="o">.</span><span class="n">index_end</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">data_cont</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;reals&quot;</span><span class="p">][</span><span class="n">idx_slice</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">data_cat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;categoricals&quot;</span><span class="p">][</span><span class="n">idx_slice</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">time</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;time&quot;</span><span class="p">][</span><span class="n">idx_slice</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">target</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span><span class="p">[</span><span class="n">idx_slice</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]]</span>
        <span class="n">groups</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;groups&quot;</span><span class="p">][</span><span class="n">index</span><span class="o">.</span><span class="n">index_start</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">][</span><span class="n">idx_slice</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="c1"># get target scale in the form of a list</span>
        <span class="n">target_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">(</span><span class="n">groups</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">group_ids</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_normalizer</span><span class="p">,</span> <span class="n">MultiNormalizer</span><span class="p">):</span>
            <span class="n">target_scale</span> <span class="o">=</span> <span class="p">[</span><span class="n">target_scale</span><span class="p">]</span>

        <span class="c1"># fill in missing values (if not all time indices are specified)</span>
        <span class="n">sequence_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">sequence_length</span> <span class="o">&lt;</span> <span class="n">index</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">:</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">allow_missing_timesteps</span>
            <span class="p">),</span> <span class="s2">&quot;allow_missing_timesteps should be True if sequences have gaps&quot;</span>
            <span class="n">repetitions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                <span class="p">[</span><span class="n">time</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">time</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">dtype</span><span class="p">)]</span>
            <span class="p">)</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">time</span><span class="p">)),</span> <span class="n">repetitions</span><span class="p">)</span>
            <span class="n">repetition_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="kc">False</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">),</span> <span class="n">indices</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">==</span> <span class="n">indices</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
            <span class="p">)</span>

            <span class="c1"># select data</span>
            <span class="n">data_cat</span> <span class="o">=</span> <span class="n">data_cat</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
            <span class="n">data_cont</span> <span class="o">=</span> <span class="n">data_cont</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
            <span class="n">target</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">target</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>

            <span class="c1"># reset index</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_idx</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reals</span><span class="p">:</span>
                <span class="n">time_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reals</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">time_idx</span><span class="p">)</span>
                <span class="n">data_cont</span><span class="p">[:,</span> <span class="n">time_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span>
                    <span class="n">data_cont</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">time_idx</span><span class="p">],</span>
                    <span class="n">data_cont</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">time_idx</span><span class="p">],</span>
                    <span class="nb">len</span><span class="p">(</span><span class="n">target</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">data_cont</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                <span class="p">)</span>

            <span class="c1"># make replacements to fill in categories</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoded_constant_fill_strategy</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reals</span><span class="p">:</span>
                    <span class="n">data_cont</span><span class="p">[</span><span class="n">repetition_indices</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reals</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">name</span><span class="p">)]</span> <span class="o">=</span> <span class="n">value</span>
                <span class="k">elif</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span>
                    <span class="sa">f</span><span class="s2">&quot;__target__</span><span class="si">{</span><span class="n">target_name</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">target_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span>
                <span class="p">]:</span>
                    <span class="n">target_pos</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">name</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="s2">&quot;__target__&quot;</span><span class="p">)</span> <span class="p">:])</span>
                    <span class="n">target</span><span class="p">[</span><span class="n">target_pos</span><span class="p">][</span><span class="n">repetition_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
                <span class="k">elif</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flat_categoricals</span><span class="p">:</span>
                    <span class="n">data_cat</span><span class="p">[</span><span class="n">repetition_indices</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">flat_categoricals</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">name</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">value</span>
                    <span class="p">)</span>
                <span class="k">elif</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span><span class="p">:</span>  <span class="c1"># target is just not an input value</span>
                    <span class="k">pass</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Variable </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> is not known and thus cannot be filled in&quot;</span>
                    <span class="p">)</span>

            <span class="n">sequence_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">target</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># determine data window</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">sequence_length</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_prediction_length</span>
        <span class="p">),</span> <span class="s2">&quot;Sequence length should be at least minimum prediction length&quot;</span>
        <span class="c1"># determine prediction/decode length and encode length</span>
        <span class="n">decoder_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">calculate_decoder_length</span><span class="p">(</span><span class="n">time</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">sequence_length</span><span class="p">)</span>
        <span class="n">encoder_length</span> <span class="o">=</span> <span class="n">sequence_length</span> <span class="o">-</span> <span class="n">decoder_length</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">decoder_length</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_prediction_length</span>
        <span class="p">),</span> <span class="s2">&quot;Decoder length should be at least minimum prediction length&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">encoder_length</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_encoder_length</span>
        <span class="p">),</span> <span class="s2">&quot;Encoder length should be at least minimum encoder length&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">randomize_length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># randomization improves generalization</span>
            <span class="c1"># modify encode and decode lengths</span>
            <span class="n">modifiable_encoder_length</span> <span class="o">=</span> <span class="n">encoder_length</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_encoder_length</span>
            <span class="n">encoder_length_probability</span> <span class="o">=</span> <span class="n">Beta</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">randomize_length</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">randomize_length</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>

            <span class="c1"># subsample a new/smaller encode length</span>
            <span class="n">new_encoder_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_encoder_length</span> <span class="o">+</span> <span class="nb">int</span><span class="p">(</span>
                <span class="p">(</span><span class="n">modifiable_encoder_length</span> <span class="o">*</span> <span class="n">encoder_length_probability</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">()</span>
            <span class="p">)</span>

            <span class="c1"># extend decode length if possible</span>
            <span class="n">new_decoder_length</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span>
                <span class="n">decoder_length</span> <span class="o">+</span> <span class="p">(</span><span class="n">encoder_length</span> <span class="o">-</span> <span class="n">new_encoder_length</span><span class="p">),</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">max_prediction_length</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># select subset of sequence of new sequence</span>
            <span class="k">if</span> <span class="n">new_encoder_length</span> <span class="o">+</span> <span class="n">new_decoder_length</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">target</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="n">data_cat</span> <span class="o">=</span> <span class="n">data_cat</span><span class="p">[</span>
                    <span class="n">encoder_length</span> <span class="o">-</span> <span class="n">new_encoder_length</span> <span class="p">:</span> <span class="n">encoder_length</span>
                    <span class="o">+</span> <span class="n">new_decoder_length</span>
                <span class="p">]</span>
                <span class="n">data_cont</span> <span class="o">=</span> <span class="n">data_cont</span><span class="p">[</span>
                    <span class="n">encoder_length</span> <span class="o">-</span> <span class="n">new_encoder_length</span> <span class="p">:</span> <span class="n">encoder_length</span>
                    <span class="o">+</span> <span class="n">new_decoder_length</span>
                <span class="p">]</span>
                <span class="n">target</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">t</span><span class="p">[</span>
                        <span class="n">encoder_length</span> <span class="o">-</span> <span class="n">new_encoder_length</span> <span class="p">:</span> <span class="n">encoder_length</span>
                        <span class="o">+</span> <span class="n">new_decoder_length</span>
                    <span class="p">]</span>
                    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">target</span>
                <span class="p">]</span>
                <span class="k">if</span> <span class="n">weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span><span class="p">[</span>
                        <span class="n">encoder_length</span> <span class="o">-</span> <span class="n">new_encoder_length</span> <span class="p">:</span> <span class="n">encoder_length</span>
                        <span class="o">+</span> <span class="n">new_decoder_length</span>
                    <span class="p">]</span>
                <span class="n">encoder_length</span> <span class="o">=</span> <span class="n">new_encoder_length</span>
                <span class="n">decoder_length</span> <span class="o">=</span> <span class="n">new_decoder_length</span>

            <span class="c1"># switch some variables to nan if encode length is 0</span>
            <span class="k">if</span> <span class="n">encoder_length</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout_categoricals</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">data_cat</span><span class="p">[</span>
                    <span class="p">:,</span>
                    <span class="p">[</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">flat_categoricals</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_categoricals</span>
                    <span class="p">],</span>
                <span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># zero is encoded nan</span>

        <span class="k">assert</span> <span class="n">decoder_length</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Decoder length should be greater than 0&quot;</span>
        <span class="k">assert</span> <span class="n">encoder_length</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Encoder length should be at least 0&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_relative_time_idx</span><span class="p">:</span>
            <span class="n">data_cont</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reals</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;relative_time_idx&quot;</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="n">encoder_length</span><span class="p">,</span> <span class="n">decoder_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">data_cont</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
                <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_encoder_length</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_encoder_length</span><span class="p">:</span>
            <span class="n">data_cont</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reals</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;encoder_length&quot;</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="p">(</span><span class="n">encoder_length</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_encoder_length</span><span class="p">)</span>
                <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_encoder_length</span>
                <span class="o">*</span> <span class="mf">2.0</span>
            <span class="p">)</span>

        <span class="c1"># rescale target</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">target_normalizer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_normalizers</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">target_normalizer</span><span class="p">,</span> <span class="n">EncoderNormalizer</span><span class="p">):</span>
                <span class="n">target_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
                <span class="c1"># fit and transform</span>
                <span class="n">target_normalizer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">target</span><span class="p">[</span><span class="n">idx</span><span class="p">][:</span><span class="n">encoder_length</span><span class="p">])</span>
                <span class="c1"># get new scale</span>
                <span class="n">single_target_scale</span> <span class="o">=</span> <span class="n">target_normalizer</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()</span>
                <span class="c1"># modify input data</span>
                <span class="k">if</span> <span class="n">target_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reals</span><span class="p">:</span>
                    <span class="n">data_cont</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reals</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">target_name</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">target_normalizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">target</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
                    <span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_target_scales</span><span class="p">:</span>
                    <span class="n">data_cont</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reals</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">target_name</span><span class="si">}</span><span class="s2">_center&quot;</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">transform_values</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">target_name</span><span class="si">}</span><span class="s2">_center&quot;</span><span class="p">,</span> <span class="n">single_target_scale</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                        <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="p">)</span>
                    <span class="n">data_cont</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reals</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">target_name</span><span class="si">}</span><span class="s2">_scale&quot;</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">transform_values</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">target_name</span><span class="si">}</span><span class="s2">_scale&quot;</span><span class="p">,</span> <span class="n">single_target_scale</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                        <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="p">)</span>
                <span class="c1"># scale needs to be numpy to be consistent with GroupNormalizer</span>
                <span class="n">target_scale</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">single_target_scale</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

        <span class="c1"># rescale covariates</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reals</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span> <span class="ow">and</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">lagged_variables</span><span class="p">:</span>
                <span class="n">normalizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_transformer</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">normalizer</span><span class="p">,</span> <span class="n">EncoderNormalizer</span><span class="p">):</span>
                    <span class="c1"># fit and transform</span>
                    <span class="n">pos</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reals</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
                    <span class="n">normalizer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data_cont</span><span class="p">[:</span><span class="n">encoder_length</span><span class="p">,</span> <span class="n">pos</span><span class="p">])</span>
                    <span class="c1"># transform</span>
                    <span class="n">data_cont</span><span class="p">[:,</span> <span class="n">pos</span><span class="p">]</span> <span class="o">=</span> <span class="n">normalizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data_cont</span><span class="p">[:,</span> <span class="n">pos</span><span class="p">])</span>

        <span class="c1"># also normalize lagged variables</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reals</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">lagged_variables</span><span class="p">:</span>
                <span class="n">normalizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_transformer</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">normalizer</span><span class="p">,</span> <span class="n">EncoderNormalizer</span><span class="p">):</span>
                    <span class="n">pos</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reals</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
                    <span class="n">data_cont</span><span class="p">[:,</span> <span class="n">pos</span><span class="p">]</span> <span class="o">=</span> <span class="n">normalizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data_cont</span><span class="p">[:,</span> <span class="n">pos</span><span class="p">])</span>

        <span class="c1"># overwrite values</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_overwrite_values</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_overwrite_values</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">],</span> <span class="nb">slice</span><span class="p">):</span>
                <span class="n">positions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_overwrite_values</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_overwrite_values</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;all&quot;</span><span class="p">:</span>
                <span class="n">positions</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_overwrite_values</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;encoder&quot;</span><span class="p">:</span>
                <span class="n">positions</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">encoder_length</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># decoder</span>
                <span class="n">positions</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="n">encoder_length</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_overwrite_values</span><span class="p">[</span><span class="s2">&quot;variable&quot;</span><span class="p">]</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reals</span><span class="p">:</span>
                <span class="n">idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reals</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_overwrite_values</span><span class="p">[</span><span class="s2">&quot;variable&quot;</span><span class="p">])</span>
                <span class="n">data_cont</span><span class="p">[</span><span class="n">positions</span><span class="p">,</span> <span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_overwrite_values</span><span class="p">[</span><span class="s2">&quot;values&quot;</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="s2">&quot;overwrite values variable has to be &quot;</span>
                    <span class="s2">&quot;either in real or categorical variables&quot;</span>
                <span class="p">)</span>
                <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_overwrite_values</span><span class="p">[</span><span class="s2">&quot;variable&quot;</span><span class="p">]</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flat_categoricals</span><span class="p">,</span> <span class="n">msg</span>
                <span class="n">idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flat_categoricals</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_overwrite_values</span><span class="p">[</span><span class="s2">&quot;variable&quot;</span><span class="p">])</span>
                <span class="n">data_cat</span><span class="p">[</span><span class="n">positions</span><span class="p">,</span> <span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_overwrite_values</span><span class="p">[</span><span class="s2">&quot;values&quot;</span><span class="p">]</span>

        <span class="c1"># weight is only required for decoder</span>
        <span class="k">if</span> <span class="n">weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span><span class="p">[</span><span class="n">encoder_length</span><span class="p">:]</span>

        <span class="c1"># if user defined target as list, output should be list, otherwise tensor</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_target</span><span class="p">:</span>
            <span class="n">encoder_target</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span><span class="p">[:</span><span class="n">encoder_length</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">target</span><span class="p">]</span>
            <span class="n">target</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span><span class="p">[</span><span class="n">encoder_length</span><span class="p">:]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">target</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">encoder_target</span> <span class="o">=</span> <span class="n">target</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="n">encoder_length</span><span class="p">]</span>
            <span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">encoder_length</span><span class="p">:]</span>
            <span class="n">target_scale</span> <span class="o">=</span> <span class="n">target_scale</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">return</span> <span class="p">(</span>
            <span class="nb">dict</span><span class="p">(</span>
                <span class="n">x_cat</span><span class="o">=</span><span class="n">data_cat</span><span class="p">,</span>
                <span class="n">x_cont</span><span class="o">=</span><span class="n">data_cont</span><span class="p">,</span>
                <span class="n">encoder_length</span><span class="o">=</span><span class="n">encoder_length</span><span class="p">,</span>
                <span class="n">decoder_length</span><span class="o">=</span><span class="n">decoder_length</span><span class="p">,</span>
                <span class="n">encoder_target</span><span class="o">=</span><span class="n">encoder_target</span><span class="p">,</span>
                <span class="n">encoder_time_idx_start</span><span class="o">=</span><span class="n">time</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">,</span>
                <span class="n">target_scale</span><span class="o">=</span><span class="n">target_scale</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_collate_fn</span><span class="p">(</span>
        <span class="n">batches</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Collate function to combine items into mini-batch for dataloader.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        batches (list[tuple[dict[str, torch.Tensor], torch.Tensor]]):</span>
<span class="sd">            List of samples generated with :py:meth:`~__getitem__`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict[str, torch.Tensor]</span>
<span class="sd">            dictionary of minibatches with keys:</span>

<span class="sd">            * encoder_cat: (batch_size, encoder_length, num_categorical),</span>
<span class="sd">                categorical variables for encoder</span>
<span class="sd">            * encoder_cont: (batch_size, encoder_length, num_real),</span>
<span class="sd">                continuous variables for encoder</span>
<span class="sd">            * encoder_target: (batch_size, encoder_length, num_target),</span>
<span class="sd">                target variables for encoder</span>
<span class="sd">            * encoder_lengths: (batch_size), length of encoder</span>
<span class="sd">            * decoder_cat: (batch_size, decoder_length, num_categorical),</span>
<span class="sd">                categorical variables for decoder</span>
<span class="sd">            * decoder_cont: (batch_size, decoder_length, num_real),</span>
<span class="sd">                continuous variables for decoder</span>
<span class="sd">            * decoder_target: (batch_size, decoder_length, num_target),</span>
<span class="sd">                target variables for decoder</span>
<span class="sd">            * decoder_lengths: (batch_size), length of decoder</span>
<span class="sd">            * decoder_time_idx: (batch_size, decoder_length),</span>
<span class="sd">                time index for decoder</span>
<span class="sd">            * groups: (batch_size), group ids</span>
<span class="sd">            * target_scale: (batch_size, num_target),</span>
<span class="sd">                scale of target variables</span>

<span class="sd">        tuple[torch.Tensor, torch.Tensor]</span>
<span class="sd">            minibatch, 2-tuple with entries:</span>

<span class="sd">            * target: (batch_size, decoder_length, num_target),</span>
<span class="sd">                target variables</span>
<span class="sd">            * weight: (batch_size, decoder_length),</span>
<span class="sd">                weights for target variables</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># collate function for dataloader</span>
        <span class="c1"># lengths</span>
        <span class="n">encoder_lengths</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
            <span class="p">[</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;encoder_length&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span>
        <span class="p">)</span>
        <span class="n">decoder_lengths</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
            <span class="p">[</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;decoder_length&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span>
        <span class="p">)</span>

        <span class="c1"># ids</span>
        <span class="n">decoder_time_idx_start</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                <span class="p">[</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;encoder_time_idx_start&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">],</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="o">+</span> <span class="n">encoder_lengths</span>
        <span class="p">)</span>
        <span class="n">decoder_time_idx</span> <span class="o">=</span> <span class="n">decoder_time_idx_start</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span>
            <span class="n">decoder_lengths</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
        <span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">groups</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;groups&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">])</span>

        <span class="c1"># features</span>
        <span class="n">encoder_cont</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">pad_sequence</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;x_cont&quot;</span><span class="p">][:</span><span class="n">length</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">length</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">encoder_lengths</span><span class="p">,</span> <span class="n">batches</span><span class="p">)</span>
            <span class="p">],</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">encoder_cat</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">pad_sequence</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;x_cat&quot;</span><span class="p">][:</span><span class="n">length</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">length</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">encoder_lengths</span><span class="p">,</span> <span class="n">batches</span><span class="p">)</span>
            <span class="p">],</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">decoder_cont</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">pad_sequence</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;x_cont&quot;</span><span class="p">][</span><span class="n">length</span><span class="p">:]</span>
                <span class="k">for</span> <span class="n">length</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">encoder_lengths</span><span class="p">,</span> <span class="n">batches</span><span class="p">)</span>
            <span class="p">],</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">decoder_cat</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">pad_sequence</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;x_cat&quot;</span><span class="p">][</span><span class="n">length</span><span class="p">:]</span>
                <span class="k">for</span> <span class="n">length</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">encoder_lengths</span><span class="p">,</span> <span class="n">batches</span><span class="p">)</span>
            <span class="p">],</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># target scale</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batches</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;target_scale&quot;</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>  <span class="c1"># stack tensor</span>
            <span class="n">target_scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;target_scale&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">])</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batches</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;target_scale&quot;</span><span class="p">],</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="n">target_scale</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batches</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;target_scale&quot;</span><span class="p">])):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span>
                    <span class="n">batches</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;target_scale&quot;</span><span class="p">][</span><span class="n">idx</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
                <span class="p">):</span>  <span class="c1"># stack tensor</span>
                    <span class="n">scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                        <span class="p">[</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;target_scale&quot;</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">]</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
                            <span class="p">[</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;target_scale&quot;</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">],</span>
                            <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                        <span class="p">),</span>
                    <span class="p">)</span>
                <span class="n">target_scale</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># convert to tensor</span>
            <span class="n">target_scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;target_scale&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span>
                <span class="p">),</span>
            <span class="p">)</span>

        <span class="c1"># target and weight</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batches</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="n">target</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">rnn</span><span class="o">.</span><span class="n">pad_sequence</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">],</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batches</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span>
            <span class="p">]</span>
            <span class="n">encoder_target</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">rnn</span><span class="o">.</span><span class="n">pad_sequence</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;encoder_target&quot;</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">],</span>
                    <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batches</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span>
            <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">target</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">pad_sequence</span><span class="p">(</span>
                <span class="p">[</span><span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">],</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
            <span class="n">encoder_target</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">pad_sequence</span><span class="p">(</span>
                <span class="p">[</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;encoder_target&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">],</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">batches</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">pad_sequence</span><span class="p">(</span>
                <span class="p">[</span><span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">],</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">return</span> <span class="p">(</span>
            <span class="nb">dict</span><span class="p">(</span>
                <span class="n">encoder_cat</span><span class="o">=</span><span class="n">encoder_cat</span><span class="p">,</span>
                <span class="n">encoder_cont</span><span class="o">=</span><span class="n">encoder_cont</span><span class="p">,</span>
                <span class="n">encoder_target</span><span class="o">=</span><span class="n">encoder_target</span><span class="p">,</span>
                <span class="n">encoder_lengths</span><span class="o">=</span><span class="n">encoder_lengths</span><span class="p">,</span>
                <span class="n">decoder_cat</span><span class="o">=</span><span class="n">decoder_cat</span><span class="p">,</span>
                <span class="n">decoder_cont</span><span class="o">=</span><span class="n">decoder_cont</span><span class="p">,</span>
                <span class="n">decoder_target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span>
                <span class="n">decoder_lengths</span><span class="o">=</span><span class="n">decoder_lengths</span><span class="p">,</span>
                <span class="n">decoder_time_idx</span><span class="o">=</span><span class="n">decoder_time_idx</span><span class="p">,</span>
                <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">,</span>
                <span class="n">target_scale</span><span class="o">=</span><span class="n">target_scale</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">),</span>
        <span class="p">)</span>

<div class="viewcode-block" id="TimeSeriesDataSet.to_dataloader">
<a class="viewcode-back" href="../../../../api/pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.html#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.to_dataloader">[docs]</a>
    <span class="k">def</span> <span class="nf">to_dataloader</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span>
        <span class="n">batch_sampler</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Sampler</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataLoader</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Construct dataloader from dataset, for use in models.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        train : bool, optional, default=Trze</span>
<span class="sd">            whether dataloader is used for training (True) or prediction (False).</span>
<span class="sd">            Will shuffle and drop last batch if True. Defaults to True.</span>
<span class="sd">        batch_size : int, optional, default=64</span>
<span class="sd">            batch size for training model. Defaults to 64.</span>
<span class="sd">        batch_sampler : Sampler, str, or None, optional, default=None</span>
<span class="sd">            torch batch sampler or string. One of</span>

<span class="sd">            * &quot;synchronized&quot;: ensure that samples in decoder are aligned in time.</span>
<span class="sd">                Does not support missing values in dataset.</span>
<span class="sd">                This makes only sense if the underlying algorithm makes use of</span>
<span class="sd">                values aligned in time.</span>
<span class="sd">            * PyTorch Sampler instance: any PyTorch sampler,</span>
<span class="sd">                e.g., ``the WeightedRandomSampler()``</span>
<span class="sd">            * None: samples are taken randomly from times series.</span>

<span class="sd">        **kwargs: additional arguments passed to ``DataLoader`` constructor</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        DataLoader: dataloader that returns Tuple.</span>
<span class="sd">            First entry is ``x``, a dictionary of tensors with the entries,</span>
<span class="sd">            and shapes in brackets.</span>

<span class="sd">            * encoder_cat : long (batch_size x n_encoder_time_steps x n_features)</span>
<span class="sd">                long tensor of encoded categoricals for encoder</span>
<span class="sd">            * encoder_cont : float (batch_size x n_encoder_time_steps x n_features)</span>
<span class="sd">                float tensor of scaled continuous variables for encoder</span>
<span class="sd">            * encoder_target : float (batch_size x n_encoder_time_steps) or list thereof</span>
<span class="sd">                if list, each entry for a different target.</span>
<span class="sd">                float tensor with unscaled continous target</span>
<span class="sd">                or encoded categorical target,</span>
<span class="sd">                list of tensors for multiple targets</span>
<span class="sd">            * encoder_lengths : long (batch_size)</span>
<span class="sd">                long tensor with lengths of the encoder time series. No entry will</span>
<span class="sd">                be greater than n_encoder_time_steps</span>
<span class="sd">            * decoder_cat : long (batch_size x n_decoder_time_steps x n_features)</span>
<span class="sd">                long tensor of encoded categoricals for decoder</span>
<span class="sd">            * decoder_cont : float (batch_size x n_decoder_time_steps x n_features)</span>
<span class="sd">                float tensor of scaled continuous variables for decoder</span>
<span class="sd">            * decoder_target : float (batch_size x n_decoder_time_steps) or list thereof</span>
<span class="sd">                if list, with each entry for a different target.</span>
<span class="sd">                float tensor with unscaled continous target or encoded categorical</span>
<span class="sd">                target for decoder</span>
<span class="sd">                - this corresponds to first entry of ``y``,</span>
<span class="sd">                list of tensors for multiple targets</span>
<span class="sd">            * decoder_lengths : long (batch_size)</span>
<span class="sd">                long tensor with lengths of the decoder time series. No entry will</span>
<span class="sd">                be greater than n_decoder_time_steps</span>
<span class="sd">            * group_ids : float (batch_size x number_of_ids)</span>
<span class="sd">                encoded group ids that identify a time series in the dataset</span>
<span class="sd">            * target_scale : float (batch_size x scale_size) or list thereof.</span>
<span class="sd">                if list, with each entry for a different target.</span>
<span class="sd">                parameters used to normalize the target.</span>
<span class="sd">                Typically these are mean and standard deviation.</span>
<span class="sd">                Is list of tensors for multiple targets.</span>

<span class="sd">            Second entry is ``y``, a tuple of the form (``target``, `weight`)</span>

<span class="sd">            * target : float (batch_size x n_decoder_time_steps) or list thereof</span>
<span class="sd">                if list, with each entry for a different target.</span>
<span class="sd">                unscaled (continuous) or encoded (categories) targets,</span>
<span class="sd">                list of tensors for multiple targets</span>
<span class="sd">            * weight : None or float (batch_size x n_decoder_time_steps)</span>
<span class="sd">                weights for each target, None if no weight is used (= equal weights)</span>

<span class="sd">        Example</span>
<span class="sd">        -------</span>
<span class="sd">        Weight by samples for training:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from torch.utils.data import WeightedRandomSampler</span>

<span class="sd">            # length of probabilties for sampler have to be equal to the length of index</span>
<span class="sd">            probabilities = np.sqrt(1 + data.loc[dataset.index, &quot;target&quot;])</span>
<span class="sd">            sampler = WeightedRandomSampler(probabilities, len(probabilities))</span>
<span class="sd">            dataset.to_dataloader(train=True, sampler=sampler, shuffle=False)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">default_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
            <span class="n">shuffle</span><span class="o">=</span><span class="n">train</span><span class="p">,</span>
            <span class="n">drop_last</span><span class="o">=</span><span class="n">train</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">batch_size</span><span class="p">,</span>
            <span class="n">collate_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_collate_fn</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">batch_sampler</span><span class="o">=</span><span class="n">batch_sampler</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">default_kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="n">default_kwargs</span>
        <span class="k">if</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;batch_sampler&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">sampler</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;batch_sampler&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sampler</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">sampler</span> <span class="o">==</span> <span class="s2">&quot;synchronized&quot;</span><span class="p">:</span>
                    <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;batch_sampler&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">TimeSynchronizedBatchSampler</span><span class="p">(</span>
                        <span class="n">SequentialSampler</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span>
                        <span class="n">batch_size</span><span class="o">=</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">],</span>
                        <span class="n">shuffle</span><span class="o">=</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;shuffle&quot;</span><span class="p">],</span>
                        <span class="n">drop_last</span><span class="o">=</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;drop_last&quot;</span><span class="p">],</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;batch_sampler </span><span class="si">{</span><span class="n">sampler</span><span class="si">}</span><span class="s2"> unknown - &quot;</span>
                        <span class="s2">&quot;see docstring for valid batch_sampler&quot;</span>
                    <span class="p">)</span>
            <span class="k">del</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">]</span>
            <span class="k">del</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;shuffle&quot;</span><span class="p">]</span>
            <span class="k">del</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;drop_last&quot;</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="TimeSeriesDataSet.x_to_index">
<a class="viewcode-back" href="../../../../api/pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.html#pytorch_forecasting.data.timeseries._timeseries.TimeSeriesDataSet.x_to_index">[docs]</a>
    <span class="k">def</span> <span class="nf">x_to_index</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Decode dataframe index from x.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dataframe with time index column for first prediction and group ids</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">index_data</span> <span class="o">=</span> <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">time_idx</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;decoder_time_idx&quot;</span><span class="p">][:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()}</span>
        <span class="k">for</span> <span class="nb">id</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">group_ids</span><span class="p">:</span>
            <span class="n">index_data</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;groups&quot;</span><span class="p">][:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">group_ids</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="nb">id</span><span class="p">)]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
            <span class="c1"># decode if possible</span>
            <span class="n">index_data</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_values</span><span class="p">(</span>
                <span class="nb">id</span><span class="p">,</span> <span class="n">index_data</span><span class="p">[</span><span class="nb">id</span><span class="p">],</span> <span class="n">inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">group_id</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
        <span class="n">index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index_data</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">index</span></div>


    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">repr_class</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">attributes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">(),</span>
            <span class="n">extra_attributes</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">length</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)),</span>
        <span class="p">)</span></div>

</pre></div>

                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2020, Jan Beitner.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.3.7.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>