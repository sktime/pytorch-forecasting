{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzVbXsEBxnF-"
   },
   "source": [
    "# Example Notebook for a basic vignette for `pytorch-forecasting v2` Model Training and Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yt0uZV7Px-40"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    ":warning: The \"Data Pipeline\" showcased here is part of an experimental rework of the `pytorch-forecasting` data layer, planned for release in v2.0.0. The API is currently unstable and subject to change without prior notice. This notebook serves as a basic demonstration of the intended workflow and is not recommended for use in production environments. Feedback and suggestions are highly encouraged â€” please share them in <a href=\"https://github.com/sktime/pytorch-forecasting/issues/1736\">issue 1736</a>.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r15UunnLoxnK"
   },
   "source": [
    "In this notebook, we demonstrate how to train and evaluate the **Temporal Fusion Transformer (TFT)** using the new `TimeSeries` and `DataModule` API from the v2 pipeline.\n",
    "We can do this in 2 ways:\n",
    "1. **High-level package API:**\n",
    "\n",
    "    This approach handles data loading, dataloader creation, and model training internally. It provides a simple, `scikit-learn`-like `fit` â†’ `predict` workflow.\n",
    "    Users can still configure key training options (such as the `trainer`, callbacks, and training parameters) but cannot plug in fully custom `trainer` implementations or override internal pipeline logic.\n",
    "\n",
    "2. **Low-level 3-stage pipeline**:\n",
    "This involves explicitly constructing:\n",
    "    * a `TimeSeries` object\n",
    "\n",
    "    * a `DataModule`\n",
    "\n",
    "    * the model (e.g., `TFT`)\n",
    "    \n",
    "    This workflow is ideal if you need custom setups such as custom trainers, callbacks, or advanced data preprocessing.\n",
    "    It requires a deeper understanding of how the three layers (TimeSeries, DataModule, and the model) interact, but offers maximum flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyMFNk4MyY_b"
   },
   "source": [
    "# Create Synthetic data\n",
    "We generate a synthetic dataset using `load_toydata` that creates a `pandas` DataFrame with just numerical values as for now **the pipeline assumes the data to be numerical only**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RkgOT4kiy_RU"
   },
   "outputs": [],
   "source": [
    "from pytorch_forecasting.data.examples import load_toydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "WX-FRdusJSVN",
    "outputId": "2ad916b8-2fd9-4318-afb1-2bda84d284d7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"data_df\",\n  \"rows\": 4900,\n  \"fields\": [\n    {\n      \"column\": \"series_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          83,\n          53,\n          70\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time_idx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 0,\n        \"max\": 48,\n        \"num_unique_values\": 49,\n        \"samples\": [\n          13,\n          45,\n          47\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6712252870750063,\n        \"min\": -1.2780952045426857,\n        \"max\": 1.3163602917006327,\n        \"num_unique_values\": 4900,\n        \"samples\": [\n          0.19335967827533446,\n          0.8492207493147326,\n          -0.9687640491099185\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6753351884449413,\n        \"min\": -1.2780952045426857,\n        \"max\": 1.3163602917006327,\n        \"num_unique_values\": 4900,\n        \"samples\": [\n          0.6981263626070341,\n          0.7052787051636003,\n          -0.861386757323439\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"future_known_feature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6741140972121411,\n        \"min\": -0.9991351502732795,\n        \"max\": 1.0,\n        \"num_unique_values\": 49,\n        \"samples\": [\n          0.26749882862458735,\n          -0.2107957994307797,\n          -0.01238866346289056\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"static_feature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2792423704109133,\n        \"min\": 0.031153133884698536,\n        \"max\": 0.9662188410416612,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          0.24602577096925082,\n          0.8680231736929984,\n          0.6913124004679789\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"static_feature_cat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "data_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-1832c3c5-7f87-4d94-b11a-f1f39dcbdc3e\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>category</th>\n",
       "      <th>future_known_feature</th>\n",
       "      <th>static_feature</th>\n",
       "      <th>static_feature_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.030643</td>\n",
       "      <td>0.148280</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.039213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.148280</td>\n",
       "      <td>0.433029</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995004</td>\n",
       "      <td>0.039213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.433029</td>\n",
       "      <td>0.742511</td>\n",
       "      <td>0</td>\n",
       "      <td>0.980067</td>\n",
       "      <td>0.039213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.742511</td>\n",
       "      <td>0.729270</td>\n",
       "      <td>0</td>\n",
       "      <td>0.955336</td>\n",
       "      <td>0.039213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.729270</td>\n",
       "      <td>0.628604</td>\n",
       "      <td>0</td>\n",
       "      <td>0.921061</td>\n",
       "      <td>0.039213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1832c3c5-7f87-4d94-b11a-f1f39dcbdc3e')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-1832c3c5-7f87-4d94-b11a-f1f39dcbdc3e button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-1832c3c5-7f87-4d94-b11a-f1f39dcbdc3e');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-846d0093-caf5-46ab-8a57-4a3a141ca666\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-846d0093-caf5-46ab-8a57-4a3a141ca666')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-846d0093-caf5-46ab-8a57-4a3a141ca666 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   series_id  time_idx         x         y  category  future_known_feature  \\\n",
       "0          0         0 -0.030643  0.148280         0              1.000000   \n",
       "1          0         1  0.148280  0.433029         0              0.995004   \n",
       "2          0         2  0.433029  0.742511         0              0.980067   \n",
       "3          0         3  0.742511  0.729270         0              0.955336   \n",
       "4          0         4  0.729270  0.628604         0              0.921061   \n",
       "\n",
       "   static_feature  static_feature_cat  \n",
       "0        0.039213                   0  \n",
       "1        0.039213                   0  \n",
       "2        0.039213                   0  \n",
       "3        0.039213                   0  \n",
       "4        0.039213                   0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_series = 100  # Number of individual time series to generate\n",
    "seq_length = 50  # Length of each time series\n",
    "data_df = load_toydata(num_series, seq_length)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8TgLH82runO"
   },
   "source": [
    "# High-level API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1cqKCRur4oj"
   },
   "source": [
    "## Steps\n",
    "* Create the `TimeSeries` object\n",
    "* Create `configs` for model, `datamodule`, `trainer` etc.\n",
    "* Create the `model_pkg` object\n",
    "* perform `pkg.fit` and `pkg.predict`.\n",
    "\n",
    "##  Create Dataset object\n",
    "\n",
    "`TimeSeries` returns the raw data in terms of tensors .\n",
    "\n",
    "---\n",
    "\n",
    "`TimeSeries` dataset's Key arguments:\n",
    "- `data`: DataFrame with sequence data.\n",
    "- `time`: integer typed column denoting the time index within `data`.\n",
    "- `target`:  Column(s) in `data` denoting the forecasting target.\n",
    "- `group`: List of column names identifying a time series instance within `data`.\n",
    "- `num`: List of numerical features.\n",
    "- `cat`: List of categorical features.\n",
    "- `known`: Features known in future\n",
    "- `unknown`: Features not known in the future\n",
    "- `static`: List of variables that do not change over time,\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "u8OPR0HntXqR"
   },
   "outputs": [],
   "source": [
    "from pytorch_forecasting.data.timeseries import TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6a_oy4VjtrHQ",
    "outputId": "54678fb8-864e-4f32-eeb9-83697946a3e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/pytorch-forecasting/pytorch_forecasting/data/timeseries/_timeseries_v2.py:105: UserWarning: TimeSeries is part of an experimental rework of the pytorch-forecasting data layer, scheduled for release with v2.0.0. The API is not stable and may change without prior warning. For beta testing, but not for stable production use. Feedback and suggestions are very welcome in pytorch-forecasting issue 1736, https://github.com/sktime/pytorch-forecasting/issues/1736\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# create `TimeSeries` dataset that returns the raw data in terms of tensors\n",
    "dataset = TimeSeries(\n",
    "    data=data_df,\n",
    "    time=\"time_idx\",\n",
    "    target=\"y\",\n",
    "    group=[\"series_id\"],\n",
    "    num=[\"x\", \"future_known_feature\", \"static_feature\"],\n",
    "    cat=[\"category\", \"static_feature_cat\"],\n",
    "    known=[\"future_known_feature\"],\n",
    "    unknown=[\"x\", \"category\"],\n",
    "    static=[\"static_feature\", \"static_feature_cat\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EoS6W9zh6wCj"
   },
   "source": [
    "## Create the configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "MKPXPUcC5dTY"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from pytorch_forecasting.data.encoders import (\n",
    "    EncoderNormalizer,\n",
    "    NaNLabelEncoder,\n",
    "    TorchNormalizer,\n",
    ")\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYl9-oZz6nk6"
   },
   "source": [
    "Here we use `EncoderDecoderTimeSeriesDataModule`\n",
    "\n",
    "\n",
    "`EncoderDecoderTimeSeriesDataModule` key arguments:\n",
    "- `time_series_dataset`: `TimeSeries` dataset instance\n",
    "- `max_encoder_length` : Maximum length of the encoder input sequence.\n",
    "- `max_prediction_length` : Maximum length of the decoder output sequence.\n",
    "- `batch_size` : Batch size for DataLoader.\n",
    "- `categorical_encoders` :  Dictionary of categorical encoders.\n",
    "- `scalers` : Dictionary of feature scalers.\n",
    "- `target_normalizer`: Normalizer for the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "YGMShzfyttp_"
   },
   "outputs": [],
   "source": [
    "datamodule_cfg = dict(\n",
    "    max_encoder_length=30,\n",
    "    max_prediction_length=1,\n",
    "    batch_size=32,\n",
    "    categorical_encoders={\n",
    "        \"category\": NaNLabelEncoder(add_nan=True),\n",
    "        \"static_feature_cat\": NaNLabelEncoder(add_nan=True),\n",
    "    },\n",
    "    scalers={\n",
    "        \"x\": StandardScaler(),\n",
    "        \"future_known_feature\": StandardScaler(),\n",
    "        \"static_feature\": StandardScaler(),\n",
    "    },\n",
    "    target_normalizer=TorchNormalizer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pi5Qkznh6t3y"
   },
   "source": [
    "We would use `TFT` model in this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "q6Thm13ct7OV"
   },
   "outputs": [],
   "source": [
    "model_cfg = dict(\n",
    "    loss=MAE(),\n",
    "    logging_metrics=[MAE(), SMAPE()],\n",
    "    optimizer=\"adam\",\n",
    "    optimizer_params={\"lr\": 1e-3},\n",
    "    lr_scheduler=\"reduce_lr_on_plateau\",\n",
    "    lr_scheduler_params={\"mode\": \"min\", \"factor\": 0.1, \"patience\": 10},\n",
    "    hidden_size=64,\n",
    "    num_layers=2,\n",
    "    attention_head_size=4,\n",
    "    dropout=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Stfuc_xCuON6"
   },
   "outputs": [],
   "source": [
    "trainer_cfg = dict(\n",
    "    max_epochs=5,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    enable_progress_bar=True,\n",
    "    log_every_n_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "XS_ND8UAubdN"
   },
   "outputs": [],
   "source": [
    "from pytorch_forecasting.models.temporal_fusion_transformer._tft_pkg_v2 import (\n",
    "    TFT_pkg_v2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yoqI8907DG4"
   },
   "source": [
    "## Create the `model_pkg` object\n",
    "\n",
    "This `pkg` class acts as a wrapper around the whole ML pipeline in `pytorch-forecasting` and we can simply just define the `pkg` class and then use `pkg.fit` and `pkg.predict` to perform the \"fit\", \"predict\" mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aOxng4Rguwj2",
    "outputId": "2c50fcad-f990-4aae-f0bb-5dbdd6a87377"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': MAE(), 'logging_metrics': [MAE(), SMAPE()], 'optimizer': 'adam', 'optimizer_params': {'lr': 0.001}, 'lr_scheduler': 'reduce_lr_on_plateau', 'lr_scheduler_params': {'mode': 'min', 'factor': 0.1, 'patience': 10}, 'hidden_size': 64, 'num_layers': 2, 'attention_head_size': 4, 'dropout': 0.1}\n"
     ]
    }
   ],
   "source": [
    "model_pkg = TFT_pkg_v2(\n",
    "    model_cfg=model_cfg,\n",
    "    trainer_cfg=trainer_cfg,\n",
    "    datamodule_cfg=datamodule_cfg,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 976,
     "referenced_widgets": [
      "4ecdea6764d145118ab53e59451d2b0c",
      "e7b969aa6d8e433d9aeeac4357bc425d",
      "42707b895305490b82cd644250e689fa",
      "19c3c106d5a9489cae445a0b5fc88183",
      "a6e5908902eb40e997e6086287f28f2a",
      "f23d99cc4f01426eb4fc8d41fc8f4b16",
      "df8d7458b0fa4f508d4ce357fc95c609",
      "464464a47d604d708be37e18edec4810",
      "c7ca9662eae04999b21de91c183a0856",
      "e82943533ad54539a777d6adae271d0f",
      "e0fa236745204d5ba2dbc1ff2c51f1a2",
      "c52bb8ff12db4df3a05cf1da7b5470f7",
      "273fb7ccddeb476f9c76bd1be44a6ae0",
      "922dfb34c7494b20a874e294c07447e0",
      "96eda6cd2fbc47b9a29d2cf176332058",
      "d2ed70b544924436b185f79d0cd90862",
      "aff8baef21494ccf99bf092fc3daaae0",
      "640d3876c2ce49de9757962b5b5b0e32",
      "f99327891eeb424b9df4fe04a6bedcfb",
      "04804ca4c425464db2754abf3cf95568",
      "386a2097c02f4af6ba239e385f4b0b47",
      "7e95bdbc3a6c46bf8b1e96bdecfa7303",
      "572629c64cfd46a983f1a8c6483a2cf1",
      "61f356a200c5470db777e7e0f9e8c520",
      "4905c6d809274aa39a984e3e458fc89a",
      "b16522c88ebb435f96c05315ef91ebbb",
      "65cce98698644285896363e509ae6139",
      "a4a4c07f117e46989cb4877a5d2dd9e0",
      "3f8cc20607db40c7acb4110feba9ab0d",
      "3c5c1f55d5a64838b94fc0fbd85097c6",
      "4f5cce37b6ac430e85757dd06b06953a",
      "942645c506ea436fb598455d84c8a970",
      "969a3ddfaed84150944d697307ababe4",
      "955c5e9c139148a1a352d17202fe097f",
      "f0fbcbcf02e443bc99a469cf4c7f8131",
      "72fb23e179594f35a68418e2e0ee65fc",
      "7808bf48e45940cfa0d4bccae784d730",
      "ed0358a45ec14ce687fc02904a815e38",
      "67a3d79f1b2e4e03b9a564286c04d5d4",
      "27fd0da590314bb68dfac5b7c72d6584",
      "15e539660a2547f49fb2cf8a6143f5fa",
      "c46b831b37a347868f1d35d0dbbfd923",
      "3f985da9d6a245c5b54dbb47926a4fd4",
      "5ab64c01efb84e75af1a8aaf6675f5bf",
      "8d0747756fd2434399ae8d233a82d607",
      "f77d800d097b494ca3e945abdaedd75c",
      "05a14444ea4043dea69a4e7185e66cb1",
      "b775518f409449928c3211260d7223c0",
      "2db9a1e74ad14139af235f1a2a146e0a",
      "2bcdfdf1b12c495aa8b425c88fcfbd1b",
      "d71a01b309e948239a16062097ee76a2",
      "006cdf49ce55411bb072c2670d87773f",
      "5b3be082628244948284a40bea451ff1",
      "bf96e25bd5d64892a329b624961abeb8",
      "b5e879fa1fee4d0ba30ac5af07d1d8c5",
      "78f2d725dcb34deca5407c277c384d8d",
      "e1dc997d76d54eb9a9245530a60c2cd9",
      "8fa00a6415b74091a012bc5fff543f42",
      "c74c472cdf174a28a4ca3fed1b312332",
      "409d65e2b79f49318c580d9835ffc29c",
      "568141e0b45f44ff9b497c6474d8019f",
      "1a889d0b55bb4e6d80d5f170297a6262",
      "679072fe36f5404588879eab670e01e2",
      "ab72364dc8cf433e907c40df3e7be9e9",
      "d56c627297bd435fbbc60317066084f9",
      "6a62c54d7d7b4f689dc31e57aaa20411",
      "3ab523d60fd249a7bcece32280872abd",
      "ef8e78e4f8a248dcbbc2ea3e464c5922",
      "56685ebbfd244154bd1829dec6f0db0b",
      "dc5f9a923d27492cb382691ec01a1ddc",
      "58995b1bd1c24433a3aca0ab53c6b8bf",
      "9082a1b6eb3a4d14b4c92eedec1c2404",
      "13eb0c5265ad48d08b3f8e46a55896f0",
      "f91e202108684aa9af76fdf3e9d83206",
      "f617590dcd184fd99f98515940ac85af",
      "33a1e5f21b694e3bb62d2c0d73aa65e3",
      "8c8c8832e16c4d489e0df7514dc78f6a"
     ]
    },
    "id": "c27Qj4QAvFwx",
    "outputId": "21bbd594-d92e-498b-bd02-71829295c483"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/pytorch-forecasting/pytorch_forecasting/data/data_module.py:129: UserWarning: EncoderDecoderTimeSeriesDataModule is part of an experimental rework of the pytorch-forecasting data layer, scheduled for release with v2.0.0. The API is not stable and may change without prior warning. For beta testing, but not for stable production use. Feedback and suggestions are very welcome in pytorch-forecasting issue 1736, https://github.com/sktime/pytorch-forecasting/issues/1736\n",
      "  warn(\n",
      "/content/pytorch-forecasting/pytorch_forecasting/models/base/_base_model_v2.py:64: UserWarning: The Model 'TFT' is part of an experimental reworkof the pytorch-forecasting model layer, scheduled for release with v2.0.0. The API is not stable and may change without prior warning. This class is intended for beta testing and as a basic skeleton, but not for stable production use. Feedback and suggestions are very welcome in pytorch-forecasting issue 1736, https://github.com/sktime/pytorch-forecasting/issues/1736\n",
      "  warn(\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO: \n",
      "  | Name                  | Type               | Params | Mode \n",
      "---------------------------------------------------------------------\n",
      "0 | loss                  | MAE                | 0      | train\n",
      "1 | encoder_var_selection | Sequential         | 709    | train\n",
      "2 | decoder_var_selection | Sequential         | 193    | train\n",
      "3 | static_context_linear | Linear             | 192    | train\n",
      "4 | lstm_encoder          | LSTM               | 51.5 K | train\n",
      "5 | lstm_decoder          | LSTM               | 50.4 K | train\n",
      "6 | self_attention        | MultiheadAttention | 16.6 K | train\n",
      "7 | pre_output            | Linear             | 4.2 K  | train\n",
      "8 | output_layer          | Linear             | 65     | train\n",
      "---------------------------------------------------------------------\n",
      "123 K     Trainable params\n",
      "0         Non-trainable params\n",
      "123 K     Total params\n",
      "0.495     Total estimated model params size (MB)\n",
      "18        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "INFO:lightning.pytorch.callbacks.model_summary:\n",
      "  | Name                  | Type               | Params | Mode \n",
      "---------------------------------------------------------------------\n",
      "0 | loss                  | MAE                | 0      | train\n",
      "1 | encoder_var_selection | Sequential         | 709    | train\n",
      "2 | decoder_var_selection | Sequential         | 193    | train\n",
      "3 | static_context_linear | Linear             | 192    | train\n",
      "4 | lstm_encoder          | LSTM               | 51.5 K | train\n",
      "5 | lstm_decoder          | LSTM               | 50.4 K | train\n",
      "6 | self_attention        | MultiheadAttention | 16.6 K | train\n",
      "7 | pre_output            | Linear             | 4.2 K  | train\n",
      "8 | output_layer          | Linear             | 65     | train\n",
      "---------------------------------------------------------------------\n",
      "123 K     Trainable params\n",
      "0         Non-trainable params\n",
      "123 K     Total params\n",
      "0.495     Total estimated model params size (MB)\n",
      "18        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ecdea6764d145118ab53e59451d2b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52bb8ff12db4df3a05cf1da7b5470f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572629c64cfd46a983f1a8c6483a2cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "955c5e9c139148a1a352d17202fe097f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0747756fd2434399ae8d233a82d607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78f2d725dcb34deca5407c277c384d8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab523d60fd249a7bcece32280872abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts saved in: /content/pytorch-forecasting/checkpoints\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/content/pytorch-forecasting/checkpoints/best-epoch=3-step=168.ckpt')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pkg.fit(dataset)  # You can also pass in a DataModule here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYb9WJVy7nyC"
   },
   "source": [
    "\n",
    "#### Output\n",
    "Output of TFT model is a `dict` with key `prediction`:\n",
    "\n",
    "- `y_pred[\"prediction\"]`: Tensor of shape `(batch_size, prediction_length, output_size)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218,
     "referenced_widgets": [
      "c232241e3ca24eddb2dae0f9ceb7e114",
      "b8ca7fe5fc534f3bbecc9130102a3129",
      "ad5be790369941ea9aa51bc297740f54",
      "374f1f4cb472482eaad8c7a00eaf3217",
      "a6c3a711dc41433a8b255a68f9b3a8a2",
      "12cb9f1a3f5b4111a995bba45ea38ca3",
      "d89abdeee4a6494abc9be8dd1da0ec0c",
      "30485ca293ea4d7ba1591727897f2e28",
      "5e40761af7644c9aa7861c62c75ed441",
      "dc3ad9baee4b4f58b69a3af4891deb4d",
      "6b5a84943e524c559a68099c05220f2c"
     ]
    },
    "id": "vTt5w73CvNuc",
    "outputId": "24089add-49b9-410d-d0f3-50cd7426b35d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/pytorch-forecasting/pytorch_forecasting/data/data_module.py:129: UserWarning: EncoderDecoderTimeSeriesDataModule is part of an experimental rework of the pytorch-forecasting data layer, scheduled for release with v2.0.0. The API is not stable and may change without prior warning. For beta testing, but not for stable production use. Feedback and suggestions are very welcome in pytorch-forecasting issue 1736, https://github.com/sktime/pytorch-forecasting/issues/1736\n",
      "  warn(\n",
      "INFO: ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c232241e3ca24eddb2dae0f9ceb7e114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = model_pkg.predict(dataset, return_info=[\"index\", \"x\", \"y\"])\n",
    "# You can also pass in a DataModule or Dataloader here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KANOUlepv0ty",
    "outputId": "17ce66d0-5ba9-4a09-b5fc-9ecebb8bd470"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Predicted Value:\n",
      "Index: -0.0801810473203659\n",
      "Prediction: 0.11192154139280319\n",
      "Actual: -0.1557866632938385\n"
     ]
    }
   ],
   "source": [
    "print(\"First Predicted Value:\")\n",
    "print(\"Index:\", preds[\"index\"][0].item())\n",
    "print(\"Prediction:\", preds[\"prediction\"][0].item())\n",
    "print(\"Actual:\", preds[\"y\"][0].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2-S5EXeo2er"
   },
   "source": [
    "# 3-stage pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6D9ARyp05R0t"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "## Steps\n",
    "\n",
    "1. Create `TimeSeries` Dataset object\n",
    "2. Create DataModule object\n",
    "3. Initialize, Train & Run Inference with the Model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###  Create Dataset & DataModule\n",
    "\n",
    "- `TimeSeries` returns the raw data in terms of tensors .\n",
    "- `DataModule` wraps the dataset, handles splits, preprocessing, batching, and exposes `metadata` for the model initialisation.\n",
    "\n",
    "\n",
    "\n",
    "### Initialize the Model\n",
    "\n",
    "We initialize the TFT model using the `metadata` provided by the `DataModule`. This metadata includes all required dimensional info for the encoder, decoder, and static inputs.\n",
    "\n",
    "\n",
    "\n",
    "### Train the Model\n",
    "\n",
    "We use a `Trainer` from PyTorch Lightning to train the model\n",
    "\n",
    "### Run Inference\n",
    "\n",
    "After training, we can make predictions using the trained model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYQ5CdNUyc2q"
   },
   "source": [
    "## 1. Create the dataset\n",
    "We create a `TimeSeries` dataset instance that returns the raw data in terms of tensors, then this \"raw data\" is sent to the `data_module`that will internally handle the dataloaders and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONe8Eo1zzvCH"
   },
   "source": [
    "`TimeSeries` dataset's Key arguments:\n",
    "- `data`: DataFrame with sequence data.\n",
    "- `time`: integer typed column denoting the time index within `data`.\n",
    "- `target`:  Column(s) in `data` denoting the forecasting target.\n",
    "- `group`: List of column names identifying a time series instance within `data`.\n",
    "- `num`: List of numerical features.\n",
    "- `cat`: List of categorical features.\n",
    "- `known`: Features known in future\n",
    "- `unknown`: Features not known in the future\n",
    "- `static`: List of variables that do not change over time,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "JPD3y3qny5Dx"
   },
   "outputs": [],
   "source": [
    "from pytorch_forecasting.data.timeseries import TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AxxPHK6AKSD2",
    "outputId": "7d8eea0b-6bfc-447c-b40b-f3c7e8bae4a4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/pytorch-forecasting/pytorch_forecasting/data/timeseries/_timeseries_v2.py:105: UserWarning: TimeSeries is part of an experimental rework of the pytorch-forecasting data layer, scheduled for release with v2.0.0. The API is not stable and may change without prior warning. For beta testing, but not for stable production use. Feedback and suggestions are very welcome in pytorch-forecasting issue 1736, https://github.com/sktime/pytorch-forecasting/issues/1736\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# create `TimeSeries` dataset that returns the raw data in terms of tensors\n",
    "dataset = TimeSeries(\n",
    "    data=data_df,\n",
    "    time=\"time_idx\",\n",
    "    target=\"y\",\n",
    "    group=[\"series_id\"],\n",
    "    num=[\"x\", \"future_known_feature\", \"static_feature\"],\n",
    "    cat=[\"category\", \"static_feature_cat\"],\n",
    "    known=[\"future_known_feature\"],\n",
    "    unknown=[\"x\", \"category\"],\n",
    "    static=[\"static_feature\", \"static_feature_cat\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCKRpRkOsmro"
   },
   "source": [
    "## 2. Create datamodule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-yHU46v1MhN"
   },
   "source": [
    "`EncoderDecoderTimeSeriesDataModule` key arguments:\n",
    "- `time_series_dataset`: `TimeSeries` dataset instance\n",
    "- `max_encoder_length` : Maximum length of the encoder input sequence.\n",
    "- `max_prediction_length` : Maximum length of the decoder output sequence.\n",
    "- `batch_size` : Batch size for DataLoader.\n",
    "- `categorical_encoders` :  Dictionary of categorical encoders.\n",
    "- `scalers` : Dictionary of feature scalers.\n",
    "- `target_normalizer`: Normalizer for the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "DUWB4LrGyxrL"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from pytorch_forecasting.data.data_module import EncoderDecoderTimeSeriesDataModule\n",
    "from pytorch_forecasting.data.encoders import (\n",
    "    EncoderNormalizer,\n",
    "    NaNLabelEncoder,\n",
    "    TorchNormalizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5U5Lr_ZFKX0s",
    "outputId": "248cf4c4-b7e4-4210-c782-e142ced29189"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/pytorch-forecasting/pytorch_forecasting/data/data_module.py:129: UserWarning: EncoderDecoderTimeSeriesDataModule is part of an experimental rework of the pytorch-forecasting data layer, scheduled for release with v2.0.0. The API is not stable and may change without prior warning. For beta testing, but not for stable production use. Feedback and suggestions are very welcome in pytorch-forecasting issue 1736, https://github.com/sktime/pytorch-forecasting/issues/1736\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# create the `data_module` that handles the dataloaders and preprocessing\n",
    "data_module = EncoderDecoderTimeSeriesDataModule(\n",
    "    time_series_dataset=dataset,\n",
    "    max_encoder_length=30,\n",
    "    max_prediction_length=1,\n",
    "    batch_size=32,\n",
    "    categorical_encoders={\n",
    "        \"category\": NaNLabelEncoder(add_nan=True),\n",
    "        \"static_feature_cat\": NaNLabelEncoder(add_nan=True),\n",
    "    },\n",
    "    scalers={\n",
    "        \"x\": StandardScaler(),\n",
    "        \"future_known_feature\": StandardScaler(),\n",
    "        \"static_feature\": StandardScaler(),\n",
    "    },\n",
    "    target_normalizer=TorchNormalizer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qykX7vQ7zWnC"
   },
   "source": [
    "## 3. Initialise and train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kz3MO362Tlo"
   },
   "source": [
    "To initialise the model you now don't have to pass arguments like `encoder_cont`, `decoder_cont` etc as they are calculated internally using the `metadata` property [[source]](https://github.com/sktime/pytorch-forecasting/blob/4a34931e499c2b59de3939fcffcaabd75204b045/pytorch_forecasting/data/data_module.py#L264-L292) of `EncoderDecoderTimeSeriesDataModule`. But you still have to pass other params like `loss`, `optimizer` etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XvwIuzD34Ytk"
   },
   "source": [
    "\n",
    "```python\n",
    "model = TFT(\n",
    "    loss=nn.MSELoss(),\n",
    "    logging_metrics=[MAE(), SMAPE()],\n",
    "    metadata=data_module.metadata,  # <-- crucial for model setup\n",
    "    ...\n",
    ")\n",
    "```\n",
    "\n",
    "The `metadata` includes:\n",
    "- `max_encoder_length`, `max_prediction_length`\n",
    "- number of continuous/categorical variables in encoder/decoder\n",
    "- number of static features\n",
    "\n",
    "These are used to configure internal layers like `encoder_cont`, `decoder_cat`, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xOsEucZnzCkN"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer._tft_v2 import TFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9qbjnTxnyh4H",
    "outputId": "a486be25-1c41-4ef2-f2ce-8e5da9704594"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/pytorch-forecasting/pytorch_forecasting/models/base/_base_model_v2.py:64: UserWarning: The Model 'TFT' is part of an experimental reworkof the pytorch-forecasting model layer, scheduled for release with v2.0.0. The API is not stable and may change without prior warning. This class is intended for beta testing and as a basic skeleton, but not for stable production use. Feedback and suggestions are very welcome in pytorch-forecasting issue 1736, https://github.com/sktime/pytorch-forecasting/issues/1736\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialise the Model\n",
    "model = TFT(\n",
    "    loss=MAE(),\n",
    "    logging_metrics=[MAE(), SMAPE()],\n",
    "    optimizer=\"adam\",\n",
    "    optimizer_params={\"lr\": 1e-3},\n",
    "    lr_scheduler=\"reduce_lr_on_plateau\",\n",
    "    lr_scheduler_params={\"mode\": \"min\", \"factor\": 0.1, \"patience\": 10},\n",
    "    hidden_size=64,\n",
    "    num_layers=2,\n",
    "    attention_head_size=4,\n",
    "    dropout=0.1,\n",
    "    metadata=data_module.metadata,  # pass the metadata from the datamodule to the model\n",
    "    # to initialise important params like `encoder_cont` etc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svdoye-d8F-z"
   },
   "source": [
    "We use a `Trainer` from PyTorch Lightning to train the model:\n",
    "\n",
    "```python\n",
    "trainer = Trainer(max_epochs=5, ...)\n",
    "trainer.fit(model, data_module)\n",
    "```\n",
    "\n",
    "The `Trainer`:\n",
    "- Pulls data from `data_module`\n",
    "- Handles device placement\n",
    "- Logs training progress and metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RTSmUu9RytS8"
   },
   "outputs": [],
   "source": [
    "from lightning.pytorch import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 940,
     "referenced_widgets": [
      "a553dd138d714a18af6c0713e1b43897",
      "34b327966f2b4573a30331a4ca2bad36",
      "2012c67eef9d43099e0566c866d24043",
      "abd2f8bdab144398b139ba1653e325b7",
      "8c09917e05734fd4ac283d3f6ec98de3",
      "2d9aeac5b4d6406b95f41030b3902ead",
      "fdd3021d0aba4ea19d02b9fde8e01e6c",
      "26963ab219a447f2a53313948576286d",
      "870e865f5c3c48d88971b7d4a0f18f1f",
      "66628b3d61634d44b911582f00355793",
      "6ae72c38fbe742ac850b2cb60d7faa2e",
      "86d1a5f363394cc18785ac88a22d76d3",
      "c5db7875e835420cb238605415521449",
      "7f3b3e4f12e04abc9baf01711628f447",
      "13053e2cc53b4d86a18835d3cf62d9a0",
      "a7637150a8614da1a9df8e820c3a5195",
      "bc0b2a7717d14663bafd06df6462469f",
      "418156a6b73246dc86e8fce9112c14ea",
      "2151663ad02a429cac5a52a90371ce95",
      "f07bfb9fa06342389b5fec3fb19d59f1",
      "68689a954b69463ba4a2f02ed26d41a9",
      "fb5c4ef912a54a96a4aaacbd9b7d0517",
      "87c0a054bd0a4cc38bdaa2ef39bb30ae",
      "f8bb72058f0141c69e0dac07c0ad4bbd",
      "377ab5bbba5a46c3bb65d29ff2eac00b",
      "34ff67844e7742bcb40b5fc0d4d6c475",
      "ab042b4a1b0644c9819cc0d21ca1f13f",
      "01d5bef8db0c42a7a82f9600a6ee7549",
      "ffb26eb93aa049b1a2a808c60dc9508a",
      "0108dec7eb894503ba2e7e1bd33e814b",
      "6ab9f5c0352f4da7acda358e07fd7793",
      "f856cbb51d3c4b31bf7ca98d7f387fc7",
      "4ca73580d9ae4cd190da8d2e36e27a89",
      "9d5419fc33de4216807044da7fe61524",
      "4e2b7089a69644e9a1ff3afd7524d491",
      "10f011e768704402a8d46f6377c6364e",
      "f542ed5ec0204587a03813849b712b2e",
      "e1c67f9cef4a4bb79411efc427122c2c",
      "1380306827ec4169a896b9ffcbeb8c2c",
      "828c025cedfc483e9fb0af4f7c7b9393",
      "41b14de355a04031ad4deabdadc6f9fe",
      "c12b35d0715a4ae580557cd6c17740c8",
      "d3e3d7deb36441539c459e24ab2d8aa3",
      "7f23a8e77dce4f38a764c7637fe10b78",
      "a9e0349ab6494ec09a6f909e152f685d",
      "f648ccd5714f4f0fa5f9710d6a26a5a8",
      "168a880240964d0194f1b986eacbcd29",
      "d44ceef01cd24e9aa3090b6f85d784aa",
      "01487f5cfc2e4a79b5b310c7732cba16",
      "64622e3cde0543918d827a5bccee0abd",
      "00e7ff7f5a1646e887b35fb22ab4a8b0",
      "37db4be2353f436abf3ec0a71dca8e39",
      "2daef716eda64487837f300db34039da",
      "21e78da0f7204d5e8ccfc92cc39be9ae",
      "12b11fd7fb53408e92e79ad50cfdd433",
      "83af6fa1a89c44398eaa18bc89031fa8",
      "762d1c8b6c2a4b7996c0ed9dfabe8f8c",
      "53ebd9b8a8e54e93a572dd807d9fafd4",
      "6cfa122301624a2e9efd2364d1d114bb",
      "a4a42a7c37fd4d22b2af0495f6b77292",
      "d57a2d0bbbb246f9b049024de69cea94",
      "ed8f3f06633c4f249a8311e311118c97",
      "06458336850c4c838ad02188538c6c64",
      "6ffbcceb8ca6487dbcd7e1b03f78d957",
      "4b0ccc7bbcc146a5bccc9b41483fb505",
      "6df22cc241a843ccab44daa16db38136",
      "803a672f660842f6ab949ea62fc9e44e",
      "969658209b1043c59b4c931280fd2f5f",
      "7cce8e0bd68b4fe69a1e67f4b695c31f",
      "e2039b30418048d8a030037d2f711498",
      "690e2dc613364e5b9e3f204c76798f12",
      "eda10823474b40949452e97f0259009f",
      "51382e4f2efc4f9ea25254c3ccc07ba0",
      "70518e8f3e704fed9d91cf2eb28546d6",
      "5cad874f97cb4132a987dc1908bba9aa",
      "29be52da8ab2448e902bf9a9a264e5dd",
      "de1138c4a27d44dabe2179511b31160e"
     ]
    },
    "id": "aB_ayE_eykXp",
    "outputId": "bdcab291-96b3-4dd6-e997-09e08c95653f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO: \n",
      "  | Name                  | Type               | Params | Mode \n",
      "---------------------------------------------------------------------\n",
      "0 | loss                  | MAE                | 0      | train\n",
      "1 | encoder_var_selection | Sequential         | 709    | train\n",
      "2 | decoder_var_selection | Sequential         | 193    | train\n",
      "3 | static_context_linear | Linear             | 192    | train\n",
      "4 | lstm_encoder          | LSTM               | 51.5 K | train\n",
      "5 | lstm_decoder          | LSTM               | 50.4 K | train\n",
      "6 | self_attention        | MultiheadAttention | 16.6 K | train\n",
      "7 | pre_output            | Linear             | 4.2 K  | train\n",
      "8 | output_layer          | Linear             | 65     | train\n",
      "---------------------------------------------------------------------\n",
      "123 K     Trainable params\n",
      "0         Non-trainable params\n",
      "123 K     Total params\n",
      "0.495     Total estimated model params size (MB)\n",
      "18        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "INFO:lightning.pytorch.callbacks.model_summary:\n",
      "  | Name                  | Type               | Params | Mode \n",
      "---------------------------------------------------------------------\n",
      "0 | loss                  | MAE                | 0      | train\n",
      "1 | encoder_var_selection | Sequential         | 709    | train\n",
      "2 | decoder_var_selection | Sequential         | 193    | train\n",
      "3 | static_context_linear | Linear             | 192    | train\n",
      "4 | lstm_encoder          | LSTM               | 51.5 K | train\n",
      "5 | lstm_decoder          | LSTM               | 50.4 K | train\n",
      "6 | self_attention        | MultiheadAttention | 16.6 K | train\n",
      "7 | pre_output            | Linear             | 4.2 K  | train\n",
      "8 | output_layer          | Linear             | 65     | train\n",
      "---------------------------------------------------------------------\n",
      "123 K     Trainable params\n",
      "0         Non-trainable params\n",
      "123 K     Total params\n",
      "0.495     Total estimated model params size (MB)\n",
      "18        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a553dd138d714a18af6c0713e1b43897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d1a5f363394cc18785ac88a22d76d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c0a054bd0a4cc38bdaa2ef39bb30ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d5419fc33de4216807044da7fe61524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e0349ab6494ec09a6f909e152f685d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83af6fa1a89c44398eaa18bc89031fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "803a672f660842f6ab949ea62fc9e44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "print(\"\\nTraining model...\")\n",
    "trainer = Trainer(\n",
    "    max_epochs=5,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    enable_progress_bar=True,\n",
    "    log_every_n_steps=10,\n",
    ")\n",
    "\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p3mI-QVJ8TZF"
   },
   "source": [
    "\n",
    "#### Output\n",
    "Output of TFT model is a `dict` with key `prediction`:\n",
    "\n",
    "- `y_pred[\"prediction\"]`: Tensor of shape `(batch_size, prediction_length, output_size)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.setup(stage=\"test\")\n",
    "test_dataloader = data_module.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181,
     "referenced_widgets": [
      "37994d5bc49f4e70985436884f91c290",
      "2e9e4d42c79943d6b898f71a64c77d2a",
      "c2baeafd63d84115a4adc58542390e6a",
      "2c0e791c673e4df3b964a8315ab47fe2",
      "d0ebcd6e60bd4cb1b0004e20d4cbf868",
      "c58ffcd54aff4df5bee07cbd5fc0ac9e",
      "0d957465db5048e2b4a1a144a29b2d6f",
      "0b59e2c8901d40d79ceb08156d1c4e1d",
      "da6a1fefd37b4a74a77eaf48d09a1d1b",
      "2e49603fb8454b538257b9297507122d",
      "2a26b76eeffe4cf899776c4913552d1f"
     ]
    },
    "id": "_b8o8e2Tmzbd",
    "outputId": "e437cf69-2d5f-4c5a-cf6c-4d0dcf31f444"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37994d5bc49f4e70985436884f91c290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = model.predict(test_dataloader, return_info=[\"index\", \"x\", \"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ndMvbe0pLha",
    "outputId": "266ef096-374b-45f8-8ea0-4d283c588443"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Predicted Value:\n",
      "Index: 0.11104673147201538\n",
      "Prediction: -0.001255139708518982\n",
      "Actual: 0.07348770648241043\n"
     ]
    }
   ],
   "source": [
    "print(\"First Predicted Value:\")\n",
    "print(\"Index:\", preds[\"index\"][0].item())\n",
    "print(\"Prediction:\", preds[\"prediction\"][0].item())\n",
    "print(\"Actual:\", preds[\"y\"][0].item())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
